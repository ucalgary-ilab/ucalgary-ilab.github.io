<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><title data-next-head="">Designing Interaction with Autonomous Vehicles: External Displays and Interfaces for Vulnerable Road Users | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="Autonomous vehicles, External automotive displays, Pedestrians with hearing aids, Pedestrians in wheelchairs, Co-design, VR simulation" data-next-head=""/><meta name="description" content="In the near future, mixed traffic consisting of manual and autonomous vehicles (AVs) will be common. Autonomous vehicles with advanced technology offer opportunities for innovative designs and introduce communication challenges for vulnerable road users such as pedestrians and cyclists. Our goal is to explore the emerging new domain of interaction between different road users and autonomous vehicles in a future AV transportation ecosystem. This led us to conduct the thesis following these two themes: 1) understanding design opportunities for external automotive displays (EADs) of AVs; 2) exploring the design of interactions between vulnerable road users (VRUs) and AVs. In theme 1, our work extends contemporary research into visualizations and related applications for autonomous vehicles. Focusing on external car bodies as a design space we introduce a set of EADs. EADs show visualizations to share context and user-specific information and offer opportunities for interaction between users and AVs. We conducted a design study to explore design concepts for EADs to provide services to different road users: pedestrians, passengers, and drivers of other vehicles. Based on the design study, we prototyped four EADs in virtual reality (VR) to demonstrate the potential of our approach. This exploration contributes to our vision for EADs, a design critique of the prototypes, and a discussion of the possible impact and future usage of external automotive displays. In theme 2, we are interested in the ways pedestrians will interact with autonomous vehicles in the absence of non-verbal cues from the driver (such as eye movements, hand gestures, etc.). Crossing streets in these new situations could be more dangerous for VRUs without a proper communication medium. We examined a subset of this challenge with two groups of pedestrians: interaction between AVs and pedestrians with hearing aids (PHAs), and pedestrians in wheelchairs (PWs). First, we worked with hearing aid users as a preliminary exploration of this research. We conduct a co-design study with a co-designer with hearing impairment who has lived experience of wearing hearing aid enhancements. This study contributes several insights and design recommendations on how potential audio cues can be designed to enhance direct communications between PHAs and AVs. For the second part of our research, we designed interactions between pedestrians in wheelchairs and AVs. From an early exploration of potential interface designs through a design study with interaction designers, we prototyped different interfaces in VR. Then, we evaluated the implemented simulations during a co-design study with a powered wheelchair user following inclusive design practices. We identify and reflect on interface design ideas that can help PWs make safe crossing decisions at intersections and discuss design insights for implementing different inclusive interfaces." data-next-head=""/><meta property="og:title" content="Designing Interaction with Autonomous Vehicles: External Displays and Interfaces for Vulnerable Road Users | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta property="og:description" content="In the near future, mixed traffic consisting of manual and autonomous vehicles (AVs) will be common. Autonomous vehicles with advanced technology offer opportunities for innovative designs and introduce communication challenges for vulnerable road users such as pedestrians and cyclists. Our goal is to explore the emerging new domain of interaction between different road users and autonomous vehicles in a future AV transportation ecosystem. This led us to conduct the thesis following these two themes: 1) understanding design opportunities for external automotive displays (EADs) of AVs; 2) exploring the design of interactions between vulnerable road users (VRUs) and AVs. In theme 1, our work extends contemporary research into visualizations and related applications for autonomous vehicles. Focusing on external car bodies as a design space we introduce a set of EADs. EADs show visualizations to share context and user-specific information and offer opportunities for interaction between users and AVs. We conducted a design study to explore design concepts for EADs to provide services to different road users: pedestrians, passengers, and drivers of other vehicles. Based on the design study, we prototyped four EADs in virtual reality (VR) to demonstrate the potential of our approach. This exploration contributes to our vision for EADs, a design critique of the prototypes, and a discussion of the possible impact and future usage of external automotive displays. In theme 2, we are interested in the ways pedestrians will interact with autonomous vehicles in the absence of non-verbal cues from the driver (such as eye movements, hand gestures, etc.). Crossing streets in these new situations could be more dangerous for VRUs without a proper communication medium. We examined a subset of this challenge with two groups of pedestrians: interaction between AVs and pedestrians with hearing aids (PHAs), and pedestrians in wheelchairs (PWs). First, we worked with hearing aid users as a preliminary exploration of this research. We conduct a co-design study with a co-designer with hearing impairment who has lived experience of wearing hearing aid enhancements. This study contributes several insights and design recommendations on how potential audio cues can be designed to enhance direct communications between PHAs and AVs. For the second part of our research, we designed interactions between pedestrians in wheelchairs and AVs. From an early exploration of potential interface designs through a design study with interaction designers, we prototyped different interfaces in VR. Then, we evaluated the implemented simulations during a co-design study with a powered wheelchair user following inclusive design practices. We identify and reflect on interface design ideas that can help PWs make safe crossing decisions at intersections and discuss design insights for implementing different inclusive interfaces." data-next-head=""/><meta property="og:site_name" content="University of Calgary Interactions Lab" data-next-head=""/><meta property="og:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/theses/cover/msc-2021-asha.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:title" content="Designing Interaction with Autonomous Vehicles: External Displays and Interfaces for Vulnerable Road Users | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta name="twitter:description" content="In the near future, mixed traffic consisting of manual and autonomous vehicles (AVs) will be common. Autonomous vehicles with advanced technology offer opportunities for innovative designs and introduce communication challenges for vulnerable road users such as pedestrians and cyclists. Our goal is to explore the emerging new domain of interaction between different road users and autonomous vehicles in a future AV transportation ecosystem. This led us to conduct the thesis following these two themes: 1) understanding design opportunities for external automotive displays (EADs) of AVs; 2) exploring the design of interactions between vulnerable road users (VRUs) and AVs. In theme 1, our work extends contemporary research into visualizations and related applications for autonomous vehicles. Focusing on external car bodies as a design space we introduce a set of EADs. EADs show visualizations to share context and user-specific information and offer opportunities for interaction between users and AVs. We conducted a design study to explore design concepts for EADs to provide services to different road users: pedestrians, passengers, and drivers of other vehicles. Based on the design study, we prototyped four EADs in virtual reality (VR) to demonstrate the potential of our approach. This exploration contributes to our vision for EADs, a design critique of the prototypes, and a discussion of the possible impact and future usage of external automotive displays. In theme 2, we are interested in the ways pedestrians will interact with autonomous vehicles in the absence of non-verbal cues from the driver (such as eye movements, hand gestures, etc.). Crossing streets in these new situations could be more dangerous for VRUs without a proper communication medium. We examined a subset of this challenge with two groups of pedestrians: interaction between AVs and pedestrians with hearing aids (PHAs), and pedestrians in wheelchairs (PWs). First, we worked with hearing aid users as a preliminary exploration of this research. We conduct a co-design study with a co-designer with hearing impairment who has lived experience of wearing hearing aid enhancements. This study contributes several insights and design recommendations on how potential audio cues can be designed to enhance direct communications between PHAs and AVs. For the second part of our research, we designed interactions between pedestrians in wheelchairs and AVs. From an early exploration of potential interface designs through a design study with interaction designers, we prototyped different interfaces in VR. Then, we evaluated the implemented simulations during a co-design study with a powered wheelchair user following inclusive design practices. We identify and reflect on interface design ideas that can help PWs make safe crossing decisions at intersections and discuss design insights for implementing different inclusive interfaces." data-next-head=""/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/theses/cover/msc-2021-asha.jpg" data-next-head=""/><meta name="twitter:card" content="summary" data-next-head=""/><meta name="twitter:site" content="@ucalgary" data-next-head=""/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link rel="preload" href="/pr-preview/pr-163/_next/static/media/dc84b505c4b06e35-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/pr-preview/pr-163/_next/static/css/f4de94a4e08ecab3.css" as="style"/><link rel="preload" href="/pr-preview/pr-163/_next/static/css/a1a0497113412518.css" as="style"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              // $('.ui.sidebar')
              //   .sidebar('attach events', '.sidebar.icon')

              $('.sidebar.icon').on('click', function(event) {
                $('.ui.sidebar')
                  .sidebar('toggle')
              })

              $('.project').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })

              $('.thesis').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><link rel="stylesheet" href="/pr-preview/pr-163/_next/static/css/f4de94a4e08ecab3.css" data-n-g=""/><link rel="stylesheet" href="/pr-preview/pr-163/_next/static/css/a1a0497113412518.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/pr-preview/pr-163/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/pr-preview/pr-163/_next/static/chunks/webpack-2345941070d47ac4.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/340-e48e16335d89a433.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/main-f5a95b893c70049f.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/vendor-styles-c12d0d7ab35b0c98.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/505-9d87e35d03758351.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/pages/_app-09ca72778dd825e1.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/347-6f14004506bc7107.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/590-8bb7f72173922b48.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/104-79403ca78d551e49.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/960-f1b2911e7e0a7930.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/chunks/pages/theses/%5Bid%5D-5942484107cc76b8.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/86xmzMl4ij6CfWFN0U-00/_buildManifest.js" defer=""></script><script src="/pr-preview/pr-163/_next/static/86xmzMl4ij6CfWFN0U-00/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_9e8ce4"><div class="ui center aligned container"><div class="ui secondary huge compact menu"><a class="item" href="/pr-preview/pr-163/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui tiny image" style="color:transparent" srcSet="/pr-preview/pr-163/static/images/ilab-logo-3d.gif 1x" src="/pr-preview/pr-163/static/images/ilab-logo-3d.gif"/></a><a class="item" href="/pr-preview/pr-163/people/">People</a><a class="item" href="/pr-preview/pr-163/publications/">Research</a></div></div><div class="pusher"><div class="ui stackable grid"><div class="one wide column"></div><div class="ten wide column centered" style="margin-top:30px"><div id="thesis"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-163/thesiss/">Thesis</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">MSc 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"></div><div class="thirteen wide column"><h1>Designing Interaction with Autonomous Vehicles: External Displays and Interfaces for Vulnerable Road Users</h1><p class="meta"><a href="/people/ashratuz-zavin-asha"><img alt="ashratuz-zavin-asha photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-163/static/images/people/ashratuz-zavin-asha.jpg 1x" src="/pr-preview/pr-163/static/images/people/ashratuz-zavin-asha.jpg"/><strong>Ashratuz Zavin Asha</strong></a><span class="role"> (author)</span>, <a href="/people/ehud-sharlin"><img alt="ehud-sharlin photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-163/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-163/static/images/people/ehud-sharlin.jpg"/><strong>Ehud Sharlin</strong></a><span class="role"> (supervisor)</span>, <span>Michael John Jacobson Jr.<!-- --> <span class="role"> (committee)</span></span>, <span>Barry Wylant<!-- --> <span class="role"> (committee)</span></span>, <span>Patrick Finn<!-- --> <span class="role"> (committee)</span></span></p></div></div></div><div class="block"><h1>Abstract</h1><p>In the near future, mixed traffic consisting of manual and autonomous vehicles (AVs) will be common. Autonomous vehicles with advanced technology offer opportunities for innovative designs and introduce communication challenges for vulnerable road users such as pedestrians and cyclists. Our goal is to explore the emerging new domain of interaction between different road users and autonomous vehicles in a future AV transportation ecosystem. This led us to conduct the thesis following these two themes: 1) understanding design opportunities for external automotive displays (EADs) of AVs; 2) exploring the design of interactions between vulnerable road users (VRUs) and AVs. In theme 1, our work extends contemporary research into visualizations and related applications for autonomous vehicles. Focusing on external car bodies as a design space we introduce a set of EADs. EADs show visualizations to share context and user-specific information and offer opportunities for interaction between users and AVs. We conducted a design study to explore design concepts for EADs to provide services to different road users: pedestrians, passengers, and drivers of other vehicles. Based on the design study, we prototyped four EADs in virtual reality (VR) to demonstrate the potential of our approach. This exploration contributes to our vision for EADs, a design critique of the prototypes, and a discussion of the possible impact and future usage of external automotive displays. In theme 2, we are interested in the ways pedestrians will interact with autonomous vehicles in the absence of non-verbal cues from the driver (such as eye movements, hand gestures, etc.). Crossing streets in these new situations could be more dangerous for VRUs without a proper communication medium. We examined a subset of this challenge with two groups of pedestrians: interaction between AVs and pedestrians with hearing aids (PHAs), and pedestrians in wheelchairs (PWs). First, we worked with hearing aid users as a preliminary exploration of this research. We conduct a co-design study with a co-designer with hearing impairment who has lived experience of wearing hearing aid enhancements. This study contributes several insights and design recommendations on how potential audio cues can be designed to enhance direct communications between PHAs and AVs. For the second part of our research, we designed interactions between pedestrians in wheelchairs and AVs. From an early exploration of potential interface designs through a design study with interaction designers, we prototyped different interfaces in VR. Then, we evaluated the implemented simulations during a co-design study with a powered wheelchair user following inclusive design practices. We identify and reflect on interface design ideas that can help PWs make safe crossing decisions at intersections and discuss design insights for implementing different inclusive interfaces.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Autonomous Vehicles</span><span class="ui brown basic label">External Automotive Displays</span><span class="ui brown basic label">Pedestrians With Hearing Aids</span><span class="ui brown basic label">Pedestrians In Wheelchairs</span><span class="ui brown basic label">Co Design</span><span class="ui brown basic label">VR Simulation</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Ashratuz Zavin Asha<!-- -->. <b>Designing Interaction with Autonomous Vehicles: External Displays and Interfaces for Vulnerable Road Users</b>. <i></i> <!-- -->University of Calgary<!-- -->. <!-- -->Master of Science (MSc)<!-- -->. <!-- -->2021-09-02<!-- -->. <!-- -->URL: <a href="http://hdl.handle.net/1880/113831" target="_blank">http://hdl.handle.net/1880/113831</a></p></div></div></div></div><div class="one wide column"></div></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><div class="content"><a href="https://ucalgary.ca"><img alt="University of Calgary logo" loading="lazy" width="200" height="0" decoding="async" data-nimg="1" style="color:transparent;max-width:200px;margin:0px auto;height:auto" srcSet="/pr-preview/pr-163/static/images/logo-4.png 1x, /pr-preview/pr-163/static/images/logo-4.png 2x" src="/pr-preview/pr-163/static/images/logo-4.png"/></a><div class="sub header"><a class="item" href="https://cpsc.ucalgary.ca">Department of Computer Science</a></div></div></div></footer></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"ids":[{"id":"mmus-2012-pon"},{"id":"msc-2008-guo"},{"id":"msc-2011-harris"},{"id":"msc-2011-sultanum"},{"id":"msc-2012-lapides"},{"id":"msc-2015-li"},{"id":"msc-2017-hu"},{"id":"msc-2017-mok"},{"id":"msc-2017-payne"},{"id":"msc-2018-cartwright"},{"id":"msc-2018-ta"},{"id":"msc-2019-danyluk"},{"id":"msc-2019-kollannur"},{"id":"msc-2019-kuzabaviciute"},{"id":"msc-2019-mahadevan"},{"id":"msc-2019-mikalauskas"},{"id":"msc-2019-wun"},{"id":"msc-2021-asha"},{"id":"msc-2021-hung"},{"id":"msc-2021-wannamaker"},{"id":"msc-2023-dhawka"},{"id":"msc-2023-jadon"},{"id":"msc-2023-smith"},{"id":"msc-2023-wei"},{"id":"msc-2024-friedel"},{"id":"msc-2025-chulpongsatorn"},{"id":"phd-2010-young"},{"id":"phd-2017-somanath"},{"id":"phd-2018-mostafa"},{"id":"phd-2018-rajabiyazdi"},{"id":"phd-2019-li"},{"id":"phd-2020-ledo-maira"},{"id":"phd-2022-hull"},{"id":"phd-2024-mckendrick"},{"id":"phd-2025-cabral-mota"},{"id":"phd-2025-poostchi"},{"id":"phd-2025-pratte"}]},"__N_SSG":true},"page":"/theses/[id]","query":{"id":"msc-2021-asha"},"buildId":"86xmzMl4ij6CfWFN0U-00","assetPrefix":"/pr-preview/pr-163","runtimeConfig":{"basePath":"/pr-preview/pr-163"},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><title data-next-head="">Anthony Tang | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="Human-Computer Interaction, HCI, Information Visualization, University of Calgary, CHI, UIST" data-next-head=""/><meta name="description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" data-next-head=""/><meta property="og:title" content="Anthony Tang | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta property="og:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" data-next-head=""/><meta property="og:site_name" content="University of Calgary Interactions Lab" data-next-head=""/><meta property="og:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/people/anthony-tang.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:title" content="Anthony Tang | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta name="twitter:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" data-next-head=""/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/people/anthony-tang.jpg" data-next-head=""/><meta name="twitter:card" content="summary" data-next-head=""/><meta name="twitter:site" content="@ucalgary" data-next-head=""/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link rel="preload" href="/pr-preview/pr-99/_next/static/media/e807dee2426166ad-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/pr-preview/pr-99/_next/static/css/6d9e7a9830112c75.css" as="style"/><link rel="preload" href="/pr-preview/pr-99/_next/static/css/fa1543fdff44676b.css" as="style"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              // $('.ui.sidebar')
              //   .sidebar('attach events', '.sidebar.icon')

              $('.sidebar.icon').on('click', function(event) {
                $('.ui.sidebar')
                  .sidebar('toggle')
              })

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><link rel="stylesheet" href="/pr-preview/pr-99/_next/static/css/6d9e7a9830112c75.css" data-n-g=""/><link rel="stylesheet" href="/pr-preview/pr-99/_next/static/css/fa1543fdff44676b.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/pr-preview/pr-99/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/pr-preview/pr-99/_next/static/chunks/webpack-f365d01970793294.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/340-70a4acb82854fa33.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/main-237fefe93cf728ed.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/vendor-styles-6190db7a8f8561e2.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/110-2c2224f87be24bba.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/pages/_app-a1a52e1bf24d014b.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/723-9071df5d30f1ec6a.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/900-3b16458dd50e4a22.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/230-149465347cb3e206.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/829-1c30adaf55f71841.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/296-4a5d5256c11fe53c.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/696-884c089d111039d5.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/174-72a5fea7d32a35fe.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/chunks/pages/people/%5Bid%5D-475519d5c256ba52.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/-5mA34hSgvPPCQ_3JIeXx/_buildManifest.js" defer=""></script><script src="/pr-preview/pr-99/_next/static/-5mA34hSgvPPCQ_3JIeXx/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_0af360"><div class="ui right vertical sidebar menu"><a class="item" href="/pr-preview/pr-99/">Home</a><a class="item" href="/pr-preview/pr-99/publications/">Publications</a><a class="item active" href="/pr-preview/pr-99/people/">People</a><a class="item" href="/pr-preview/pr-99/courses/">Courses</a><a class="item" href="/pr-preview/pr-99/facility/">Facility</a><a class="item" href="/pr-preview/pr-99/seminar/">Seminar</a><a class="item" href="/pr-preview/pr-99/location/">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/pr-preview/pr-99/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item" href="/pr-preview/pr-99/publications/">Publications</a><a class="item active" href="/pr-preview/pr-99/people/">People</a><a class="item" href="/pr-preview/pr-99/courses/">Courses</a><a class="item" href="/pr-preview/pr-99/facility/">Facility</a><a class="item" href="/pr-preview/pr-99/seminar/">Seminar</a><a class="item" href="/pr-preview/pr-99/location/">Location</a><div class="toc item"><a href="/pr-preview/pr-99/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div><div class="pusher"><div class="ui stackable grid"><div class="one wide column"></div><div class="eleven wide column centered"><div id="person" class="category" style="text-align:center"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular image large-profile" style="color:transparent;margin:auto" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><h1>Anthony Tang</h1><p>Adjunct Associate Professor (Singapore Management University)</p><p><a target="_blank" href="https://hcitang.github.io/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>https://hcitang.github.io/</a></p><p><a target="_blank" href="https://scholar.google.com/citations?user=RG1EQowAAAAJ"><svg data-prefix="fas" data-icon="graduation-cap" class="svg-inline--fa fa-graduation-cap" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M48 195.8l209.2 86.1c9.8 4 20.2 6.1 30.8 6.1s21-2.1 30.8-6.1l242.4-99.8c9-3.7 14.8-12.4 14.8-22.1s-5.8-18.4-14.8-22.1L318.8 38.1C309 34.1 298.6 32 288 32s-21 2.1-30.8 6.1L14.8 137.9C5.8 141.6 0 150.3 0 160L0 456c0 13.3 10.7 24 24 24s24-10.7 24-24l0-260.2zm48 71.7L96 384c0 53 86 96 192 96s192-43 192-96l0-116.6-142.9 58.9c-15.6 6.4-32.2 9.7-49.1 9.7s-33.5-3.3-49.1-9.7L96 267.4z"></path></svg>Google Scholar</a></p><div class="ui horizontal small divided link list"><div class="item"><a target="_blank" style="font-size:1.2em" href="https://twitter.com/proclubboy"><svg data-prefix="fab" data-icon="twitter" class="svg-inline--fa fa-twitter" role="img" viewBox="0 0 512 512" aria-hidden="true"><path fill="currentColor" d="M459.4 151.7c.3 4.5 .3 9.1 .3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103l0-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53 51.7 63.7 129.3 105.3 216.4 109.8-1.6-7.8-2.6-15.9-2.6-24 0-57.8 46.8-104.9 104.9-104.9 30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3z"></path></svg>proclubboy</a></div><div class="item"><a target="_blank" style="font-size:1.2em" href="http://github.com/hcitang"><svg data-prefix="fab" data-icon="github-alt" class="svg-inline--fa fa-github-alt" role="img" viewBox="0 0 512 512" aria-hidden="true"><path fill="currentColor" d="M202.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM496 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3l48.2 0c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"></path></svg>hcitang</a></div></div><div class="one wide column"><div class="ui horizontal small divided link list"></div></div></div><div id="publications" class="category"><h1 class="ui horizontal divider header"><svg data-prefix="far" data-icon="file-lines" class="svg-inline--fa fa-file-lines" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M64 48l112 0 0 88c0 39.8 32.2 72 72 72l88 0 0 240c0 8.8-7.2 16-16 16L64 464c-8.8 0-16-7.2-16-16L48 64c0-8.8 7.2-16 16-16zM224 67.9l92.1 92.1-68.1 0c-13.3 0-24-10.7-24-24l0-68.1zM64 0C28.7 0 0 28.7 0 64L0 448c0 35.3 28.7 64 64 64l256 0c35.3 0 64-28.7 64-64l0-261.5c0-17-6.7-33.3-18.7-45.3L242.7 18.7C230.7 6.7 214.5 0 197.5 0L64 0zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24l144 0c13.3 0 24-10.7 24-24s-10.7-24-24-24l-144 0zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24l144 0c13.3 0 24-10.7 24-24s-10.7-24-24-24l-144 0z"></path></svg>Publications</h1><div class="ui segment" style="margin-top:50px"><div class="publication ui vertical segment stackable grid" data-id="assets-2023-mok"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/assets-2023-mok.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/assets-2023-mok.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">ASSETS 2023</span></p><p class="color" style="font-size:1.3em"><b>Experiences of Autistic Twitch Livestreamers: “I have made easily the most meaningful and impactful relationships”</b></p><p><a href="/pr-preview/pr-99/people/terrance-mok/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/terrance-mok.jpg 1x" src="/pr-preview/pr-99/static/images/people/terrance-mok.jpg"/><span class="author-link">Terrance Mok</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <span>Adam McCrimmon</span> , <a href="/pr-preview/pr-99/people/lora-oehlberg/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><span class="author-link">Lora Oehlberg</span></a></p><div><div class="ui large basic labels"><span class="ui brown basic label">Autism</span><span class="ui brown basic label">Live Streaming</span><span class="ui brown basic label">Autistic</span><span class="ui brown basic label">Twitch</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="tei-2021-pratte"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/tei-2021-pratte.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/tei-2021-pratte.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">TEI 2021</span></p><p class="color" style="font-size:1.3em"><b>Evoking Empathy: A Framework for Describing Empathy Tools</b></p><p><a href="/pr-preview/pr-99/people/sydney-pratte/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/sydney-pratte.jpg 1x" src="/pr-preview/pr-99/static/images/people/sydney-pratte.jpg"/><span class="author-link">Sydney Pratte</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <a href="/pr-preview/pr-99/people/lora-oehlberg/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><span class="author-link">Lora Oehlberg</span></a></p><div><div class="ui large basic labels"><span class="ui brown basic label">Empathy</span><span class="ui brown basic label">Empathy Tools</span><span class="ui brown basic label">Design Strategies</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="uist-2020-yixian"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/uist-2020-yixian.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/uist-2020-yixian.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">UIST 2020</span></p><p class="color" style="font-size:1.3em"><b>ZoomWalls: Dynamic Walls that Simulate Haptic Infrastructure for Room-scale VR World</b></p><p><span>Yan Yixian</span> , <span>Kazuki Takashima</span> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <span>Takayuki Tanno</span> , <span>Kazuyuki Fujita</span> , <span>Yoshifumi Kitamura</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Encountered Type Haptic Devices</span><span class="ui brown basic label">Immersive Experience</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="imx-2020-mok"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/imx-2020-mok.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/imx-2020-mok.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">IMX 2020</span></p><p class="color" style="font-size:1.3em"><b>Talk Like Somebody is Watching: Understanding and Supporting Novice Live Streamers</b></p><p><a href="/pr-preview/pr-99/people/terrance-mok/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/terrance-mok.jpg 1x" src="/pr-preview/pr-99/static/images/people/terrance-mok.jpg"/><span class="author-link">Terrance Mok</span></a> , <a href="/pr-preview/pr-99/people/colin-auyeung/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/colin-auyeung.jpg 1x" src="/pr-preview/pr-99/static/images/people/colin-auyeung.jpg"/><span class="author-link">Colin Au Yeung</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <a href="/pr-preview/pr-99/people/lora-oehlberg/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><span class="author-link">Lora Oehlberg</span></a></p><div><div class="ui large basic labels"><span class="ui brown basic label">Live Streams</span><span class="ui brown basic label">Streamers</span><span class="ui brown basic label">Chatbot</span><span class="ui brown basic label">Audience</span><span class="ui brown basic label">Virtual Audience</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2020-anjani"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2020-anjani.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2020-anjani.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2020</span></p><p class="color" style="font-size:1.3em"><b>Why do people watch others eat food? An Empirical Study on the Motivations and Practices of Mukbang Viewers</b></p><p><span>Laurensia Anjani</span> , <a href="/pr-preview/pr-99/people/terrance-mok/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/terrance-mok.jpg 1x" src="/pr-preview/pr-99/static/images/people/terrance-mok.jpg"/><span class="author-link">Terrance Mok</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <a href="/pr-preview/pr-99/people/lora-oehlberg/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><span class="author-link">Lora Oehlberg</span></a> , <span>Wooi Boon Goh</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Video Streams</span><span class="ui brown basic label">Mukbang</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2019-seyed"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/dis-2019-seyed.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/dis-2019-seyed.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2019</span><span class="ui big basic pink label"><b><svg data-prefix="fas" data-icon="award" class="svg-inline--fa fa-award" role="img" viewBox="0 0 448 512" aria-hidden="true"><path fill="currentColor" d="M245.9-25.9c-13.4-8.2-30.3-8.2-43.7 0-24.4 14.9-39.5 18.9-68.1 18.3-15.7-.4-30.3 8.1-37.9 21.9-13.7 25.1-24.8 36.2-49.9 49.9-13.8 7.5-22.2 22.2-21.9 37.9 .7 28.6-3.4 43.7-18.3 68.1-8.2 13.4-8.2 30.3 0 43.7 14.9 24.4 18.9 39.5 18.3 68.1-.4 15.7 8.1 30.3 21.9 37.9 22.1 12.1 33.3 22.1 45.1 41.5L42.7 458.5c-5.9 11.9-1.1 26.3 10.7 32.2l86 43c11.5 5.7 25.5 1.4 31.7-9.8l52.8-95.1 52.8 95.1c6.2 11.2 20.2 15.6 31.7 9.8l86-43c11.9-5.9 16.7-20.3 10.7-32.2l-48.6-97.2c11.7-19.4 23-29.4 45.1-41.5 13.8-7.5 22.2-22.2 21.9-37.9-.7-28.6 3.4-43.7 18.3-68.1 8.2-13.4 8.2-30.3 0-43.7-14.9-24.4-18.9-39.5-18.3-68.1 .4-15.7-8.1-30.3-21.9-37.9-25.1-13.7-36.2-24.8-49.9-49.9-7.5-13.8-22.2-22.2-37.9-21.9-28.6 .7-43.7-3.4-68.1-18.3zM224 96a96 96 0 1 1 0 192 96 96 0 1 1 0-192z"></path></svg> Honorable Mention</b></span></p><p class="color" style="font-size:1.3em"><b>Mannequette: Understanding and Enabling Collaboration and Creativity on Avant-Garde Fashion-Tech Runways</b></p><p><a href="/pr-preview/pr-99/people/teddy-seyed/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/teddy-seyed.jpg 1x" src="/pr-preview/pr-99/static/images/people/teddy-seyed.jpg"/><span class="author-link">Teddy Seyed</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a></p><div><div class="ui large basic labels"><span class="ui brown basic label">Fashion</span><span class="ui brown basic label">Haute Couture</span><span class="ui brown basic label">E Textiles</span><span class="ui brown basic label">Maker Culture</span><span class="ui brown basic label">Fashion Tech</span><span class="ui brown basic label">Wearables</span><span class="ui brown basic label">Avant Garde</span><span class="ui brown basic label">Haute Tech Couture</span><span class="ui brown basic label">Modular</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="tei-2019-tolley"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/tei-2019-tolley.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/tei-2019-tolley.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">TEI 2019</span></p><p class="color" style="font-size:1.3em"><b>WindyWall: Exploring Creative Wind Simulations</b></p><p><span>David Tolley</span> , <span>Thi Ngoc Tram Nguyen</span> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <span>Nimesha Ranasinghe</span> , <span>Kensaku Kawauchi</span> , <span>Ching-Chiuan Yen</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Tactile Haptic Interaction</span><span class="ui brown basic label">Multimodal Interaction</span><span class="ui brown basic label">Novel Actuators Displays</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2018-pham"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/dis-2018-pham.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/dis-2018-pham.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2018</span></p><p class="color" style="font-size:1.3em"><b>Scale Impacts Elicited Gestures for Manipulating Holograms: Implications for AR Gesture Design</b></p><p><span>Tran Pham</span> , <span>Jo Vermeulen</span> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <span>Lindsay MacDonald Vermeulen</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Gestures</span><span class="ui brown basic label">Gesture Elicitation</span><span class="ui brown basic label">Hololens</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2018-dillman"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2018-dillman.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2018-dillman.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2018</span></p><p class="color" style="font-size:1.3em"><b>A Visual Interaction Cue Framework from Video Game Environments for Augmented Reality</b></p><p><span>Kody R. Dillman</span> , <a href="/pr-preview/pr-99/people/terrance-mok/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/terrance-mok.jpg 1x" src="/pr-preview/pr-99/static/images/people/terrance-mok.jpg"/><span class="author-link">Terrance Mok</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <a href="/pr-preview/pr-99/people/lora-oehlberg/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><span class="author-link">Lora Oehlberg</span></a> , <span>Alex Mitchell</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Game Design</span><span class="ui brown basic label">Guidance</span><span class="ui brown basic label">Interaction Cues</span><span class="ui brown basic label">Augmented Reality</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2018-feick"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2018-feick.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2018-feick.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2018</span><span class="ui big basic pink label"><b><svg data-prefix="fas" data-icon="award" class="svg-inline--fa fa-award" role="img" viewBox="0 0 448 512" aria-hidden="true"><path fill="currentColor" d="M245.9-25.9c-13.4-8.2-30.3-8.2-43.7 0-24.4 14.9-39.5 18.9-68.1 18.3-15.7-.4-30.3 8.1-37.9 21.9-13.7 25.1-24.8 36.2-49.9 49.9-13.8 7.5-22.2 22.2-21.9 37.9 .7 28.6-3.4 43.7-18.3 68.1-8.2 13.4-8.2 30.3 0 43.7 14.9 24.4 18.9 39.5 18.3 68.1-.4 15.7 8.1 30.3 21.9 37.9 22.1 12.1 33.3 22.1 45.1 41.5L42.7 458.5c-5.9 11.9-1.1 26.3 10.7 32.2l86 43c11.5 5.7 25.5 1.4 31.7-9.8l52.8-95.1 52.8 95.1c6.2 11.2 20.2 15.6 31.7 9.8l86-43c11.9-5.9 16.7-20.3 10.7-32.2l-48.6-97.2c11.7-19.4 23-29.4 45.1-41.5 13.8-7.5 22.2-22.2 21.9-37.9-.7-28.6 3.4-43.7 18.3-68.1 8.2-13.4 8.2-30.3 0-43.7-14.9-24.4-18.9-39.5-18.3-68.1 .4-15.7-8.1-30.3-21.9-37.9-25.1-13.7-36.2-24.8-49.9-49.9-7.5-13.8-22.2-22.2-37.9-21.9-28.6 .7-43.7-3.4-68.1-18.3zM224 96a96 96 0 1 1 0 192 96 96 0 1 1 0-192z"></path></svg> Honorable Mention</b></span></p><p class="color" style="font-size:1.3em"><b>Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration</b></p><p><a href="/pr-preview/pr-99/people/martin-feick/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/martin-feick.jpg 1x" src="/pr-preview/pr-99/static/images/people/martin-feick.jpg"/><span class="author-link">Martin Feick</span></a> , <span>Terrance Tin Hoi Mok</span> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <a href="/pr-preview/pr-99/people/lora-oehlberg/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><span class="author-link">Lora Oehlberg</span></a> , <a href="/pr-preview/pr-99/people/ehud-sharlin/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg"/><span class="author-link">Ehud Sharlin</span></a></p><div><div class="ui large basic labels"><span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Object Focused Collaboration</span><span class="ui brown basic label">Physical Telepresence</span><span class="ui brown basic label">Collaborative Physical Tasks</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2018-heshmat"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2018-heshmat.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2018-heshmat.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2018</span></p><p class="color" style="font-size:1.3em"><b>Geocaching with a Beam: Shared Outdoor Activities through a Telepresence Robot with 360 Degree Viewing</b></p><p><span>Yasamin Heshmat</span> , <a href="/pr-preview/pr-99/people/brennan-jones/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/brennan-jones.jpg 1x" src="/pr-preview/pr-99/static/images/people/brennan-jones.jpg"/><span class="author-link">Brennan Jones</span></a> , <span>Xiaoxuan Xiong</span> , <a href="/pr-preview/pr-99/people/carman-neustaedter/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg 1x" src="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg"/><span class="author-link">Carman Neustaedter</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <span>Bernhard E. Riecke</span> , <span>Lillian Yang</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Video Communication</span><span class="ui brown basic label">Telepresence Robots</span><span class="ui brown basic label">Leisure Activities</span><span class="ui brown basic label">Social Presence</span><span class="ui brown basic label">Geocaching</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2018-wuertz"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2018-wuertz.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2018-wuertz.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2018</span></p><p class="color" style="font-size:1.3em"><b>A Design Framework for Awareness Cues in Distributed Multiplayer Games</b></p><p><span>Jason Wuertz</span> , <span>Sultan A. Alharthi</span> , <span>William A. Hamilton</span> , <span>Scott Bateman</span> , <a href="/pr-preview/pr-99/people/carl-gutwin/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/carl-gutwin.jpg 1x" src="/pr-preview/pr-99/static/images/people/carl-gutwin.jpg"/><span class="author-link">Carl Gutwin</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <span>Zachary O. Toups</span> , <span>Jessica Hammer</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Workspace Awareness</span><span class="ui brown basic label">Situation Awareness</span><span class="ui brown basic label">Game Design</span><span class="ui brown basic label">Distributed Multiplayer Games</span><span class="ui brown basic label">Awareness Cues</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="hri-2018-feick"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/hri-2018-feick.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/hri-2018-feick.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">HRI 2018</span></p><p class="color" style="font-size:1.3em"><b>The Way You Move: The Effect of a Robot Surrogate Movement in Remote Collaboration</b></p><p><a href="/pr-preview/pr-99/people/martin-feick/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/martin-feick.jpg 1x" src="/pr-preview/pr-99/static/images/people/martin-feick.jpg"/><span class="author-link">Martin Feick</span></a> , <a href="/pr-preview/pr-99/people/lora-oehlberg/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><span class="author-link">Lora Oehlberg</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <span>André Miede</span> , <a href="/pr-preview/pr-99/people/ehud-sharlin/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg"/><span class="author-link">Ehud Sharlin</span></a></p><div><div class="ui large basic labels"><span class="ui brown basic label">Movement Trajectory Velocity</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Robot Surrogate</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2016-jones"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/dis-2016-jones.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/dis-2016-jones.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2016</span></p><p class="color" style="font-size:1.3em"><b>Elevating Communication, Collaboration, and Shared Experiences in Mobile Video through Drones</b></p><p><a href="/pr-preview/pr-99/people/brennan-jones/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/brennan-jones.jpg 1x" src="/pr-preview/pr-99/static/images/people/brennan-jones.jpg"/><span class="author-link">Brennan Jones</span></a> , <span>Kody Dillman</span> , <span>Richard Tang</span> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <a href="/pr-preview/pr-99/people/ehud-sharlin/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg"/><span class="author-link">Ehud Sharlin</span></a> , <a href="/pr-preview/pr-99/people/lora-oehlberg/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><span class="author-link">Lora Oehlberg</span></a> , <a href="/pr-preview/pr-99/people/carman-neustaedter/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg 1x" src="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg"/><span class="author-link">Carman Neustaedter</span></a> , <span>Scott Bateman</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Telepresence</span><span class="ui brown basic label">Video Communication</span><span class="ui brown basic label">Shared Experiences</span><span class="ui brown basic label">Teleoperation</span><span class="ui brown basic label">Drones</span><span class="ui brown basic label">Collaboration</span><span class="ui brown basic label">Hri</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2015-aseniero"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2015-aseniero.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2015-aseniero.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2015</span></p><p class="color" style="font-size:1.3em"><b>Stratos: Using Visualization to Support Decisions in Strategic Software Release Planning</b></p><p><a href="/pr-preview/pr-99/people/bon-adriel-aseniero/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/bon-adriel-aseniero.jpg 1x" src="/pr-preview/pr-99/static/images/people/bon-adriel-aseniero.jpg"/><span class="author-link">Bon Adriel Aseniero</span></a> , <span>Tiffany Wun</span> , <a href="/pr-preview/pr-99/people/david-ledo/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/david-ledo.jpg 1x" src="/pr-preview/pr-99/static/images/people/david-ledo.jpg"/><span class="author-link">David Ledo</span></a> , <span>Guenther Ruhe</span> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a> , <a href="/pr-preview/pr-99/people/sheelagh-carpendale/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/sheelagh-carpendale.jpg 1x" src="/pr-preview/pr-99/static/images/people/sheelagh-carpendale.jpg"/><span class="author-link">Sheelagh Carpendale</span></a></p><div><div class="ui large basic labels"><span class="ui brown basic label">Software Engineering</span><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Release Planning</span></div></div></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2015-jones"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2015-jones.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2015-jones.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2015</span></p><p class="color" style="font-size:1.3em"><b>Mechanics of Camera Work in Mobile Video Collaboration</b></p><p><a href="/pr-preview/pr-99/people/brennan-jones/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/brennan-jones.jpg 1x" src="/pr-preview/pr-99/static/images/people/brennan-jones.jpg"/><span class="author-link">Brennan Jones</span></a> , <span>Anna Witcraft</span> , <span>Scott Bateman</span> , <a href="/pr-preview/pr-99/people/carman-neustaedter/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg 1x" src="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg"/><span class="author-link">Carman Neustaedter</span></a> , <a href="/pr-preview/pr-99/people/anthony-tang/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><span class="author-link">Anthony Tang</span></a></p><div><div class="ui large basic labels"><span class="ui brown basic label">Video Communication</span><span class="ui brown basic label">Collaboration</span><span class="ui brown basic label">Mobile Computing</span><span class="ui brown basic label">Handheld Devices</span><span class="ui brown basic label">Cscw</span></div></div></div></div></div><div id="publications-modal"><div id="assets-2023-mok" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/assets-2023-mok/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>assets-2023-mok</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">ASSETS 2023</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/assets-2023-mok.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/assets-2023-mok.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/assets-2023-mok" target="_blank">Experiences of Autistic Twitch Livestreamers: “I have made easily the most meaningful and impactful relationships”</a></h1><p class="meta"><a href="/people/terrance-mok"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/terrance-mok.jpg 1x" src="/pr-preview/pr-99/static/images/people/terrance-mok.jpg"/><strong>Terrance Mok</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <span>Adam McCrimmon</span> , <a href="/people/lora-oehlberg"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/assets-2023-mok.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>assets-2023-mok.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We present perspectives from 10 autistic Twitch streamers regarding their experiences as livestreamers and how autism uniquely colors their experiences. Livestreaming offers a social online experience distinct from in-person, face-to-face communication, where autistic people tend to encounter challenges. Our reflexive thematic analysis of interviews with 10 participants showcases autistic livestreamers’ perspectives in their own words. Our findings center on the importance of having streamers establishing connections with other, sharing autistic identities, controlling a space for social interaction, personal growth, and accessibility challenges. In our discussion, we highlight the crucial value of having a medium for autistic representation, as well as design opportunities for streaming platforms to onboard autistic livestreamers and to facilitate livestreamers communication with their audience.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Autism</span><span class="ui brown basic label">Live Streaming</span><span class="ui brown basic label">Autistic</span><span class="ui brown basic label">Twitch</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Terrance Mok<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Adam McCrimmon<!-- -->, <!-- -->Lora Oehlberg<!-- -->. <b>Experiences of Autistic Twitch Livestreamers: “I have made easily the most meaningful and impactful relationships”</b>. <i>In undefined (ASSETS &#x27;23)</i>. <!-- -->  Page: 1-<!-- -->.  DOI: <a href="https://doi.org/10.1145/3597638.3608416" target="_blank">https://doi.org/10.1145/3597638.3608416</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="tei-2021-pratte" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/tei-2021-pratte/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>tei-2021-pratte</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">TEI 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/tei-2021-pratte.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/tei-2021-pratte.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/tei-2021-pratte" target="_blank">Evoking Empathy: A Framework for Describing Empathy Tools</a></h1><p class="meta"><a href="/people/sydney-pratte"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/sydney-pratte.jpg 1x" src="/pr-preview/pr-99/static/images/people/sydney-pratte.jpg"/><strong>Sydney Pratte</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <a href="/people/lora-oehlberg"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/tei-2021-pratte.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>tei-2021-pratte.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/JBCzPt5ILxo" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/JBCzPt5ILxo?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/JBCzPt5ILxo/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Empathy tools are experiences designed to evoke empathetic responses by placing the user in another’s lived and felt experience. The problem is that designers do not have a common vocabulary to describe empathy tool experiences; consequently, it is difficult to compare/contrast empathy tool designs or to think about their efficacy. To address this problem, we analyzed 26 publications on empathy tools to develop a descriptive framework for designers of empathy tools. Based on our analysis, we found that empathy tools can be described along three dimensions: (i) the amount of agency the tool allows, (ii) the user’s perspective while using the tool, and (iii) the type of sensations that are experienced. We show that this framework can be used to describe a wide variety of empathy tools and provide recommendations for empathy tool designers, as well as techniques for measuring the efficacy of an empathy tool experience.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Empathy</span><span class="ui brown basic label">Empathy Tools</span><span class="ui brown basic label">Design Strategies</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Sydney Pratte<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Lora Oehlberg<!-- -->. <b>Evoking Empathy: A Framework for Describing Empathy Tools</b>. <i>In Proceedings of the International Conference on Tangible, Embedded, and Embodied Interaction (TEI &#x27;21)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://dl.acm.org/doi/10.1145/3430524.3440644" target="_blank">https://dl.acm.org/doi/10.1145/3430524.3440644</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="uist-2020-yixian" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/uist-2020-yixian/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>uist-2020-yixian</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">UIST 2020</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/uist-2020-yixian.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/uist-2020-yixian.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/uist-2020-yixian" target="_blank">ZoomWalls: Dynamic Walls that Simulate Haptic Infrastructure for Room-scale VR World</a></h1><p class="meta"><span>Yan Yixian</span> , <span>Kazuki Takashima</span> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <span>Takayuki Tanno</span> , <span>Kazuyuki Fujita</span> , <span>Yoshifumi Kitamura</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/uist-2020-yixian.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>uist-2020-yixian.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/j2iSNDkBxAY" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/j2iSNDkBxAY?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/j2iSNDkBxAY/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We focus on the problem of simulating the haptic infrastructure of a virtual environment (i.e. walls, doors). Our approach relies on multiple ZoomWalls---autonomous robotic encounter-type haptic wall-shaped props---that coordinate to provide haptic feedback for room-scale virtual reality. Based on a user&#x27;s movement through the physical space, ZoomWall props are coordinated through a predict-and-dispatch architecture to provide just-in-time haptic feedback for objects the user is about to touch. To refine our system, we conducted simulation studies of different prediction algorithms, which helped us to refine our algorithmic approach to realize the physical ZoomWall prototype. Finally, we evaluated our system through a user experience study, which showed that participants found that ZoomWalls increased their sense of presence in the VR environment. ZoomWalls represents an instance of autonomous mobile reusable props, which we view as an important design direction for haptics in VR.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Encountered Type Haptic Devices</span><span class="ui brown basic label">Immersive Experience</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Yan Yixian<!-- -->, <!-- -->Kazuki Takashima<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Takayuki Tanno<!-- -->, <!-- -->Kazuyuki Fujita<!-- -->, <!-- -->Yoshifumi Kitamura<!-- -->. <b>ZoomWalls: Dynamic Walls that Simulate Haptic Infrastructure for Room-scale VR World</b>. <i>In Proceedings of the Annual ACM Symposium on User Interface Software and Technology (UIST &#x27;20)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3379337.3415859" target="_blank">https://doi.org/10.1145/3379337.3415859</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="imx-2020-mok" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/imx-2020-mok/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>imx-2020-mok</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">IMX 2020</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/imx-2020-mok.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/imx-2020-mok.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/imx-2020-mok" target="_blank">Talk Like Somebody is Watching: Understanding and Supporting Novice Live Streamers</a></h1><p class="meta"><a href="/people/terrance-mok"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/terrance-mok.jpg 1x" src="/pr-preview/pr-99/static/images/people/terrance-mok.jpg"/><strong>Terrance Mok</strong></a> , <a href="/people/colin-auyeung"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/colin-auyeung.jpg 1x" src="/pr-preview/pr-99/static/images/people/colin-auyeung.jpg"/><strong>Colin Au Yeung</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <a href="/people/lora-oehlberg"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/imx-2020-mok.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>imx-2020-mok.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We built a chatbot system–Audience Bot–that simulates an audience for novice live streamers to engage with while streaming. New live streamers on platforms like Twitch are expected to perform and talk to themselves, even while no one is watching. We ran an observational lab study on how Audience Bot assists novice live streamers as they acclimate to multitasking–simultaneously playing a video game while performing for a (simulated) audience.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Live Streams</span><span class="ui brown basic label">Streamers</span><span class="ui brown basic label">Chatbot</span><span class="ui brown basic label">Audience</span><span class="ui brown basic label">Virtual Audience</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Terrance Mok<!-- -->, <!-- -->Colin Au Yeung<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Lora Oehlberg<!-- -->. <b>Talk Like Somebody is Watching: Understanding and Supporting Novice Live Streamers</b>. <i>In undefined (IMX &#x27;20)</i>. <!-- -->  Page: 1-<!-- -->6<!-- -->.  DOI: <a href="10.1145/3391614.3399392" target="_blank">10.1145/3391614.3399392</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2020-anjani" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/chi-2020-anjani/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>chi-2020-anjani</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI 2020</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2020-anjani.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2020-anjani.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2020-anjani" target="_blank">Why do people watch others eat food? An Empirical Study on the Motivations and Practices of Mukbang Viewers</a></h1><p class="meta"><span>Laurensia Anjani</span> , <a href="/people/terrance-mok"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/terrance-mok.jpg 1x" src="/pr-preview/pr-99/static/images/people/terrance-mok.jpg"/><strong>Terrance Mok</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <a href="/people/lora-oehlberg"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a> , <span>Wooi Boon Goh</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2020-anjani.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>chi-2020-anjani.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We present a mixed-methods study of viewers on their practices and motivations around watching mukbang — video streams of people eating large quantities of food. Viewers&#x27; experiences provide insight on future technologies for multisensorial video streams and technology-supported commensality (eating with others). We surveyed 104 viewers and interviewed 15 of them about their attitudes and reflections on their mukbang viewing habits, their physiological aspects of watching someone eat, and their perceived social relationship with mukbangers. Based on our findings, we propose design implications for remote commensality, and for synchronized multisensorial video streaming content.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Video Streams</span><span class="ui brown basic label">Mukbang</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Laurensia Anjani<!-- -->, <!-- -->Terrance Mok<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Wooi Boon Goh<!-- -->. <b>Why do people watch others eat food? An Empirical Study on the Motivations and Practices of Mukbang Viewers</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;20)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3313831.3376567" target="_blank">https://doi.org/10.1145/3313831.3376567</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/Dkp8A_em90M" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/Dkp8A_em90M?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/Dkp8A_em90M/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2019-seyed" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/dis-2019-seyed/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>dis-2019-seyed</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">DIS 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/dis-2019-seyed.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/dis-2019-seyed.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/dis-2019-seyed" target="_blank">Mannequette: Understanding and Enabling Collaboration and Creativity on Avant-Garde Fashion-Tech Runways</a></h1><p class="meta"><a href="/people/teddy-seyed"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/teddy-seyed.jpg 1x" src="/pr-preview/pr-99/static/images/people/teddy-seyed.jpg"/><strong>Teddy Seyed</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/dis-2019-seyed.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>dis-2019-seyed.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>Drawing upon multiple disciplines, avant-garde fashion-tech teams push the boundaries between fashion and technology. Many are well trained in envisioning aesthetic qualities of garments, but few have formal training on designing and fabricating technologies themselves. We introduce Mannequette, a prototyping tool for fashion-tech garments that enables teams to experiment with interactive technologies at early stages of their design processes. Mannequette provides an abstraction of light-based outputs and sensor-based inputs for garments through a DJ mixer-like interface that allows for dynamic changes and recording/playback of visual effects. The base of Mannequette can also be incorporated into the final garment, where it is then connected to the final components. We conducted an 8-week deployment study with eight design teams who created new garments for a runway show. Our results revealed Mannequette allowed teams to repeatedly consider new design and technical options early in their creative processes, and to communicate more effectively across disciplinary backgrounds.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Fashion</span><span class="ui brown basic label">Haute Couture</span><span class="ui brown basic label">E Textiles</span><span class="ui brown basic label">Maker Culture</span><span class="ui brown basic label">Fashion Tech</span><span class="ui brown basic label">Wearables</span><span class="ui brown basic label">Avant Garde</span><span class="ui brown basic label">Haute Tech Couture</span><span class="ui brown basic label">Modular</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Teddy Seyed<!-- -->, <!-- -->Anthony Tang<!-- -->. <b>Mannequette: Understanding and Enabling Collaboration and Creativity on Avant-Garde Fashion-Tech Runways</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;19)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3322276.3322305" target="_blank">https://doi.org/10.1145/3322276.3322305</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="tei-2019-tolley" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/tei-2019-tolley/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>tei-2019-tolley</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">TEI 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/tei-2019-tolley.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/tei-2019-tolley.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/tei-2019-tolley" target="_blank">WindyWall: Exploring Creative Wind Simulations</a></h1><p class="meta"><span>David Tolley</span> , <span>Thi Ngoc Tram Nguyen</span> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <span>Nimesha Ranasinghe</span> , <span>Kensaku Kawauchi</span> , <span>Ching-Chiuan Yen</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/tei-2019-tolley.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>tei-2019-tolley.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/Tn11UmsOsTE" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/Tn11UmsOsTE?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/Tn11UmsOsTE/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Wind simulations are typically one-off implementations for specific applications. We introduce WindyWall, a platform for creative design and exploration of wind simulations. WindyWall is a three-panel 90-fan array that encapsulates users with 270? of wind coverage. We describe the design and implementation of the array panels, discussing how the panels can be re-arranged, where various wind simulations can be realized as simple effects. To understand how people perceive &quot;wind&quot; generated from WindyWall, we conducted a pilot study of wind magnitude perception using different wind activation patterns from WindyWall. Our findings suggest that: horizontal wind activations are perceived more readily than vertical ones, and that people&#x27;s perceptions of wind are highly variable-most individuals will rate airflow differently in subsequent exposures. Based on our findings, we discuss the importance of developing a method for characterizing wind simulations, and provide design directions for others using fan arrays to simulate wind.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Tactile Haptic Interaction</span><span class="ui brown basic label">Multimodal Interaction</span><span class="ui brown basic label">Novel Actuators Displays</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">David Tolley<!-- -->, <!-- -->Thi Ngoc Tram Nguyen<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Nimesha Ranasinghe<!-- -->, <!-- -->Kensaku Kawauchi<!-- -->, <!-- -->Ching-Chiuan Yen<!-- -->. <b>WindyWall: Exploring Creative Wind Simulations</b>. <i>In Proceedings of the International Conference on Tangible, Embedded, and Embodied Interaction (TEI &#x27;19)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="https://doi.org/10.1145/3294109.3295624" target="_blank">https://doi.org/10.1145/3294109.3295624</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2018-pham" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/dis-2018-pham/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>dis-2018-pham</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">DIS 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/dis-2018-pham.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/dis-2018-pham.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/dis-2018-pham" target="_blank">Scale Impacts Elicited Gestures for Manipulating Holograms: Implications for AR Gesture Design</a></h1><p class="meta"><span>Tran Pham</span> , <span>Jo Vermeulen</span> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <span>Lindsay MacDonald Vermeulen</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/dis-2018-pham.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>dis-2018-pham.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>Because gesture design for augmented reality (AR) remains idiosyncratic, people cannot necessarily use gestures learned in one AR application in another. To design discoverable gestures, we need to understand what gestures people expect to use. We explore how the scale of AR affects the gestures people expect to use to interact with 3D holograms. Using an elicitation study, we asked participants to generate gestures in response to holographic task referents, where we varied the scale of holograms from desktop-scale to room-scale objects. We found that the scale of objects and scenes in the AR experience moderates the generated gestures. Most gestures were informed by physical interaction, and when people interacted from a distance, they sought a good perspective on the target object before and during the interaction. These results suggest that gesture designers need to account for scale, and should not simply reuse gestures across different hologram sizes.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Gestures</span><span class="ui brown basic label">Gesture Elicitation</span><span class="ui brown basic label">Hololens</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Tran Pham<!-- -->, <!-- -->Jo Vermeulen<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Lindsay MacDonald Vermeulen<!-- -->. <b>Scale Impacts Elicited Gestures for Manipulating Holograms: Implications for AR Gesture Design</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->14<!-- -->.  DOI: <a href="https://doi.org/10.1145/3196709.3196719" target="_blank">https://doi.org/10.1145/3196709.3196719</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2018-dillman" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/chi-2018-dillman/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>chi-2018-dillman</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2018-dillman.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2018-dillman.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2018-dillman" target="_blank">A Visual Interaction Cue Framework from Video Game Environments for Augmented Reality</a></h1><p class="meta"><span>Kody R. Dillman</span> , <a href="/people/terrance-mok"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/terrance-mok.jpg 1x" src="/pr-preview/pr-99/static/images/people/terrance-mok.jpg"/><strong>Terrance Mok</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <a href="/people/lora-oehlberg"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a> , <span>Alex Mitchell</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2018-dillman.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>chi-2018-dillman.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>Based on an analysis of 49 popular contemporary video games, we develop a descriptive framework of visual interaction cues in video games. These cues are used to inform players what can be interacted with, where to look, and where to go within the game world. These cues vary along three dimensions: the purpose of the cue, the visual design of the cue, and the circumstances under which the cue is shown. We demonstrate that this framework can also be used to describe interaction cues for augmented reality applications. Beyond this, we show how the framework can be used to generatively derive new design ideas for visual interaction cues in augmented reality experiences.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Game Design</span><span class="ui brown basic label">Guidance</span><span class="ui brown basic label">Interaction Cues</span><span class="ui brown basic label">Augmented Reality</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kody R. Dillman<!-- -->, <!-- -->Terrance Mok<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Alex Mitchell<!-- -->. <b>A Visual Interaction Cue Framework from Video Game Environments for Augmented Reality</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173574.3173714" target="_blank">https://doi.org/10.1145/3173574.3173714</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/3FoZStToALQ" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/3FoZStToALQ?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/3FoZStToALQ/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2018-feick" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/chi-2018-feick/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>chi-2018-feick</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2018-feick.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2018-feick.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2018-feick" target="_blank">Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration</a></h1><p class="meta"><a href="/people/martin-feick"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/martin-feick.jpg 1x" src="/pr-preview/pr-99/static/images/people/martin-feick.jpg"/><strong>Martin Feick</strong></a> , <span>Terrance Tin Hoi Mok</span> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <a href="/people/lora-oehlberg"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a> , <a href="/people/ehud-sharlin"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2018-feick.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>chi-2018-feick.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/sfxTHsPJWHY" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/sfxTHsPJWHY?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/sfxTHsPJWHY/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Remote collaborators working together on physical objects have difficulty building a shared understanding of what each person is talking about. Conventional video chat systems are insufficient for many situations because they present a single view of the object in a flattened image. To understand how this limited perspective affects collaboration, we designed the Remote Manipulator (ReMa), which can reproduce orientation manipulations on a proxy object at a remote site. We conducted two studies with ReMa, with two main findings. First, a shared perspective is more effective and preferred compared to the opposing perspective offered by conventional video chat systems. Second, the physical proxy and video chat complement one another in a combined system: people used the physical proxy to understand objects, and used video chat to perform gestures and confirm remote actions.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Object Focused Collaboration</span><span class="ui brown basic label">Physical Telepresence</span><span class="ui brown basic label">Collaborative Physical Tasks</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Martin Feick<!-- -->, <!-- -->Terrance Tin Hoi Mok<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173574.3173855" target="_blank">https://doi.org/10.1145/3173574.3173855</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2018-heshmat" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/chi-2018-heshmat/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>chi-2018-heshmat</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2018-heshmat.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2018-heshmat.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2018-heshmat" target="_blank">Geocaching with a Beam: Shared Outdoor Activities through a Telepresence Robot with 360 Degree Viewing</a></h1><p class="meta"><span>Yasamin Heshmat</span> , <a href="/people/brennan-jones"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/brennan-jones.jpg 1x" src="/pr-preview/pr-99/static/images/people/brennan-jones.jpg"/><strong>Brennan Jones</strong></a> , <span>Xiaoxuan Xiong</span> , <a href="/people/carman-neustaedter"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg 1x" src="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg"/><strong>Carman Neustaedter</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <span>Bernhard E. Riecke</span> , <span>Lillian Yang</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2018-heshmat.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>chi-2018-heshmat.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>People often enjoy sharing outdoor activities together such as walking and hiking. However, when family and friends are separated by distance it can be difficult if not impossible to share such activities. We explore this design space by investigating the benefits and challenges of using a telepresence robot to support outdoor leisure activities. In our study, participants participated in the outdoor activity of geocaching where one person geocached with the help of a remote partner via a telepresence robot. We compared a wide field of view (WFOV) camera to a 360° camera. Results show the benefits of having a physical embodiment and a sense of immersion with the 360° view. Yet challenges related to a lack of environmental awareness, safety issues, and privacy concerns resulting from bystander interactions. These findings illustrate the need to design telepresence robots with the environment and public in mind to provide an enhanced sensory experience while balancing safety and privacy issues resulting from being amongst the general public.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Video Communication</span><span class="ui brown basic label">Telepresence Robots</span><span class="ui brown basic label">Leisure Activities</span><span class="ui brown basic label">Social Presence</span><span class="ui brown basic label">Geocaching</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Yasamin Heshmat<!-- -->, <!-- -->Brennan Jones<!-- -->, <!-- -->Xiaoxuan Xiong<!-- -->, <!-- -->Carman Neustaedter<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Bernhard E. Riecke<!-- -->, <!-- -->Lillian Yang<!-- -->. <b>Geocaching with a Beam: Shared Outdoor Activities through a Telepresence Robot with 360 Degree Viewing</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173574.3173933" target="_blank">https://doi.org/10.1145/3173574.3173933</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2018-wuertz" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/chi-2018-wuertz/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>chi-2018-wuertz</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2018-wuertz.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2018-wuertz.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2018-wuertz" target="_blank">A Design Framework for Awareness Cues in Distributed Multiplayer Games</a></h1><p class="meta"><span>Jason Wuertz</span> , <span>Sultan A. Alharthi</span> , <span>William A. Hamilton</span> , <span>Scott Bateman</span> , <a href="/people/carl-gutwin"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/carl-gutwin.jpg 1x" src="/pr-preview/pr-99/static/images/people/carl-gutwin.jpg"/><strong>Carl Gutwin</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <span>Zachary O. Toups</span> , <span>Jessica Hammer</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2018-wuertz.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>chi-2018-wuertz.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>In the physical world, teammates develop situation awareness about each other&#x27;s location, status, and actions through cues such as gaze direction and ambient noise. To support situation awareness, distributed multiplayer games provide awareness cues - information that games automatically make available to players to support cooperative gameplay. The design of awareness cues can be extremely complex, impacting how players experience games and work with teammates. Despite the importance of awareness cues, designers have little beyond experiential knowledge to guide their design. In this work, we describe a design framework for awareness cues, providing insight into what information they provide, how they communicate this information, and how design choices can impact play experience. Our research, based on a grounded theory analysis of current games, is the first to provide a characterization of awareness cues, providing a palette for game designers to improve design practice and a starting point for deeper research into collaborative play.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Workspace Awareness</span><span class="ui brown basic label">Situation Awareness</span><span class="ui brown basic label">Game Design</span><span class="ui brown basic label">Distributed Multiplayer Games</span><span class="ui brown basic label">Awareness Cues</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Jason Wuertz<!-- -->, <!-- -->Sultan A. Alharthi<!-- -->, <!-- -->William A. Hamilton<!-- -->, <!-- -->Scott Bateman<!-- -->, <!-- -->Carl Gutwin<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Zachary O. Toups<!-- -->, <!-- -->Jessica Hammer<!-- -->. <b>A Design Framework for Awareness Cues in Distributed Multiplayer Games</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->14<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173574.3173817" target="_blank">https://doi.org/10.1145/3173574.3173817</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="hri-2018-feick" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/hri-2018-feick/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>hri-2018-feick</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">HRI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/hri-2018-feick.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/hri-2018-feick.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/hri-2018-feick" target="_blank">The Way You Move: The Effect of a Robot Surrogate Movement in Remote Collaboration</a></h1><p class="meta"><a href="/people/martin-feick"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/martin-feick.jpg 1x" src="/pr-preview/pr-99/static/images/people/martin-feick.jpg"/><strong>Martin Feick</strong></a> , <a href="/people/lora-oehlberg"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <span>André Miede</span> , <a href="/people/ehud-sharlin"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/hri-2018-feick.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>hri-2018-feick.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>In this paper, we discuss the role of the movement trajectory and velocity enabled by our tele-robotic system (ReMa) for remote collaboration on physical tasks. Our system reproduces changes in object orientation and position at a remote location using a humanoid robotic arm. However, even minor kinematics differences between robot and human arm can result in awkward or exaggerated robot movements. As a result, user communication with the robotic system can become less efficient, less fluent and more time intensive.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Movement Trajectory Velocity</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Robot Surrogate</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Martin Feick<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->André Miede<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>The Way You Move: The Effect of a Robot Surrogate Movement in Remote Collaboration</b>. <i>In Adjunct Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction (HRI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->2<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173386.3176959" target="_blank">https://doi.org/10.1145/3173386.3176959</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2016-jones" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/dis-2016-jones/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>dis-2016-jones</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">DIS 2016</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/dis-2016-jones.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/dis-2016-jones.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/dis-2016-jones" target="_blank">Elevating Communication, Collaboration, and Shared Experiences in Mobile Video through Drones</a></h1><p class="meta"><a href="/people/brennan-jones"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/brennan-jones.jpg 1x" src="/pr-preview/pr-99/static/images/people/brennan-jones.jpg"/><strong>Brennan Jones</strong></a> , <span>Kody Dillman</span> , <span>Richard Tang</span> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <a href="/people/ehud-sharlin"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-99/static/images/people/ehud-sharlin.jpg"/><strong>Ehud Sharlin</strong></a> , <a href="/people/lora-oehlberg"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-99/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a> , <a href="/people/carman-neustaedter"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg 1x" src="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg"/><strong>Carman Neustaedter</strong></a> , <span>Scott Bateman</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/dis-2016-jones.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>dis-2016-jones.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/10hbJHIQVX8" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/10hbJHIQVX8?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/10hbJHIQVX8/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>People are increasingly using mobile video to communicate, collaborate, and share experiences while on the go. Yet this presents challenges in adequately sharing camera views with remote users. In this paper, we study the use of semi-autonomous drones for video conferencing, where an outdoor user (using a smartphone) is connected to a desktop user who can explore the environment from the drone&#x27;s perspective. We describe findings from a study where pairs collaborated to complete shared navigation and search tasks. We illustrate the benefits of providing the desktop user with a view that is elevated, manipulable, and decoupled from the outdoor user. In addition, we articulate how participants overcame challenges in communicating environmental information and navigational cues, negotiated control of the view, and used the drone as a tool for sharing experiences. This provides a new way of thinking about mobile video conferencing where cameras that are decoupled from both users play an integral role in communication, collaboration, and sharing experiences.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Telepresence</span><span class="ui brown basic label">Video Communication</span><span class="ui brown basic label">Shared Experiences</span><span class="ui brown basic label">Teleoperation</span><span class="ui brown basic label">Drones</span><span class="ui brown basic label">Collaboration</span><span class="ui brown basic label">Hri</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Brennan Jones<!-- -->, <!-- -->Kody Dillman<!-- -->, <!-- -->Richard Tang<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Carman Neustaedter<!-- -->, <!-- -->Scott Bateman<!-- -->. <b>Elevating Communication, Collaboration, and Shared Experiences in Mobile Video through Drones</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;16)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/2901790.2901847" target="_blank">https://doi.org/10.1145/2901790.2901847</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2015-aseniero" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/chi-2015-aseniero/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>chi-2015-aseniero</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI 2015</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2015-aseniero.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2015-aseniero.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2015-aseniero" target="_blank">Stratos: Using Visualization to Support Decisions in Strategic Software Release Planning</a></h1><p class="meta"><a href="/people/bon-adriel-aseniero"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/bon-adriel-aseniero.jpg 1x" src="/pr-preview/pr-99/static/images/people/bon-adriel-aseniero.jpg"/><strong>Bon Adriel Aseniero</strong></a> , <span>Tiffany Wun</span> , <a href="/people/david-ledo"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/david-ledo.jpg 1x" src="/pr-preview/pr-99/static/images/people/david-ledo.jpg"/><strong>David Ledo</strong></a> , <span>Guenther Ruhe</span> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a> , <a href="/people/sheelagh-carpendale"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/sheelagh-carpendale.jpg 1x" src="/pr-preview/pr-99/static/images/people/sheelagh-carpendale.jpg"/><strong>Sheelagh Carpendale</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2015-aseniero.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>chi-2015-aseniero.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/qm57aHjTAYc" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/qm57aHjTAYc?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/qm57aHjTAYc/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Software is typically developed incrementally and released in stages. Planning these releases involves deciding which features of the system should be implemented for each release. This is a complex planning process involving numerous trade-offs-constraints and factors that often make decisions difficult. Since the success of a product depends on this plan, it is important to understand the trade-offs between different release plans in order to make an informed choice. We present STRATOS, a tool that simultaneously visualizes several software release plans. The visualization shows several attributes about each plan that are important to planners. Multiple plans are shown in a single layout to help planners find and understand the trade-offs between alternative plans. We evaluated our tool via a qualitative study and found that STRATOS enables a range of decision-making processes, helping participants decide on which plan is most optimal.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Software Engineering</span><span class="ui brown basic label">Information Visualization</span><span class="ui brown basic label">Release Planning</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Bon Adriel Aseniero<!-- -->, <!-- -->Tiffany Wun<!-- -->, <!-- -->David Ledo<!-- -->, <!-- -->Guenther Ruhe<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Sheelagh Carpendale<!-- -->. <b>Stratos: Using Visualization to Support Decisions in Strategic Software Release Planning</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;15)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="https://doi.org/10.1145/2702123.2702426" target="_blank">https://doi.org/10.1145/2702123.2702426</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2015-jones" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-99/publications/chi-2015-jones/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>chi-2015-jones</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-99/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI 2015</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/publications/cover/chi-2015-jones.jpg 1x" src="/pr-preview/pr-99/static/images/publications/cover/chi-2015-jones.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2015-jones" target="_blank">Mechanics of Camera Work in Mobile Video Collaboration</a></h1><p class="meta"><a href="/people/brennan-jones"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/brennan-jones.jpg 1x" src="/pr-preview/pr-99/static/images/people/brennan-jones.jpg"/><strong>Brennan Jones</strong></a> , <span>Anna Witcraft</span> , <span>Scott Bateman</span> , <a href="/people/carman-neustaedter"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg 1x" src="/pr-preview/pr-99/static/images/people/carman-neustaedter.jpg"/><strong>Carman Neustaedter</strong></a> , <a href="/people/anthony-tang"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-99/static/images/people/anthony-tang.jpg 1x" src="/pr-preview/pr-99/static/images/people/anthony-tang.jpg"/><strong>Anthony Tang</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2015-jones.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>chi-2015-jones.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/V133YGkLxC8" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/V133YGkLxC8?autoplay=1&gt;&lt;Image width={0} height={0} src=https://img.youtube.com/vi/V133YGkLxC8/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Mobile video conferencing, where one or more participants are moving about in the real world, enables entirely new interaction scenarios (e.g., asking for help to construct or repair an object, or showing a physical location). While we have a good understanding of the challenges of video conferencing in office or home environments, we do not fully understand the mechanics of camera work-how people use mobile devices to communicate with one another-during mobile video calls. To provide an understanding of what people do in mobile video collaboration, we conducted an observational study where pairs of participants completed tasks using a mobile video conferencing system. Our analysis suggests that people use the camera view deliberately to support their interactions-for example, to convey a message or to ask questions-but the limited field of view, and the lack of camera control can make it a frustrating experience.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Video Communication</span><span class="ui brown basic label">Collaboration</span><span class="ui brown basic label">Mobile Computing</span><span class="ui brown basic label">Handheld Devices</span><span class="ui brown basic label">Cscw</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Brennan Jones<!-- -->, <!-- -->Anna Witcraft<!-- -->, <!-- -->Scott Bateman<!-- -->, <!-- -->Carman Neustaedter<!-- -->, <!-- -->Anthony Tang<!-- -->. <b>Mechanics of Camera Work in Mobile Video Collaboration</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;15)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->10<!-- -->.  DOI: <a href="https://doi.org/10.1145/2702123.2702345" target="_blank">https://doi.org/10.1145/2702123.2702345</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div></div></div></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img loading="lazy" width="180" height="0" decoding="async" data-nimg="1" style="color:transparent;max-width:180px;margin:30px auto;height:auto" srcSet="/pr-preview/pr-99/static/images/logo-6.png 1x, /pr-preview/pr-99/static/images/logo-6.png 2x" src="/pr-preview/pr-99/static/images/logo-6.png"/><div class="content"><img loading="lazy" width="200" height="0" decoding="async" data-nimg="1" style="color:transparent;max-width:200px;margin:0px auto;height:auto" srcSet="/pr-preview/pr-99/static/images/logo-4.png 1x, /pr-preview/pr-99/static/images/logo-4.png 2x" src="/pr-preview/pr-99/static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"person":{"name":"Anthony Tang","type":"faculty","title":"Adjunct Associate Professor (Singapore Management University)","keywords":["Mixed Reality","CSCW"],"order":12,"url":"https://hcitang.github.io/","scholar":"https://scholar.google.com/citations?user=RG1EQowAAAAJ","twitter":"https://twitter.com/proclubboy","github":"http://github.com/hcitang","dir":"content/output/people","base":"anthony-tang.json","ext":".json","sourceBase":"anthony-tang.yaml","sourceExt":".yaml","photo":"/static/images/people/anthony-tang.jpg"}},"__N_SSG":true},"page":"/people/[id]","query":{"id":"anthony-tang"},"buildId":"-5mA34hSgvPPCQ_3JIeXx","assetPrefix":"/pr-preview/pr-99","runtimeConfig":{"basePath":"/pr-preview/pr-99"},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link rel="preload" href="/pr-preview/pr-138/_next/static/media/dc84b505c4b06e35-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/pr-preview/pr-138/_next/static/css/983cdb9cbcda2fe3.css" as="style"/><link rel="preload" href="/pr-preview/pr-138/_next/static/css/a1a0497113412518.css" as="style"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              // $('.ui.sidebar')
              //   .sidebar('attach events', '.sidebar.icon')

              $('.sidebar.icon').on('click', function(event) {
                $('.ui.sidebar')
                  .sidebar('toggle')
              })

              $('.project').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })

              $('.thesis').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><link rel="stylesheet" href="/pr-preview/pr-138/_next/static/css/983cdb9cbcda2fe3.css" data-n-g=""/><link rel="stylesheet" href="/pr-preview/pr-138/_next/static/css/a1a0497113412518.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/pr-preview/pr-138/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/pr-preview/pr-138/_next/static/chunks/webpack-09ad242dd996c7e7.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/chunks/340-b961b0d36fb587f8.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/chunks/main-237fefe93cf728ed.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/chunks/vendor-styles-26b30cb322f4d5ea.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/chunks/505-e272acec7cef31c2.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/chunks/pages/_app-ef1f9bbf0259e57f.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/chunks/347-501ace96f6678428.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/chunks/590-edd344c6a3068387.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/chunks/pages/theses-5c3cc556a89eadad.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/m3G8uuA_V8lxnhHa11BBF/_buildManifest.js" defer=""></script><script src="/pr-preview/pr-138/_next/static/m3G8uuA_V8lxnhHa11BBF/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_bae0a2"><div class="ui center aligned container"><div class="ui secondary huge compact menu"><a class="item" href="/pr-preview/pr-138/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui tiny image" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/ilab-logo-3d.gif 1x" src="/pr-preview/pr-138/static/images/ilab-logo-3d.gif"/></a><a class="item" href="/pr-preview/pr-138/people/">People</a><a class="item" href="/pr-preview/pr-138/publications/">Research</a></div></div><div id="theses" class="category ui container"><h1 class="ui horizontal divider header"><svg data-prefix="far" data-icon="file-lines" class="svg-inline--fa fa-file-lines" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M64 48l112 0 0 88c0 39.8 32.2 72 72 72l88 0 0 240c0 8.8-7.2 16-16 16L64 464c-8.8 0-16-7.2-16-16L48 64c0-8.8 7.2-16 16-16zM224 67.9l92.1 92.1-68.1 0c-13.3 0-24-10.7-24-24l0-68.1zM64 0C28.7 0 0 28.7 0 64L0 448c0 35.3 28.7 64 64 64l256 0c35.3 0 64-28.7 64-64l0-261.5c0-17-6.7-33.3-18.7-45.3L242.7 18.7C230.7 6.7 214.5 0 197.5 0L64 0zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24l144 0c13.3 0 24-10.7 24-24s-10.7-24-24-24l-144 0zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24l144 0c13.3 0 24-10.7 24-24s-10.7-24-24-24l-144 0z"></path></svg>Theses</h1><div class="ui segment" style="margin-top:50px"><div class="thesis ui vertical segment stackable grid" data-id="msc-2025-roy"><div class="three wide column" style="margin:auto"></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">Roy MSc 2025</span></p><p class="color" style="font-size:1.3em"><b>Engineering and Validating Soft Sensors for Interactive and Biomedical Applications</b></p><p><a href="/pr-preview/pr-138/people/sutirtha-roy/"><img alt="Sutirtha Roy picture" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/sutirtha-roy.jpg 1x" src="/pr-preview/pr-138/static/images/people/sutirtha-roy.jpg"/><span class="author-link">Sutirtha Roy</span></a><span class="role"> (author)</span>, <span>Richa Pandey</span><span class="role"> (advisor)</span>, <a href="/pr-preview/pr-138/people/aditya-shekhar-nittala/"><img alt="Aditya Nittala picture" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg 1x" src="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg"/><span class="author-link">Aditya Nittala</span></a><span class="role"> (advisor)</span>, <span>Kangsoo Kim</span><span class="role"> (committee)</span>, <a href="/pr-preview/pr-138/people/fateme-rajabiyazdi/"><img alt="Fateme Rajabiyazdi picture" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/fateme-rajabiyazdi.jpg 1x" src="/pr-preview/pr-138/static/images/people/fateme-rajabiyazdi.jpg"/><span class="author-link">Fateme Rajabiyazdi</span></a><span class="role"> (committee)</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">On Body Interaction</span><span class="ui brown basic label">Epidermal Interfaces</span><span class="ui brown basic label">Wearables</span><span class="ui brown basic label">Haptics</span><span class="ui brown basic label">Physiological Sensing</span><span class="ui brown basic label">Electrochemical Sensing</span><span class="ui brown basic label">Touch Sensing</span><span class="ui brown basic label">Deformation Sensing</span><span class="ui brown basic label">Soft Materials</span></div></div></div></div><div class="thesis ui vertical segment stackable grid" data-id="msc-2025-sandykbayeva"><div class="three wide column" style="margin:auto"></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">Sandykbayeva MSc 2025</span></p><p class="color" style="font-size:1.3em"><b>Combining Optical and Vibrational Tactile Sensing for Pre-emptive Grip Force Modulation in Robotic Grasping</b></p><p><a href="/pr-preview/pr-138/people/danissa-sandykbayeva/"><img alt="Danissa Sandykbayeva picture" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/danissa-sandykbayeva.jpg 1x" src="/pr-preview/pr-138/static/images/people/danissa-sandykbayeva.jpg"/><span class="author-link">Danissa Sandykbayeva</span></a><span class="role"> (author)</span>, <a href="/pr-preview/pr-138/people/aditya-shekhar-nittala/"><img alt="Aditya Shekhar Nittala picture" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg 1x" src="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg"/><span class="author-link">Aditya Shekhar Nittala</span></a><span class="role"> (advisor)</span>, <a href="/pr-preview/pr-138/people/ehud-sharlin/"><img alt="Ehud Sharlin picture" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-138/static/images/people/ehud-sharlin.jpg"/><span class="author-link">Ehud Sharlin</span></a><span class="role"> (committee)</span>, <span>Marie Charbonneau</span><span class="role"> (committee)</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Tactile Robotics</span><span class="ui brown basic label">Tactile Sensors</span><span class="ui brown basic label">Optical Sensors</span><span class="ui brown basic label">Vibrational Sensors</span><span class="ui brown basic label">Robotic Grasping</span></div></div></div></div><div class="thesis ui vertical segment stackable grid" data-id="msc-2025-mukashev"><div class="three wide column" style="margin:auto"></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">Mukashev MSc 2025</span></p><p class="color" style="font-size:1.3em"><b>Electrotactile Tongue Interface for Human-Computer Interaction and Robot Teleoperation</b></p><p><a href="/pr-preview/pr-138/people/dinmukhammed-mukashev/"><img alt="Dinmukhammed Mukashev picture" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/dinmukhammed-mukashev.jpg 1x" src="/pr-preview/pr-138/static/images/people/dinmukhammed-mukashev.jpg"/><span class="author-link">Dinmukhammed Mukashev</span></a><span class="role"> (author)</span>, <a href="/pr-preview/pr-138/people/aditya-shekhar-nittala/"><img alt="Aditya Nittala picture" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg 1x" src="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg"/><span class="author-link">Aditya Nittala</span></a><span class="role"> (advisor)</span>, <span>Park Junho</span><span class="role"> (committee)</span></p><div><div class="ui large basic labels"><span class="ui brown basic label">Haptics</span><span class="ui brown basic label">Robotics</span><span class="ui brown basic label">Sensory Substitution</span><span class="ui brown basic label">Tongue Interface</span><span class="ui brown basic label">Electrotactile</span></div></div></div></div></div><div id="theses-modal"><div id="msc-2025-roy" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-138/theses/msc-2025-roy/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>msc-2025-roy</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="thesis"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-138/thesiss/">Thesis</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">Roy MSc 2025</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"></div><div class="thirteen wide column"><h1><a href="/thesiss/msc-2025-roy" target="_blank">Engineering and Validating Soft Sensors for Interactive and Biomedical Applications</a></h1><p class="meta"><a href="/people/sutirtha-roy"><img alt="sutirtha-roy photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/sutirtha-roy.jpg 1x" src="/pr-preview/pr-138/static/images/people/sutirtha-roy.jpg"/><strong>Sutirtha Roy</strong></a><span class="role"> (author)</span>, <span>Richa Pandey<!-- --> <span class="role"> (advisor)</span></span>, <a href="/people/aditya-shekhar-nittala"><img alt="aditya-shekhar-nittala photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg 1x" src="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg"/><strong>Aditya Nittala</strong></a><span class="role"> (advisor)</span>, <span>Kangsoo Kim<!-- --> <span class="role"> (committee)</span></span>, <a href="/people/fateme-rajabiyazdi"><img alt="fateme-rajabiyazdi photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/fateme-rajabiyazdi.jpg 1x" src="/pr-preview/pr-138/static/images/people/fateme-rajabiyazdi.jpg"/><strong>Fateme Rajabiyazdi</strong></a><span class="role"> (committee)</span></p></div></div></div><div class="block"><h1>Abstract</h1><p>Soft materials such as foams and textiles offer exciting opportunities for creating interactive devices that seamlessly integrate electronics into wearable, comfortable, and deformable forms. However, imparting elec-tronic functionality into these materials while preserving their inherent softness, breathability, and flexibility remains a significant challenge, especially when aiming for precise device patterning using accessible, low-cost fabrication techniques. This thesis addresses these challenges by introducing two novel platforms, FabFoam and rGOSense, that enable multi-functional sensing and interactive applications on soft substrates. FabFoam presents a scalable stencil-printing approach to pattern highly viscous functional inks directly onto foam substrates. This technique preserves the foam’s softness and elasticity while enabling the cre-ation of precise electrode designs for deformation sensing, touch input, electrotactile haptics, and on-body biochemical sensing. FabFoam’s sensors achieved signal-to-noise ratios (SNR) of approximately 34 for touch sensing and 25 for deformation across all inks, demonstrating reliable performance for interactive applica-tions. Electrochemical characterization showed that FabFoam’s sweat glucose sensor achieved a sensitivity of 2.74 μA/μM and a detection limit of 4.67 μM, confirming its potential for non-invasive glucose monitoring in wearable formats. Complementing this, rGOSense introduces a reduced graphene oxide (rGO)-coated nonwoven polyester fabric platform that offers superhydrophilic surface properties while retaining the textile’s softness and breathability. The rGO-coated textile demonstrates surface conductivity of 1.7 × 104 Ω/sq, which is about 2–10 times lower resistivity than several previously reported graphene- or carbon-based conductive textiles, enhancing electrical performance without compromising comfort. The rGOSense platform supports diverse sensing modalities, achieving SNR values of around 34 for touch sensing and approximately 26 for deformation sensing across multiple trials. Furthermore, its sweat glucose sensors achieved a sensitivity of 0.12 μA/μM<br/>and a detection limit of 0.47 μM, highlighting improved electrochemical performance suitable for practical wearable biosensing. Collectively, this thesis establishes accessible, low-cost fabrication workflows for integrating advanced sensing capabilities into soft materials, enabling new possibilities in wearable health monitoring, ubiquitous sensing, and human-computer interaction (HCI). Through systematic materials characterization, technical evaluations, and demonstrations of interactive scenarios, this work contributes significantly to the field of soft interactive devices by bridging material science innovations with practical HCI applications.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">On Body Interaction</span><span class="ui brown basic label">Epidermal Interfaces</span><span class="ui brown basic label">Wearables</span><span class="ui brown basic label">Haptics</span><span class="ui brown basic label">Physiological Sensing</span><span class="ui brown basic label">Electrochemical Sensing</span><span class="ui brown basic label">Touch Sensing</span><span class="ui brown basic label">Deformation Sensing</span><span class="ui brown basic label">Soft Materials</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Sutirtha Roy<!-- -->. <b>Engineering and Validating Soft Sensors for Interactive and Biomedical Applications</b>. <i></i> <!-- -->University of Calgary<!-- -->. <!-- -->Master of Science (MSc)<!-- -->. <!-- -->2025-09-09<!-- -->. <!-- -->DOI: <a href="https://dx.doi.org/10.11575/PRISM/50406" target="_blank">https://dx.doi.org/10.11575/PRISM/50406</a>URL: <a href="https://hdl.handle.net/1880/122812" target="_blank">https://hdl.handle.net/1880/122812</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="msc-2025-sandykbayeva" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-138/theses/msc-2025-sandykbayeva/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>msc-2025-sandykbayeva</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="thesis"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-138/thesiss/">Thesis</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">Sandykbayeva MSc 2025</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"></div><div class="thirteen wide column"><h1><a href="/thesiss/msc-2025-sandykbayeva" target="_blank">Combining Optical and Vibrational Tactile Sensing for Pre-emptive Grip Force Modulation in Robotic Grasping</a></h1><p class="meta"><a href="/people/danissa-sandykbayeva"><img alt="danissa-sandykbayeva photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/danissa-sandykbayeva.jpg 1x" src="/pr-preview/pr-138/static/images/people/danissa-sandykbayeva.jpg"/><strong>Danissa Sandykbayeva</strong></a><span class="role"> (author)</span>, <a href="/people/aditya-shekhar-nittala"><img alt="aditya-shekhar-nittala photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg 1x" src="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg"/><strong>Aditya Shekhar Nittala</strong></a><span class="role"> (advisor)</span>, <a href="/people/ehud-sharlin"><img alt="ehud-sharlin photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-138/static/images/people/ehud-sharlin.jpg"/><strong>Ehud Sharlin</strong></a><span class="role"> (committee)</span>, <span>Marie Charbonneau<!-- --> <span class="role"> (committee)</span></span></p></div></div></div><div class="block"><h1>Abstract</h1><p>The last decade marked an incredible leap not only in computer science and engineering but also by a natural extension - Human-Robot Interaction. Robots are continuously evolving to simplify day-to-day tasks and the complex computational and physical challenges. However, to confidently rely on safe and efficient interactions with robots, anywhere from personal to industrial settings, we first need to ensure the robots are well-equipped to explore these settings and interact with this shared environment. In this sense, optimizing and reverse-engineering such a seemingly simple yet incredibly sophisticated process of grasping is more essential than ever. This work explores various tactile sensing techniques and aims to combine them into an ultimately optimal grasping system. The first sensor, OptiFlux, introduced in the thesis, utilizes a simple principle of intentional light leakage within incised optical guides induced by bending or pressure. An extension of this principle is a compact and flexible optical sensor capable of sensing small changes in the applied force. The second sensing system uses vibrational waves to carry essential information about the physical properties of the object that enters the system. This object information, combined with the pressure sensitivity acquired with the optical sensor, expands into an easily scalable soft tactile sensing system, allowing the robot to safely manipulate the most fragile objects. Lastly, both systems are integrated visually and analytically into a common graphical user interface, providing substantial ground for more efficient data collection and independent system control. Corresponding experiments explore the performance of each system individually and combine and present an opportunity for a discussion of future improvements and prospects of the research. In the world of tactile robotics, considering the advantages and drawbacks of various sensing methods, multimodal sensing might bring us closer to equipping robots with sensing capabilities matching or perhaps exceeding our own, leading to safer robotics.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Tactile Robotics</span><span class="ui brown basic label">Tactile Sensors</span><span class="ui brown basic label">Optical Sensors</span><span class="ui brown basic label">Vibrational Sensors</span><span class="ui brown basic label">Robotic Grasping</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Danissa Sandykbayeva<!-- -->. <b>Combining Optical and Vibrational Tactile Sensing for Pre-emptive Grip Force Modulation in Robotic Grasping</b>. <i></i> <!-- -->University of Calgary<!-- -->. <!-- -->Master of Science (MSc)<!-- -->. <!-- -->2025-08-27<!-- -->. <!-- -->DOI: <a href="https://dx.doi.org/10.11575/PRISM/50249" target="_blank">https://dx.doi.org/10.11575/PRISM/50249</a>URL: <a href="https://hdl.handle.net/1880/122656" target="_blank">https://hdl.handle.net/1880/122656</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="msc-2025-mukashev" class="ui large modal"><div class="header"><a target="_blank" href="/pr-preview/pr-138/theses/msc-2025-mukashev/"><svg data-prefix="fas" data-icon="link" class="svg-inline--fa fa-link" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M419.5 96c-16.6 0-32.7 4.5-46.8 12.7-15.8-16-34.2-29.4-54.5-39.5 28.2-24 64.1-37.2 101.3-37.2 86.4 0 156.5 70 156.5 156.5 0 41.5-16.5 81.3-45.8 110.6l-71.1 71.1c-29.3 29.3-69.1 45.8-110.6 45.8-86.4 0-156.5-70-156.5-156.5 0-1.5 0-3 .1-4.5 .5-17.7 15.2-31.6 32.9-31.1s31.6 15.2 31.1 32.9c0 .9 0 1.8 0 2.6 0 51.1 41.4 92.5 92.5 92.5 24.5 0 48-9.7 65.4-27.1l71.1-71.1c17.3-17.3 27.1-40.9 27.1-65.4 0-51.1-41.4-92.5-92.5-92.5zM275.2 173.3c-1.9-.8-3.8-1.9-5.5-3.1-12.6-6.5-27-10.2-42.1-10.2-24.5 0-48 9.7-65.4 27.1L91.1 258.2c-17.3 17.3-27.1 40.9-27.1 65.4 0 51.1 41.4 92.5 92.5 92.5 16.5 0 32.6-4.4 46.7-12.6 15.8 16 34.2 29.4 54.6 39.5-28.2 23.9-64 37.2-101.3 37.2-86.4 0-156.5-70-156.5-156.5 0-41.5 16.5-81.3 45.8-110.6l71.1-71.1c29.3-29.3 69.1-45.8 110.6-45.8 86.6 0 156.5 70.6 156.5 156.9 0 1.3 0 2.6 0 3.9-.4 17.7-15.1 31.6-32.8 31.2s-31.6-15.1-31.2-32.8c0-.8 0-1.5 0-2.3 0-33.7-18-63.3-44.8-79.6z"></path></svg>msc-2025-mukashev</a><div class="actions" style="float:right;cursor:pointer;color:grey"><svg data-prefix="fas" data-icon="xmark" class="svg-inline--fa fa-xmark" role="img" viewBox="0 0 384 512" aria-hidden="true"><path fill="currentColor" d="M55.1 73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L147.2 256 9.9 393.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0L192.5 301.3 329.9 438.6c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L237.8 256 375.1 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192.5 210.7 55.1 73.4z"></path></svg></div></div><div class="content"><div id="thesis"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-138/thesiss/">Thesis</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">Mukashev MSc 2025</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"></div><div class="thirteen wide column"><h1><a href="/thesiss/msc-2025-mukashev" target="_blank">Electrotactile Tongue Interface for Human-Computer Interaction and Robot Teleoperation</a></h1><p class="meta"><a href="/people/dinmukhammed-mukashev"><img alt="dinmukhammed-mukashev photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/dinmukhammed-mukashev.jpg 1x" src="/pr-preview/pr-138/static/images/people/dinmukhammed-mukashev.jpg"/><strong>Dinmukhammed Mukashev</strong></a><span class="role"> (author)</span>, <a href="/people/aditya-shekhar-nittala"><img alt="aditya-shekhar-nittala photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg 1x" src="/pr-preview/pr-138/static/images/people/aditya-shekhar-nittala.jpg"/><strong>Aditya Nittala</strong></a><span class="role"> (advisor)</span>, <span>Park Junho<!-- --> <span class="role"> (committee)</span></span></p></div></div></div><div class="block"><h1>Abstract</h1><p>By exploiting the tongue’s exceptional density of nerve endings and low-threshold electrical response, electrotactile tongue displays provide a precise, low-power sensory-substitution pathway for teleoperated robotic systems. This approach addresses the persistent lack of effective haptic sensation in Robot Assisted Surgery (RAS) which recognized as a critical limitation. In this thesis, we introduce TactTongue, a modular electrotactile tongue-display toolkit with a simplified high-level user interface for rapid prototyping of electrotactile tongue stimulation (ETS). Building on previous works that informed the design of a flexible electrotactile tongue display, we investigate: (1) the efficacy of ETS for delivering force feedback during teleoperated manipulation tasks; (2) the design requirements and user-interface (UI) design to support rapid prototyping; (3) the potential for tongue-gesture input and applications; and (4) how tongue-based feedback can be compared to kinesthetic haptics during robot-assisted needle-insertion task. First, we evaluated ETS in an egg-lifting teleoperation task under visual-only and tongue-stimulation conditions, demonstrating potential or higher control accuracy with tongue feedback compared to vision alone. Building on these results, we refined the hardware and UI into a compact, modular TactTongue toolkit that lowers entry barriers for both researchers and practitioners. Moreover, we show a diverse set of application demonstrators—from accessibility aids with touch input and medical‐surgery overlays to extended‐reality, taste and texture rendering—highlighting the platform’s versatility beyond the force feedback. Drawing on insights from these early studies, in ongoing work, we explore integration of electrotactile tongue stimulation with kinesthetic haptic device to enhance force perception during robot assisted needle insertion in soft tissue. These findings validate TactTongue’s design, establish UI guidelines for rapid prototyping of tongue-based interfaces, and suggest a promising multimodal feedback paradigm for preciser RAS.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Haptics</span><span class="ui brown basic label">Robotics</span><span class="ui brown basic label">Sensory Substitution</span><span class="ui brown basic label">Tongue Interface</span><span class="ui brown basic label">Electrotactile</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Dinmukhammed Mukashev<!-- -->. <b>Electrotactile Tongue Interface for Human-Computer Interaction and Robot Teleoperation</b>. <i></i> <!-- -->University of Calgary<!-- -->. <!-- -->Master of Science (MSc)<!-- -->. <!-- -->2025-07-04<!-- -->. <!-- -->DOI: <a href="https://dx.doi.org/10.11575/PRISM/49895" target="_blank">https://dx.doi.org/10.11575/PRISM/49895</a>URL: <a href="https://hdl.handle.net/1880/122303" target="_blank">https://hdl.handle.net/1880/122303</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><div class="content"><a href="https://ucalgary.ca"><img alt="University of Calgary logo" loading="lazy" width="200" height="0" decoding="async" data-nimg="1" style="color:transparent;max-width:200px;margin:0px auto;height:auto" srcSet="/pr-preview/pr-138/static/images/logo-4.png 1x, /pr-preview/pr-138/static/images/logo-4.png 2x" src="/pr-preview/pr-138/static/images/logo-4.png"/></a><div class="sub header"><a class="item" href="https://cpsc.ucalgary.ca">Department of Computer Science</a></div></div></div></footer></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{},"__N_SSG":true},"page":"/theses","query":{},"buildId":"m3G8uuA_V8lxnhHa11BBF","assetPrefix":"/pr-preview/pr-138","runtimeConfig":{"basePath":"/pr-preview/pr-138"},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
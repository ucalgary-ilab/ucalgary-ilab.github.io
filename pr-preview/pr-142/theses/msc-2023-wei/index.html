<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><title data-next-head="">Design of Anthropomorphic Interfaces for Autonomous Vehicle-Pedestrian Interaction | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="Anthropomorphism, AV-pedestrian Interaction, Immersive Analytics, VR" data-next-head=""/><meta name="description" content="Autonomous Vehicle (AV) technology promises to revolutionize human life. The promise of AVs includes reduced highway congestion, more efficient energy usage, and cheaper goods and services. However, without careful design, removing human drivers from vehicles will eliminate the natural communication channels which enable pedestrians to navigate safely. This thesis aims to design, present, and study anthropomorphic interfaces for autonomous vehicles, with the objective of enabling AVs to communicate with pedestrians through non-verbal cues. Non-verbal human communication is vital in human relationships. People use non-verbal communication when speech is impractical, such as when interacting with vehicles. When looking into ways in which AVs can use non-verbal communication to interact with pedestrians, we were inspired by the prospect of using anthropomorphic interfaces. This concept is well explored in Human-Robot Interaction (HRI) but has not been investigated in the context of AVs. For this thesis, we explored the design of anthropomorphic interfaces for autonomous vehicles. First, we proposed three types of anthropomorphic interfaces for AVs: facial expressions, hand gestures, and humanoid torsos. We developed a design space for each category using sketches and a low-fi prototype. Then, to research the benefits and limitations of anthropomorphic AVs, we implemented our AV interfaces in a Virtual Reality (VR) environment and developed two testbeds to evaluate their feasibility and scalability. Finally, we conducted two studies using the two testbeds. We investigated the study results using immersive analytics alongside traditional methods and revealed that anthropomorphic AVs could be helpful in AV-pedestrian interaction when designed by specific guidelines. Since we studied anthropomorphic AVs in VR, we were interested in the possibilities of analyzing the data of our study in an immersive environment. We designed a VR prototype specifically to analyze the data collected from the anthropomorphic AV study. The prototype provided basic immersive analytics features for the AV study data. We conducted an expert session with two domain experts to evaluate our immersive analytics prototype. The study contributed insights into the opportunities and challenges of utilizing immersive analytics to analyze AV studies." data-next-head=""/><meta property="og:title" content="Design of Anthropomorphic Interfaces for Autonomous Vehicle-Pedestrian Interaction | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta property="og:description" content="Autonomous Vehicle (AV) technology promises to revolutionize human life. The promise of AVs includes reduced highway congestion, more efficient energy usage, and cheaper goods and services. However, without careful design, removing human drivers from vehicles will eliminate the natural communication channels which enable pedestrians to navigate safely. This thesis aims to design, present, and study anthropomorphic interfaces for autonomous vehicles, with the objective of enabling AVs to communicate with pedestrians through non-verbal cues. Non-verbal human communication is vital in human relationships. People use non-verbal communication when speech is impractical, such as when interacting with vehicles. When looking into ways in which AVs can use non-verbal communication to interact with pedestrians, we were inspired by the prospect of using anthropomorphic interfaces. This concept is well explored in Human-Robot Interaction (HRI) but has not been investigated in the context of AVs. For this thesis, we explored the design of anthropomorphic interfaces for autonomous vehicles. First, we proposed three types of anthropomorphic interfaces for AVs: facial expressions, hand gestures, and humanoid torsos. We developed a design space for each category using sketches and a low-fi prototype. Then, to research the benefits and limitations of anthropomorphic AVs, we implemented our AV interfaces in a Virtual Reality (VR) environment and developed two testbeds to evaluate their feasibility and scalability. Finally, we conducted two studies using the two testbeds. We investigated the study results using immersive analytics alongside traditional methods and revealed that anthropomorphic AVs could be helpful in AV-pedestrian interaction when designed by specific guidelines. Since we studied anthropomorphic AVs in VR, we were interested in the possibilities of analyzing the data of our study in an immersive environment. We designed a VR prototype specifically to analyze the data collected from the anthropomorphic AV study. The prototype provided basic immersive analytics features for the AV study data. We conducted an expert session with two domain experts to evaluate our immersive analytics prototype. The study contributed insights into the opportunities and challenges of utilizing immersive analytics to analyze AV studies." data-next-head=""/><meta property="og:site_name" content="University of Calgary Interactions Lab" data-next-head=""/><meta property="og:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/theses/cover/msc-2023-wei.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:title" content="Design of Anthropomorphic Interfaces for Autonomous Vehicle-Pedestrian Interaction | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta name="twitter:description" content="Autonomous Vehicle (AV) technology promises to revolutionize human life. The promise of AVs includes reduced highway congestion, more efficient energy usage, and cheaper goods and services. However, without careful design, removing human drivers from vehicles will eliminate the natural communication channels which enable pedestrians to navigate safely. This thesis aims to design, present, and study anthropomorphic interfaces for autonomous vehicles, with the objective of enabling AVs to communicate with pedestrians through non-verbal cues. Non-verbal human communication is vital in human relationships. People use non-verbal communication when speech is impractical, such as when interacting with vehicles. When looking into ways in which AVs can use non-verbal communication to interact with pedestrians, we were inspired by the prospect of using anthropomorphic interfaces. This concept is well explored in Human-Robot Interaction (HRI) but has not been investigated in the context of AVs. For this thesis, we explored the design of anthropomorphic interfaces for autonomous vehicles. First, we proposed three types of anthropomorphic interfaces for AVs: facial expressions, hand gestures, and humanoid torsos. We developed a design space for each category using sketches and a low-fi prototype. Then, to research the benefits and limitations of anthropomorphic AVs, we implemented our AV interfaces in a Virtual Reality (VR) environment and developed two testbeds to evaluate their feasibility and scalability. Finally, we conducted two studies using the two testbeds. We investigated the study results using immersive analytics alongside traditional methods and revealed that anthropomorphic AVs could be helpful in AV-pedestrian interaction when designed by specific guidelines. Since we studied anthropomorphic AVs in VR, we were interested in the possibilities of analyzing the data of our study in an immersive environment. We designed a VR prototype specifically to analyze the data collected from the anthropomorphic AV study. The prototype provided basic immersive analytics features for the AV study data. We conducted an expert session with two domain experts to evaluate our immersive analytics prototype. The study contributed insights into the opportunities and challenges of utilizing immersive analytics to analyze AV studies." data-next-head=""/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/theses/cover/msc-2023-wei.jpg" data-next-head=""/><meta name="twitter:card" content="summary" data-next-head=""/><meta name="twitter:site" content="@ucalgary" data-next-head=""/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link rel="preload" href="/pr-preview/pr-142/_next/static/media/dc84b505c4b06e35-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/pr-preview/pr-142/_next/static/css/281ff1f186fbce6b.css" as="style"/><link rel="preload" href="/pr-preview/pr-142/_next/static/css/a1a0497113412518.css" as="style"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              // $('.ui.sidebar')
              //   .sidebar('attach events', '.sidebar.icon')

              $('.sidebar.icon').on('click', function(event) {
                $('.ui.sidebar')
                  .sidebar('toggle')
              })

              $('.project').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })

              $('.thesis').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><link rel="stylesheet" href="/pr-preview/pr-142/_next/static/css/281ff1f186fbce6b.css" data-n-g=""/><link rel="stylesheet" href="/pr-preview/pr-142/_next/static/css/a1a0497113412518.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/pr-preview/pr-142/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/pr-preview/pr-142/_next/static/chunks/webpack-7899779395be340d.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/340-795c2935822720c4.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/main-f5a95b893c70049f.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/vendor-styles-218505cf05882012.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/505-a6927c13d0d92549.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/pages/_app-09ca72778dd825e1.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/347-6f14004506bc7107.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/590-a0ec5d328c626dc7.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/330-04233cc3010a7fa2.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/960-4b0ff261179f7f73.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/chunks/pages/theses/%5Bid%5D-64656ddd92f422f0.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/48P8pCDlCxLVf6dR0GH9O/_buildManifest.js" defer=""></script><script src="/pr-preview/pr-142/_next/static/48P8pCDlCxLVf6dR0GH9O/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_728be9"><div class="ui center aligned container"><div class="ui secondary huge compact menu"><a class="item" href="/pr-preview/pr-142/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui tiny image" style="color:transparent" srcSet="/pr-preview/pr-142/static/images/ilab-logo-3d.gif 1x" src="/pr-preview/pr-142/static/images/ilab-logo-3d.gif"/></a><a class="item" href="/pr-preview/pr-142/people/">People</a><a class="item" href="/pr-preview/pr-142/publications/">Research</a></div></div><div class="pusher"><div class="ui stackable grid"><div class="one wide column"></div><div class="ten wide column centered" style="margin-top:30px"><div id="thesis"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-142/thesiss/">Thesis</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">MSc 2023</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"></div><div class="thirteen wide column"><h1>Design of Anthropomorphic Interfaces for Autonomous Vehicle-Pedestrian Interaction</h1><p class="meta"><a href="/people/wei-wei"><img alt="wei-wei photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-142/static/images/people/wei-wei.jpg 1x" src="/pr-preview/pr-142/static/images/people/wei-wei.jpg"/><strong>Wei Wei</strong></a><span class="role"> (author)</span>, <a href="/people/ehud-sharlin"><img alt="ehud-sharlin photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-142/static/images/people/ehud-sharlin.jpg 1x" src="/pr-preview/pr-142/static/images/people/ehud-sharlin.jpg"/><strong>Ehud Sharlin</strong></a><span class="role"> (supervisor)</span>, <span>Zhangxing Chen<!-- --> <span class="role"> (committee)</span></span>, <a href="/people/lora-oehlberg"><img alt="lora-oehlberg photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-142/static/images/people/lora-oehlberg.jpg 1x" src="/pr-preview/pr-142/static/images/people/lora-oehlberg.jpg"/><strong>Lora Oehlberg</strong></a><span class="role"> (committee)</span>, <a href="/people/sowmya-somanath"><img alt="sowmya-somanath photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-142/static/images/people/sowmya-somanath.jpg 1x" src="/pr-preview/pr-142/static/images/people/sowmya-somanath.jpg"/><strong>Sowmya Somanath</strong></a><span class="role"> (committee)</span></p></div></div></div><div class="block"><h1>Abstract</h1><p>Autonomous Vehicle (AV) technology promises to revolutionize human life. The promise of AVs includes reduced highway congestion, more efficient energy usage, and cheaper goods and services. However, without careful design, removing human drivers from vehicles will eliminate the natural communication channels which enable pedestrians to navigate safely. This thesis aims to design, present, and study anthropomorphic interfaces for autonomous vehicles, with the objective of enabling AVs to communicate with pedestrians through non-verbal cues. Non-verbal human communication is vital in human relationships. People use non-verbal communication when speech is impractical, such as when interacting with vehicles. When looking into ways in which AVs can use non-verbal communication to interact with pedestrians, we were inspired by the prospect of using anthropomorphic interfaces. This concept is well explored in Human-Robot Interaction (HRI) but has not been investigated in the context of AVs. For this thesis, we explored the design of anthropomorphic interfaces for autonomous vehicles. First, we proposed three types of anthropomorphic interfaces for AVs: facial expressions, hand gestures, and humanoid torsos. We developed a design space for each category using sketches and a low-fi prototype. Then, to research the benefits and limitations of anthropomorphic AVs, we implemented our AV interfaces in a Virtual Reality (VR) environment and developed two testbeds to evaluate their feasibility and scalability. Finally, we conducted two studies using the two testbeds. We investigated the study results using immersive analytics alongside traditional methods and revealed that anthropomorphic AVs could be helpful in AV-pedestrian interaction when designed by specific guidelines. Since we studied anthropomorphic AVs in VR, we were interested in the possibilities of analyzing the data of our study in an immersive environment. We designed a VR prototype specifically to analyze the data collected from the anthropomorphic AV study. The prototype provided basic immersive analytics features for the AV study data. We conducted an expert session with two domain experts to evaluate our immersive analytics prototype. The study contributed insights into the opportunities and challenges of utilizing immersive analytics to analyze AV studies.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Anthropomorphism</span><span class="ui brown basic label">AV Pedestrian Interaction</span><span class="ui brown basic label">Immersive Analytics</span><span class="ui brown basic label">VR</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Wei Wei<!-- -->. <b>Design of Anthropomorphic Interfaces for Autonomous Vehicle-Pedestrian Interaction</b>. <i></i> <!-- -->University of Calgary<!-- -->. <!-- -->Master of Science (MSc)<!-- -->. <!-- -->2023-01<!-- -->. <!-- -->DOI: <a href="https://dx.doi.org/10.11575/PRISM/40689" target="_blank">https://dx.doi.org/10.11575/PRISM/40689</a>URL: <a href="http://hdl.handle.net/1880/115776" target="_blank">http://hdl.handle.net/1880/115776</a></p></div></div></div></div><div class="one wide column"></div></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><div class="content"><a href="https://ucalgary.ca"><img alt="University of Calgary logo" loading="lazy" width="200" height="0" decoding="async" data-nimg="1" style="color:transparent;max-width:200px;margin:0px auto;height:auto" srcSet="/pr-preview/pr-142/static/images/logo-4.png 1x, /pr-preview/pr-142/static/images/logo-4.png 2x" src="/pr-preview/pr-142/static/images/logo-4.png"/></a><div class="sub header"><a class="item" href="https://cpsc.ucalgary.ca">Department of Computer Science</a></div></div></div></footer></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"ids":[{"id":"mmus-2012-pon"},{"id":"msc-2008-guo"},{"id":"msc-2011-harris"},{"id":"msc-2011-sultanum"},{"id":"msc-2012-lapides"},{"id":"msc-2015-li"},{"id":"msc-2017-hu"},{"id":"msc-2017-mok"},{"id":"msc-2017-payne"},{"id":"msc-2018-cartwright"},{"id":"msc-2018-ta"},{"id":"msc-2019-danyluk"},{"id":"msc-2019-kollannur"},{"id":"msc-2019-kuzabaviciute"},{"id":"msc-2019-mahadevan"},{"id":"msc-2019-mikalauskas"},{"id":"msc-2019-wun"},{"id":"msc-2021-asha"},{"id":"msc-2021-hung"},{"id":"msc-2021-wannamaker"},{"id":"msc-2023-dhawka"},{"id":"msc-2023-jadon"},{"id":"msc-2023-smith"},{"id":"msc-2023-wei"},{"id":"msc-2024-friedel"},{"id":"msc-2025-chulpongsatorn"},{"id":"phd-2010-young"},{"id":"phd-2017-somanath"},{"id":"phd-2018-mostafa"},{"id":"phd-2018-rajabiyazdi"},{"id":"phd-2019-li"},{"id":"phd-2020-ledo-maira"},{"id":"phd-2022-hull"},{"id":"phd-2024-mckendrick"},{"id":"phd-2025-cabral-mota"},{"id":"phd-2025-poostchi"},{"id":"phd-2025-pratte"}]},"__N_SSG":true},"page":"/theses/[id]","query":{"id":"msc-2023-wei"},"buildId":"48P8pCDlCxLVf6dR0GH9O","assetPrefix":"/pr-preview/pr-142","runtimeConfig":{"basePath":"/pr-preview/pr-142"},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
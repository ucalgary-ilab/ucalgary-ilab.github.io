<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><title data-next-head="">HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="mixed reality, embedded data visualization, tangible interaction, cross-device interaction" data-next-head=""/><meta name="description" content="We contribute interaction techniques for augmenting mixed reality (MR) visualizations with smartphone proxies. By combining head-mounted displays (HMDs) with mobile touchscreens, we can augment low-resolution holographic 3D charts with precise touch input, haptics feedback, high-resolution 2D graphics, and physical manipulation. Our approach aims to complement both MR and physical visualizations. Most current MR visualizations suffer from unreliable tracking, low visual resolution, and imprecise input. Data physicalizations on the other hand, although allowing for natural physical manipulation, are limited in dynamic and interactive modification. We demonstrate how mobile devices such as smartphones or tablets can serve as physical proxies for MR data interactions, creating dynamic visualizations that support precise manipulation and rich input and output. We describe 6 interaction techniques that leverage the combined physicality, sensing, and output capabilities of HMDs and smartphones, and demonstrate those interactions via a prototype system. Based on an evaluation, we outline opportunities for combining the advantages of both MR and physical charts." data-next-head=""/><meta property="og:title" content="HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta property="og:description" content="We contribute interaction techniques for augmenting mixed reality (MR) visualizations with smartphone proxies. By combining head-mounted displays (HMDs) with mobile touchscreens, we can augment low-resolution holographic 3D charts with precise touch input, haptics feedback, high-resolution 2D graphics, and physical manipulation. Our approach aims to complement both MR and physical visualizations. Most current MR visualizations suffer from unreliable tracking, low visual resolution, and imprecise input. Data physicalizations on the other hand, although allowing for natural physical manipulation, are limited in dynamic and interactive modification. We demonstrate how mobile devices such as smartphones or tablets can serve as physical proxies for MR data interactions, creating dynamic visualizations that support precise manipulation and rich input and output. We describe 6 interaction techniques that leverage the combined physicality, sensing, and output capabilities of HMDs and smartphones, and demonstrate those interactions via a prototype system. Based on an evaluation, we outline opportunities for combining the advantages of both MR and physical charts." data-next-head=""/><meta property="og:site_name" content="University of Calgary Interactions Lab" data-next-head=""/><meta property="og:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/chi-ea-2023-chulpongsatorn.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:title" content="HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta name="twitter:description" content="We contribute interaction techniques for augmenting mixed reality (MR) visualizations with smartphone proxies. By combining head-mounted displays (HMDs) with mobile touchscreens, we can augment low-resolution holographic 3D charts with precise touch input, haptics feedback, high-resolution 2D graphics, and physical manipulation. Our approach aims to complement both MR and physical visualizations. Most current MR visualizations suffer from unreliable tracking, low visual resolution, and imprecise input. Data physicalizations on the other hand, although allowing for natural physical manipulation, are limited in dynamic and interactive modification. We demonstrate how mobile devices such as smartphones or tablets can serve as physical proxies for MR data interactions, creating dynamic visualizations that support precise manipulation and rich input and output. We describe 6 interaction techniques that leverage the combined physicality, sensing, and output capabilities of HMDs and smartphones, and demonstrate those interactions via a prototype system. Based on an evaluation, we outline opportunities for combining the advantages of both MR and physical charts." data-next-head=""/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/chi-ea-2023-chulpongsatorn.jpg" data-next-head=""/><meta name="twitter:card" content="summary" data-next-head=""/><meta name="twitter:site" content="@ucalgary" data-next-head=""/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link rel="preload" href="/pr-preview/pr-161/_next/static/media/dc84b505c4b06e35-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/pr-preview/pr-161/_next/static/css/a416759b1f5d4aae.css" as="style"/><link rel="preload" href="/pr-preview/pr-161/_next/static/css/a1a0497113412518.css" as="style"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              // $('.ui.sidebar')
              //   .sidebar('attach events', '.sidebar.icon')

              $('.sidebar.icon').on('click', function(event) {
                $('.ui.sidebar')
                  .sidebar('toggle')
              })

              $('.project').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })

              $('.thesis').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><link rel="stylesheet" href="/pr-preview/pr-161/_next/static/css/a416759b1f5d4aae.css" data-n-g=""/><link rel="stylesheet" href="/pr-preview/pr-161/_next/static/css/a1a0497113412518.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/pr-preview/pr-161/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/pr-preview/pr-161/_next/static/chunks/webpack-36c9ad16b0d0c4cd.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/340-186ced8bab53bdb2.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/main-f5a95b893c70049f.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/vendor-styles-0d702b9154561405.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/505-d4a1cf67ea37d5e6.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/pages/_app-09ca72778dd825e1.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/347-6f14004506bc7107.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/590-86e5dd296f69ff04.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/383-c60258249be00af0.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/960-b4769ffb694316e6.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/chunks/pages/publications/%5Bid%5D-fe2a6e7ce1b05f32.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/WlgFI5VZy9sallUbLkjHe/_buildManifest.js" defer=""></script><script src="/pr-preview/pr-161/_next/static/WlgFI5VZy9sallUbLkjHe/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_70b7c2"><div class="ui center aligned container"><div class="ui secondary huge compact menu"><a class="item" href="/pr-preview/pr-161/"><img loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui tiny image" style="color:transparent" srcSet="/pr-preview/pr-161/static/images/ilab-logo-3d.gif 1x" src="/pr-preview/pr-161/static/images/ilab-logo-3d.gif"/></a><a class="item" href="/pr-preview/pr-161/people/">People</a><a class="item" href="/pr-preview/pr-161/publications/">Research</a></div></div><div class="pusher"><div class="ui stackable grid"><div class="one wide column"></div><div class="ten wide column centered" style="margin-top:30px"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-161/publications/">Publication</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI EA 2023</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img alt="chi-ea-2023-chulpongsatorn cover" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-161/static/images/publications/cover/chi-ea-2023-chulpongsatorn.jpg 1x" src="/pr-preview/pr-161/static/images/publications/cover/chi-ea-2023-chulpongsatorn.jpg"/></div><div class="thirteen wide column"><h1>HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies</h1><p class="meta"><a href="/people/neil-chulpongsatorn"><img alt="neil-chulpongsatorn photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-161/static/images/people/neil-chulpongsatorn.jpg 1x" src="/pr-preview/pr-161/static/images/people/neil-chulpongsatorn.jpg"/><strong>Neil Chulpongsatorn</strong></a><span class="role"></span>, <a href="/people/wesley-willett"><img alt="wesley-willett photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-161/static/images/people/wesley-willett.jpg 1x" src="/pr-preview/pr-161/static/images/people/wesley-willett.jpg"/><strong>Wesley Willett</strong></a><span class="role"></span>, <a href="/people/ryo-suzuki"><img alt="ryo-suzuki photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-161/static/images/people/ryo-suzuki.jpg 1x" src="/pr-preview/pr-161/static/images/people/ryo-suzuki.jpg"/><strong>Ryo Suzuki</strong></a><span class="role"></span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/main/static/publications/chi-ea-2023-chulpongsatorn.pdf" target="_blank"><svg data-prefix="far" data-icon="file-pdf" class="svg-inline--fa fa-file-pdf" role="img" viewBox="0 0 576 512" aria-hidden="true"><path fill="currentColor" d="M208 48L96 48c-8.8 0-16 7.2-16 16l0 384c0 8.8 7.2 16 16 16l80 0 0 48-80 0c-35.3 0-64-28.7-64-64L32 64C32 28.7 60.7 0 96 0L229.5 0c17 0 33.3 6.7 45.3 18.7L397.3 141.3c12 12 18.7 28.3 18.7 45.3l0 149.5-48 0 0-128-88 0c-39.8 0-72-32.2-72-72l0-88zM348.1 160L256 67.9 256 136c0 13.3 10.7 24 24 24l68.1 0zM240 380l32 0c33.1 0 60 26.9 60 60s-26.9 60-60 60l-12 0 0 28c0 11-9 20-20 20s-20-9-20-20l0-128c0-11 9-20 20-20zm32 80c11 0 20-9 20-20s-9-20-20-20l-12 0 0 40 12 0zm96-80l32 0c28.7 0 52 23.3 52 52l0 64c0 28.7-23.3 52-52 52l-32 0c-11 0-20-9-20-20l0-128c0-11 9-20 20-20zm32 128c6.6 0 12-5.4 12-12l0-64c0-6.6-5.4-12-12-12l-12 0 0 88 12 0zm76-108c0-11 9-20 20-20l48 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 24 28 0c11 0 20 9 20 20s-9 20-20 20l-28 0 0 44c0 11-9 20-20 20s-20-9-20-20l0-128z"></path></svg>chi-ea-2023-chulpongsatorn.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We contribute interaction techniques for augmenting mixed reality (MR) visualizations with smartphone proxies. By combining head-mounted displays (HMDs) with mobile touchscreens, we can augment low-resolution holographic 3D charts with precise touch input, haptics feedback, high-resolution 2D graphics, and physical manipulation. Our approach aims to complement both MR and physical visualizations. Most current MR visualizations suffer from unreliable tracking, low visual resolution, and imprecise input. Data physicalizations on the other hand, although allowing for natural physical manipulation, are limited in dynamic and interactive modification. We demonstrate how mobile devices such as smartphones or tablets can serve as physical proxies for MR data interactions, creating dynamic visualizations that support precise manipulation and rich input and output. We describe 6 interaction techniques that leverage the combined physicality, sensing, and output capabilities of HMDs and smartphones, and demonstrate those interactions via a prototype system. Based on an evaluation, we outline opportunities for combining the advantages of both MR and physical charts.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Embedded Data Visualization</span><span class="ui brown basic label">Tangible Interaction</span><span class="ui brown basic label">Cross Device Interaction</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Neil Chulpongsatorn<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Ryo Suzuki<!-- -->. <b>HoloTouch: Interacting with Mixed Reality Visualizations Through Smartphone Proxies</b>. <i>In <!-- -->Extended Abstracts of the CHI Conference on Human Factors in Computing Systems<!-- --> <!-- -->(<!-- -->CHI EA 2023<!-- -->)</i>ACM, New York, NY, USA<!-- --> <!-- -->Page: 1-<!-- -->8<!-- -->. <!-- -->DOI: <a href="https://doi.org/10.1145/3544549.3585738" target="_blank">https://doi.org/10.1145/3544549.3585738</a></p></div></div></div></div><div class="one wide column"></div></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><div class="content"><a href="https://ucalgary.ca"><img alt="University of Calgary logo" loading="lazy" width="200" height="0" decoding="async" data-nimg="1" style="color:transparent;max-width:200px;margin:0px auto;height:auto" srcSet="/pr-preview/pr-161/static/images/logo-4.png 1x, /pr-preview/pr-161/static/images/logo-4.png 2x" src="/pr-preview/pr-161/static/images/logo-4.png"/></a><div class="sub header"><a class="item" href="https://cpsc.ucalgary.ca">Department of Computer Science</a></div></div></div></footer></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"ids":[{"id":"assets-2017-suzuki"},{"id":"assets-2023-mok"},{"id":"cga-2019-ivanov"},{"id":"cgi-2019-danyluk"},{"id":"chi-2015-aseniero"},{"id":"chi-2015-jones"},{"id":"chi-2015-oehlberg"},{"id":"chi-2015-willett"},{"id":"chi-2017-aoki"},{"id":"chi-2017-hull"},{"id":"chi-2017-ledo"},{"id":"chi-2017-somanath"},{"id":"chi-2018-dillman"},{"id":"chi-2018-feick"},{"id":"chi-2018-heshmat"},{"id":"chi-2018-ledo"},{"id":"chi-2018-mahadevan"},{"id":"chi-2018-neustaedter"},{"id":"chi-2018-oh"},{"id":"chi-2018-suzuki"},{"id":"chi-2018-wuertz"},{"id":"chi-2019-danyluk"},{"id":"chi-2019-george"},{"id":"chi-2020-anjani"},{"id":"chi-2020-asha"},{"id":"chi-2020-goffin"},{"id":"chi-2020-hou"},{"id":"chi-2020-suzuki"},{"id":"chi-2021-danyluk"},{"id":"chi-2021-ens"},{"id":"chi-2021-hammad"},{"id":"chi-2022-bressa"},{"id":"chi-2022-ivanov"},{"id":"chi-2022-nittala"},{"id":"chi-2022-suzuki"},{"id":"chi-2023-dhawka"},{"id":"chi-2023-faridan"},{"id":"chi-2023-monteiro"},{"id":"chi-2024-bressa"},{"id":"chi-2024-dhawka"},{"id":"chi-2024-panigrahy"},{"id":"chi-2025-ghaneezabadi"},{"id":"chi-2025-madill"},{"id":"chi-2025-shiokawa"},{"id":"chi-ea-2022-blair"},{"id":"chi-ea-2023-chulpongsatorn"},{"id":"chi-ea-2023-fang"},{"id":"cmj-2020-ko"},{"id":"cnc-2019-hammad"},{"id":"cupum-2021-rout"},{"id":"dis-2016-jones"},{"id":"dis-2017-mok"},{"id":"dis-2018-mikalauskas"},{"id":"dis-2018-pham"},{"id":"dis-2018-ta"},{"id":"dis-2019-blair"},{"id":"dis-2019-bressa"},{"id":"dis-2019-ledo"},{"id":"dis-2019-mahadevan"},{"id":"dis-2019-nakayama"},{"id":"dis-2019-seyed"},{"id":"dis-2021-asha"},{"id":"dis-2021-blair"},{"id":"dis-2021-wannamaker"},{"id":"dis-2023-li"},{"id":"dis-2024-danyluk"},{"id":"frobt-2022-suzuki"},{"id":"gecco-2022-ivanov"},{"id":"gi-2020-rajabiyazdi"},{"id":"gi-2021-mactavish"},{"id":"gi-2022-hull"},{"id":"haid-2020-frisson"},{"id":"hri-2018-feick"},{"id":"httf-2024-blair"},{"id":"ieee-2021-willett"},{"id":"ijac-2021-hosseini"},{"id":"imwut-2020-wang"},{"id":"imx-2020-mok"},{"id":"iros-2020-hedayati"},{"id":"iros-2022-suzuki"},{"id":"mdpi-actuators-2024-piao"},{"id":"mdpi-arts-2023-frisson"},{"id":"mobilehci-2015-ledo"},{"id":"mobilehci-2019-hung"},{"id":"nime-2020-kirkegaard"},{"id":"nime-2020-ko"},{"id":"nime-2022-frisson"},{"id":"siggraph-labs-2023-seta"},{"id":"sui-2017-li"},{"id":"tei-2016-somanath"},{"id":"tei-2019-mikalauskas"},{"id":"tei-2019-tolley"},{"id":"tei-2019-wun"},{"id":"tei-2020-suzuki"},{"id":"tei-2021-pratte"},{"id":"tochi-2022-nittala"},{"id":"tvcg-2016-lopez"},{"id":"tvcg-2017-goffin"},{"id":"tvcg-2017-willett"},{"id":"tvcg-2019-blascheck"},{"id":"tvcg-2019-walny"},{"id":"tvcg-2020-danyluk"},{"id":"uist-2018-suzuki"},{"id":"uist-2019-suzuki"},{"id":"uist-2020-suzuki"},{"id":"uist-2020-yixian"},{"id":"uist-2021-suzuki"},{"id":"uist-2022-kaimoto"},{"id":"uist-2022-liao"},{"id":"uist-2022-nisser"},{"id":"uist-2022-nittala"},{"id":"uist-2023-chulpongsatorn"},{"id":"uist-2023-ihara"},{"id":"uist-2023-mukashev"},{"id":"uist-2023-xia"},{"id":"uist-2023-xia2"},{"id":"uist-2024-gunturu"},{"id":"uist-2024-roy"},{"id":"uist-sic-2022-faridan"},{"id":"vr-2019-satriadi"},{"id":"vrst-2022-frisson"}]},"__N_SSG":true},"page":"/publications/[id]","query":{"id":"chi-ea-2023-chulpongsatorn"},"buildId":"WlgFI5VZy9sallUbLkjHe","assetPrefix":"/pr-preview/pr-161","runtimeConfig":{"basePath":"/pr-preview/pr-161"},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
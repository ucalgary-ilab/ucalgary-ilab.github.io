<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="format-detection" content="telephone=no"/><link href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.css" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/css/lightbox.css" rel="stylesheet"/><link href="/pr-preview/pr-86/assets/img/favicon.ico" rel="shortcut icon"/><link href="/pr-preview/pr-86/static/css/style.css" rel="stylesheet"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox-plus-jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              $('.ui.sidebar')
                .sidebar('attach events', '.sidebar.icon')

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><title class="next-head">Kyzyl Monteiro | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="Human-Computer Interaction, HCI, Information Visualization, University of Calgary, CHI, UIST" class="next-head"/><meta name="description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta property="og:title" content="Kyzyl Monteiro | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta property="og:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta property="og:site_name" content="University of Calgary Interactions Lab" class="next-head"/><meta property="og:url" content="https://ilab.ucalgary.ca/" class="next-head"/><meta property="og:image" content="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" class="next-head"/><meta property="og:type" content="website" class="next-head"/><meta name="twitter:title" content="Kyzyl Monteiro | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta name="twitter:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta name="twitter:image" content="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" class="next-head"/><meta name="twitter:card" content="summary" class="next-head"/><meta name="twitter:site" content="@ucalgary" class="next-head"/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" class="next-head"/><link rel="preload" href="/pr-preview/pr-86/_next/static/8Go6BBYDSlRTtPHH1IqEa/pages/person.js" as="script"/><link rel="preload" href="/pr-preview/pr-86/_next/static/8Go6BBYDSlRTtPHH1IqEa/pages/_app.js" as="script"/><link rel="preload" href="/pr-preview/pr-86/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" as="script"/><link rel="preload" href="/pr-preview/pr-86/_next/static/chunks/commons.0c93cb8d3516282dd2c4.js" as="script"/><link rel="preload" href="/pr-preview/pr-86/_next/static/runtime/main-563fdde58a64bdca21c4.js" as="script"/></head><body><div id="__next"><div><div><div class="ui right vertical sidebar menu"><a class="item" href="/pr-preview/pr-86/">Home</a><a class="item" href="/pr-preview/pr-86/publications">Publications</a><a class="item active" href="/pr-preview/pr-86/people">People</a><a class="item" href="/pr-preview/pr-86/courses">Courses</a><a class="item" href="/pr-preview/pr-86/facility">Facility</a><a class="item" href="/pr-preview/pr-86/seminar">Seminar</a><a class="item" href="/pr-preview/pr-86/location">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/pr-preview/pr-86/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item" href="/pr-preview/pr-86/publications">Publications</a><a class="item active" href="/pr-preview/pr-86/people">People</a><a class="item" href="/pr-preview/pr-86/courses">Courses</a><a class="item" href="/pr-preview/pr-86/facility">Facility</a><a class="item" href="/pr-preview/pr-86/seminar">Seminar</a><a class="item" href="/pr-preview/pr-86/location">Location</a><div class="toc item"><a href="/pr-preview/pr-86/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div></div><div class="ui stackable grid"><div class="one wide column"></div><div class="eleven wide column centered"><div id="person" class="category" style="text-align:center"><img class="ui circular image large-profile" src="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" style="margin:auto"/><h1>Kyzyl Monteiro</h1><p></p><p><a href="https://kyzyl.me" target="_blank"><i class="fas fa-link fa-fw"></i>https://kyzyl.me</a></p><p><a href="https://scholar.google.ca/citations?user=A9IqYNoAAAAJ" target="_blank"><i class="fas fa-graduation-cap fa-fw"></i>Google Scholar</a></p><div class="ui horizontal small divided link list"><div class="item"><a href="https://twitter.com/kyzylmonteiro" target="_blank" style="font-size:1.2em"><i class="fab fa-twitter fa-fw"></i>kyzylmonteiro</a></div><div class="item"><a href="https://github.com/kyzylmonteiro" target="_blank" style="font-size:1.2em"><i class="fab fa-github-alt fa-fw"></i>kyzylmonteiro</a></div><div class="item"><a href="https://www.linkedin.com/in/kyzylmonteiro/" target="_blank" style="font-size:1.2em"><i class="fab fa-linkedin-in fa-fw"></i>LinkedIn</a></div><div class="item"><a href="mailto:kyzylmonteiro@gmail.com" target="_blank" style="font-size:1.2em"><i class="far fa-envelope fa-fw"></i>kyzylmonteiro@gmail.com</a></div></div></div><div id="publications" class="category"><h1 class="ui horizontal divider header"><i class="file alternate outline icon"></i>Publications</h1><div class="ui segment" style="margin-top:50px"><div class="publication ui vertical segment stackable grid" data-id="uist-2023-xia"><div class="three wide column" style="margin:auto"><img class="cover" src="/pr-preview/pr-86/static/images/publications/cover/uist-2023-xia.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">UIST 2023</span></p><p class="color" style="font-size:1.3em"><b>RealityCanvas: Augmented Reality Sketching for Embedded and Responsive Scribble Animation Effects</b></p><p><a href="/pr-preview/pr-86/people/zhijie-xia"><img src="/pr-preview/pr-86/static/images/people/zhijie-xia.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Zhijie Xia</span></a> , <a href="/pr-preview/pr-86/people/kyzyl-monteiro"><img src="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kyzyl Monteiro</span></a> , <a href="/pr-preview/pr-86/people/kevin-van"><img src="/pr-preview/pr-86/static/images/people/kevin-van.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kevin Van</span></a> , <a href="/pr-preview/pr-86/people/ryo-suzuki"><img src="/pr-preview/pr-86/static/images/people/ryo-suzuki.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ryo Suzuki</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Sketching Interfaces</span><span class="ui brown basic label">Scribble Animation</span><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Real Time Authoring</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2023-monteiro"><div class="three wide column" style="margin:auto"><img class="cover" src="/pr-preview/pr-86/static/images/publications/cover/chi-2023-monteiro.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2023</span></p><p class="color" style="font-size:1.3em"><b>Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching</b></p><p><a href="/pr-preview/pr-86/people/kyzyl-monteiro"><img src="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kyzyl Monteiro</span></a> , <a href="/pr-preview/pr-86/people/ritik-vatsal"><img src="/pr-preview/pr-86/static/images/people/ritik-vatsal.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ritik Vatsal</span></a> , <a href="/pr-preview/pr-86/people/neil-chulpongsatorn"><img src="/pr-preview/pr-86/static/images/people/neil-chulpongsatorn.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Neil Chulpongsatorn</span></a> , <span>Aman Parnami</span> , <a href="/pr-preview/pr-86/people/ryo-suzuki"><img src="/pr-preview/pr-86/static/images/people/ryo-suzuki.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ryo Suzuki</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Prototyping Tools</span><span class="ui brown basic label">Tangible Interactions</span><span class="ui brown basic label">Everyday Objects</span><span class="ui brown basic label">Interactive Machine Teaching</span><span class="ui brown basic label">Human Centered Machine Learning</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="uist-2022-kaimoto"><div class="three wide column" style="margin:auto"><img class="cover" src="/pr-preview/pr-86/static/images/publications/cover/uist-2022-kaimoto.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">UIST 2022</span></p><p class="color" style="font-size:1.3em"><b>Sketched Reality: Sketching Bi-Directional Interactions Between Virtual and Physical Worlds with AR and Actuated Tangible UI</b></p><p><a href="/pr-preview/pr-86/people/hiroki-kaimoto"><img src="/pr-preview/pr-86/static/images/people/hiroki-kaimoto.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Hiroki Kaimoto</span></a> , <a href="/pr-preview/pr-86/people/kyzyl-monteiro"><img src="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Kyzyl Monteiro</span></a> , <a href="/pr-preview/pr-86/people/mehrad-faridan"><img src="/pr-preview/pr-86/static/images/people/mehrad-faridan.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Mehrad Faridan</span></a> , <span>Jiatong Li</span> , <a href="/pr-preview/pr-86/people/samin-farajian"><img src="/pr-preview/pr-86/static/images/people/samin-farajian.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Samin Farajian</span></a> , <span>Yasuaki Kakehi</span> , <span>Ken Nakagaki</span> , <a href="/pr-preview/pr-86/people/ryo-suzuki"><img src="/pr-preview/pr-86/static/images/people/ryo-suzuki.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ryo Suzuki</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Actuated Tangible Interfaces</span><span class="ui brown basic label">Swarm User Interfaces</span></div></p></div></div></div><div id="publications-modal"><div id="uist-2023-xia" class="ui large modal"><div class="header"><a href="/pr-preview/pr-86/publications/uist-2023-xia" target="_blank"><i class="fas fa-link fa-fw"></i>uist-2023-xia</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-86/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">UIST 2023</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/pr-preview/pr-86/static/images/publications/cover/uist-2023-xia.jpg"/></div><div class="thirteen wide column"><h1><a href="/pr-preview/pr-86/publications/uist-2023-xia" target="_blank">RealityCanvas: Augmented Reality Sketching for Embedded and Responsive Scribble Animation Effects</a></h1><p class="meta"><a href="/pr-preview/pr-86/people/zhijie-xia"><img src="/pr-preview/pr-86/static/images/people/zhijie-xia.jpg" class="ui circular spaced image mini-profile"/><strong>Zhijie Xia</strong></a> , <a href="/pr-preview/pr-86/people/kyzyl-monteiro"><img src="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" class="ui circular spaced image mini-profile"/><strong>Kyzyl Monteiro</strong></a> , <a href="/pr-preview/pr-86/people/kevin-van"><img src="/pr-preview/pr-86/static/images/people/kevin-van.jpg" class="ui circular spaced image mini-profile"/><strong>Kevin Van</strong></a> , <a href="/pr-preview/pr-86/people/ryo-suzuki"><img src="/pr-preview/pr-86/static/images/people/ryo-suzuki.jpg" class="ui circular spaced image mini-profile"/><strong>Ryo Suzuki</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/uist-2023-xia.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>uist-2023-xia.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/HVOgH1quDsc" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/HVOgH1quDsc?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/HVOgH1quDsc/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We introduce RealityCanvas, a mobile AR sketching tool that can easily augment real-world physical motion with responsive hand-drawn animation. Recent research in AR sketching tools has enabled users to not only embed static drawings into the real world but also dynamically animate them with physical motion. However, existing tools often lack the flexibility and expressiveness of possible animations, as they primarily support simple line-based geometry. To address this limitation, we explore both expressive and improvisational AR sketched animation by introducing a set of responsive scribble animation techniques that can be directly embedded through sketching interactions: 1) object binding, 2) flip-book animation, 3) action trigger, 4) particle effects, 5) motion trajectory, and 6) contour highlight. These six animation effects were derived from the analysis of 172 existing video-edited scribble animations. We showcase these techniques through various applications, such as video creation, augmented education, storytelling, and AR prototyping. The results of our user study and expert interviews confirm that our tool can lower the barrier to creating AR-based sketched animation, while allowing creative, expressive, and improvisational AR sketching experiences.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Sketching Interfaces</span><span class="ui brown basic label">Scribble Animation</span><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Real Time Authoring</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Zhijie Xia<!-- -->, <!-- -->Kyzyl Monteiro<!-- -->, <!-- -->Kevin Van<!-- -->, <!-- -->Ryo Suzuki<!-- -->. <b>RealityCanvas: Augmented Reality Sketching for Embedded and Responsive Scribble Animation Effects</b>. <i>In Proceedings of the Annual ACM Symposium on User Interface Software and Technology (UIST &#x27;23)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->14<!-- -->.  DOI: <a href="https://doi.org/10.1145/3586183.3606716" target="_blank">https://doi.org/10.1145/3586183.3606716</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2023-monteiro" class="ui large modal"><div class="header"><a href="/pr-preview/pr-86/publications/chi-2023-monteiro" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2023-monteiro</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-86/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2023</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/pr-preview/pr-86/static/images/publications/cover/chi-2023-monteiro.jpg"/></div><div class="thirteen wide column"><h1><a href="/pr-preview/pr-86/publications/chi-2023-monteiro" target="_blank">Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching</a></h1><p class="meta"><a href="/pr-preview/pr-86/people/kyzyl-monteiro"><img src="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" class="ui circular spaced image mini-profile"/><strong>Kyzyl Monteiro</strong></a> , <a href="/pr-preview/pr-86/people/ritik-vatsal"><img src="/pr-preview/pr-86/static/images/people/ritik-vatsal.jpg" class="ui circular spaced image mini-profile"/><strong>Ritik Vatsal</strong></a> , <a href="/pr-preview/pr-86/people/neil-chulpongsatorn"><img src="/pr-preview/pr-86/static/images/people/neil-chulpongsatorn.jpg" class="ui circular spaced image mini-profile"/><strong>Neil Chulpongsatorn</strong></a> , <span>Aman Parnami</span> , <a href="/pr-preview/pr-86/people/ryo-suzuki"><img src="/pr-preview/pr-86/static/images/people/ryo-suzuki.jpg" class="ui circular spaced image mini-profile"/><strong>Ryo Suzuki</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2023-monteiro.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2023-monteiro.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/JssiyfrhIJw" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/JssiyfrhIJw?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/JssiyfrhIJw/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>This paper introduces Teachable Reality, an augmented reality (AR) prototyping tool for creating interactive tangible AR applications with arbitrary everyday objects. Teachable Reality leverages vision-based interactive machine teaching (e.g., Teachable Machine), which captures real-world interactions for AR prototyping. It identifies the user-defined tangible and gestural interactions using an on-demand computer vision model. Based on this, the user can easily create functional AR prototypes without programming, enabled by a trigger-action authoring interface. Therefore, our approach allows the flexibility, customizability, and generalizability of tangible AR applications that can address the limitation of current marker-based approaches. We explore the design space and demonstrate various AR prototypes, which include tangible and deformable interfaces, context-aware assistants, and body-driven AR applications. The results of our user study and expert interviews confirm that our approach can lower the barrier to creating functional AR prototypes while also allowing flexible and general-purpose prototyping experiences.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Prototyping Tools</span><span class="ui brown basic label">Tangible Interactions</span><span class="ui brown basic label">Everyday Objects</span><span class="ui brown basic label">Interactive Machine Teaching</span><span class="ui brown basic label">Human Centered Machine Learning</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kyzyl Monteiro<!-- -->, <!-- -->Ritik Vatsal<!-- -->, <!-- -->Neil Chulpongsatorn<!-- -->, <!-- -->Aman Parnami<!-- -->, <!-- -->Ryo Suzuki<!-- -->. <b>Teachable Reality: Prototyping Tangible Augmented Reality with Everyday Objects by Leveraging Interactive Machine Teaching</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;23)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->15<!-- -->.  DOI: <a href="https://doi.org/10.1145/3544548.3581449" target="_blank">https://doi.org/10.1145/3544548.3581449</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="uist-2022-kaimoto" class="ui large modal"><div class="header"><a href="/pr-preview/pr-86/publications/uist-2022-kaimoto" target="_blank"><i class="fas fa-link fa-fw"></i>uist-2022-kaimoto</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-86/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">UIST 2022</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/pr-preview/pr-86/static/images/publications/cover/uist-2022-kaimoto.jpg"/></div><div class="thirteen wide column"><h1><a href="/pr-preview/pr-86/publications/uist-2022-kaimoto" target="_blank">Sketched Reality: Sketching Bi-Directional Interactions Between Virtual and Physical Worlds with AR and Actuated Tangible UI</a></h1><p class="meta"><a href="/pr-preview/pr-86/people/hiroki-kaimoto"><img src="/pr-preview/pr-86/static/images/people/hiroki-kaimoto.jpg" class="ui circular spaced image mini-profile"/><strong>Hiroki Kaimoto</strong></a> , <a href="/pr-preview/pr-86/people/kyzyl-monteiro"><img src="/pr-preview/pr-86/static/images/people/kyzyl-monteiro.jpg" class="ui circular spaced image mini-profile"/><strong>Kyzyl Monteiro</strong></a> , <a href="/pr-preview/pr-86/people/mehrad-faridan"><img src="/pr-preview/pr-86/static/images/people/mehrad-faridan.jpg" class="ui circular spaced image mini-profile"/><strong>Mehrad Faridan</strong></a> , <span>Jiatong Li</span> , <a href="/pr-preview/pr-86/people/samin-farajian"><img src="/pr-preview/pr-86/static/images/people/samin-farajian.jpg" class="ui circular spaced image mini-profile"/><strong>Samin Farajian</strong></a> , <span>Yasuaki Kakehi</span> , <span>Ken Nakagaki</span> , <a href="/pr-preview/pr-86/people/ryo-suzuki"><img src="/pr-preview/pr-86/static/images/people/ryo-suzuki.jpg" class="ui circular spaced image mini-profile"/><strong>Ryo Suzuki</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/uist-2022-kaimoto.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>uist-2022-kaimoto.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/xy-IeVgoEpY" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/xy-IeVgoEpY?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/xy-IeVgoEpY/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>This paper introduces Sketched Reality, an approach that com- bines AR sketching and actuated tangible user interfaces (TUI) for bi-directional sketching interaction. Bi-directional sketching enables virtual sketches and physical objects to affect each other through physical actuation and digital computation. In the existing AR sketching, the relationship between virtual and physical worlds is only one-directional --- while physical interaction can affect virtual sketches, virtual sketches have no return effect on the physical objects or environment. In contrast, bi-directional sketching interaction allows the seamless coupling between sketches and actuated TUIs. In this paper, we employ tabletop-size small robots (Sony Toio) and an iPad-based AR sketching tool to demonstrate the concept. In our system, virtual sketches drawn and simulated on an iPad (e.g., lines, walls, pendulums, and springs) can move, actuate, collide, and constrain physical Toio robots, as if virtual sketches and the physical objects exist in the same space through seamless coupling between AR and robot motion. This paper contributes a set of novel interactions and a design space of bi-directional AR sketching. We demonstrate a series of potential applications, such as tangible physics education, explorable mechanism, tangible gaming for children, and in-situ robot programming via sketching.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Mixed Reality</span><span class="ui brown basic label">Actuated Tangible Interfaces</span><span class="ui brown basic label">Swarm User Interfaces</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Hiroki Kaimoto<!-- -->, <!-- -->Kyzyl Monteiro<!-- -->, <!-- -->Mehrad Faridan<!-- -->, <!-- -->Jiatong Li<!-- -->, <!-- -->Samin Farajian<!-- -->, <!-- -->Yasuaki Kakehi<!-- -->, <!-- -->Ken Nakagaki<!-- -->, <!-- -->Ryo Suzuki<!-- -->. <b>Sketched Reality: Sketching Bi-Directional Interactions Between Virtual and Physical Worlds with AR and Actuated Tangible UI</b>. <i>In Proceedings of the Annual ACM Symposium on User Interface Software and Technology (UIST &#x27;22)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/3526113.3545626" target="_blank">https://doi.org/10.1145/3526113.3545626</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img style="max-width:180px;margin:30px auto" src="/pr-preview/pr-86/static/images/logo-6.png"/><div class="content"><img style="max-width:200px;margin:0px auto" src="/pr-preview/pr-86/static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{"id":"kyzyl-monteiro"}},"page":"/pr-preview/pr-86/person","query":{"id":"kyzyl-monteiro"},"buildId":"8Go6BBYDSlRTtPHH1IqEa","dynamicBuildId":false,"nextExport":true}</script><script async="" id="__NEXT_PAGE__/person" src="/pr-preview/pr-86/_next/static/8Go6BBYDSlRTtPHH1IqEa/pages/person.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/pr-preview/pr-86/_next/static/8Go6BBYDSlRTtPHH1IqEa/pages/_app.js"></script><script src="/pr-preview/pr-86/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" async=""></script><script src="/pr-preview/pr-86/_next/static/chunks/commons.0c93cb8d3516282dd2c4.js" async=""></script><script src="/pr-preview/pr-86/_next/static/runtime/main-563fdde58a64bdca21c4.js" async=""></script></body></html>
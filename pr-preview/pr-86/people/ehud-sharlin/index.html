<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="format-detection" content="telephone=no"/><link href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.css" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/css/lightbox.css" rel="stylesheet"/><link href="assets/img/favicon.ico" rel="shortcut icon"/><link href="static/css/style.css" rel="stylesheet"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox-plus-jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              $('.ui.sidebar')
                .sidebar('attach events', '.sidebar.icon')

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><title class="next-head">Ehud Sharlin | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="Human-Computer Interaction, HCI, Information Visualization, University of Calgary, CHI, UIST" class="next-head"/><meta name="description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta property="og:title" content="Ehud Sharlin | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta property="og:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta property="og:site_name" content="University of Calgary Interactions Lab" class="next-head"/><meta property="og:url" content="https://ilab.ucalgary.ca/" class="next-head"/><meta property="og:image" content="static/images/people/ehud-sharlin.jpg" class="next-head"/><meta property="og:type" content="website" class="next-head"/><meta name="twitter:title" content="Ehud Sharlin | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta name="twitter:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta name="twitter:image" content="static/images/people/ehud-sharlin.jpg" class="next-head"/><meta name="twitter:card" content="summary" class="next-head"/><meta name="twitter:site" content="@ucalgary" class="next-head"/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" class="next-head"/><link rel="preload" href="_next/static/hmNAYcqzNONa-Ruzzzu6c/pages/person.js" as="script"/><link rel="preload" href="_next/static/hmNAYcqzNONa-Ruzzzu6c/pages/_app.js" as="script"/><link rel="preload" href="_next/static/runtime/webpack-8ed9452df514b4d17d80.js" as="script"/><link rel="preload" href="_next/static/chunks/commons.0c93cb8d3516282dd2c4.js" as="script"/><link rel="preload" href="_next/static/runtime/main-563fdde58a64bdca21c4.js" as="script"/></head><body><div id="__next"><div><div><div class="ui right vertical sidebar menu"><a class="item" href="/">Home</a><a class="item" href="publications">Publications</a><a class="item active" href="people">People</a><a class="item" href="courses">Courses</a><a class="item" href="facility">Facility</a><a class="item" href="seminar">Seminar</a><a class="item" href="location">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item" href="publications">Publications</a><a class="item active" href="people">People</a><a class="item" href="courses">Courses</a><a class="item" href="facility">Facility</a><a class="item" href="seminar">Seminar</a><a class="item" href="location">Location</a><div class="toc item"><a href="/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div></div><div class="ui stackable grid"><div class="one wide column"></div><div class="eleven wide column centered"><div id="person" class="category" style="text-align:center"><img class="ui circular image large-profile" src="static/images/people/ehud-sharlin.jpg" style="margin:auto"/><h1>Ehud Sharlin</h1><p>Professor</p><p><a href="http://contacts.ucalgary.ca/info/cpsc/profiles/102-3264" target="_blank"><i class="fas fa-link fa-fw"></i>http://contacts.ucalgary.ca/info/cpsc/profiles/102-3264</a></p><p><a href="https://scholar.google.ca/citations?hl=en&amp;user=eAFxlZIAAAAJ" target="_blank"><i class="fas fa-graduation-cap fa-fw"></i>Google Scholar</a></p><div class="ui horizontal small divided link list"></div></div><div id="publications" class="category"><h1 class="ui horizontal divider header"><i class="file alternate outline icon"></i>Publications</h1><div class="ui segment" style="margin-top:50px"><div class="publication ui vertical segment stackable grid" data-id="chi-2025-madill"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2025-madill.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2025</span></p><p class="color" style="font-size:1.3em"><b>Playing with Robots: Performing Arts Techniques for Designing and Understanding Robot Group Movement</b></p><p><span>Philippa Madill</span> , <span>Matthew Newton</span> , <span>Huanjun Zhao</span> , <span>Yichen Lian</span> , <a href="people/zachary-mckendrick"><img src="static/images/people/zachary-mckendrick.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Zachary McKendrick</span></a> , <span>Patrick Finn</span> , <a href="people/aditya-shekhar-nittala"><img src="static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Aditya Shekhar Nittala</span></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Humanities</span><span class="ui brown basic label">Art</span><span class="ui brown basic label">Robots</span><span class="ui brown basic label">Method</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2021-asha"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/dis-2021-asha.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2021</span></p><p class="color" style="font-size:1.3em"><b>Co-Designing Interactions between Pedestrians in Wheelchairs and Autonomous Vehicles</b></p><p><a href="people/ashratuz-zavin-asha"><img src="static/images/people/ashratuz-zavin-asha.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ashratuz Zavin Asha</span></a> , <a href="people/christopher-smith"><img src="static/images/people/christopher-smith.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Christopher Smith</span></a> , <a href="people/georgina-freeman"><img src="static/images/people/georgina-freeman.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Georgina Freeman</span></a> , <span>Sean Crump</span> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Pedestrians In Wheelchairs</span><span class="ui brown basic label">Co Design</span><span class="ui brown basic label">Autonomous Vehicles</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2021-hammad"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2021-hammad.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2021</span></p><p class="color" style="font-size:1.3em"><b>Homecoming: Exploring Returns to Long-Term Single Player Games</b></p><p><span>Noor Hammad</span> , <span>Owen Brierley</span> , <a href="people/zachary-mckendrick"><img src="static/images/people/zachary-mckendrick.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Zachary McKendrick</span></a> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <span>Patrick Finn</span> , <span>Jessica Hammer</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Long Term Single Player Game</span><span class="ui brown basic label">Autobiographical Design</span><span class="ui brown basic label">Pivot Point</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="imwut-2020-wang"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/imwut-2020-wang.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">IMWUT 2020</span></p><p class="color" style="font-size:1.3em"><b>AssessBlocks: Exploring Toy Block Play Features for Assessing Stress in Young Children after Natural Disasters</b></p><p><span>Xiyue Wang</span> , <span>Kazuki Takashima</span> , <span>Tomoaki Adachi</span> , <span>Patrick Finn</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a> , <span>Yoshifumi Kitamura</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Well Being</span><span class="ui brown basic label">Toy Blocks</span><span class="ui brown basic label">PTSD</span><span class="ui brown basic label">Tangibles For Health</span><span class="ui brown basic label">Stress Assessment</span><span class="ui brown basic label">Play</span><span class="ui brown basic label">Children</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2020-asha"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2020-asha.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2020 LBW</span></p><p class="color" style="font-size:1.3em"><b>Views from the Wheelchair: Understanding Interaction between Autonomous Vehicle and Pedestrians with Reduced Mobility</b></p><p><a href="people/ashratuz-zavin-asha"><img src="static/images/people/ashratuz-zavin-asha.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ashratuz Zavin Asha</span></a> , <a href="people/christopher-smith"><img src="static/images/people/christopher-smith.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Christopher Smith</span></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Autonomous Vehicle</span><span class="ui brown basic label">Pedestrian With Reduced Mobility</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2020-hou"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2020-hou.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2020</span></p><p class="color" style="font-size:1.3em"><b>Autonomous Vehicle-Cyclist Interaction: Peril and Promise</b></p><p><span>Ming Hou</span> , <a href="people/karthik-mahadevan"><img src="static/images/people/karthik-mahadevan.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Karthik Mahadevan</span></a> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Autonomous Vehicle Cyclist Interaction</span><span class="ui brown basic label">Interfaces For Communicating Intent And Awareness</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="cnc-2019-hammad"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/cnc-2019-hammad.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">C&amp;C 2019</span></p><p class="color" style="font-size:1.3em"><b>Mutation: Leveraging Performing Arts Practices in Cyborg Transitioning</b></p><p><a href="people/nour-hammad"><img src="static/images/people/nour-hammad.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Nour Hammad</span></a> , <span>Elaheh Sanoubari</span> , <span>Patrick Finn</span> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <span>James E. Young</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Interaction Design</span><span class="ui brown basic label">Cyborgs</span><span class="ui brown basic label">User Experience</span><span class="ui brown basic label">Performing Art Techniques</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2019-mahadevan"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/dis-2019-mahadevan.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2019</span></p><p class="color" style="font-size:1.3em"><b>AV-Pedestrian Interaction Design Using a Pedestrian Mixed Traffic Simulator</b></p><p><a href="people/karthik-mahadevan"><img src="static/images/people/karthik-mahadevan.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Karthik Mahadevan</span></a> , <span>Elaheh Sanoubari</span> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <span>James E. Young</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Mixed Traffic</span><span class="ui brown basic label">Pedestrian Simulator</span><span class="ui brown basic label">Autonomous Vehicle Pedestrian Interaction</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2018-ta"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/dis-2018-ta.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2018</span></p><p class="color" style="font-size:1.3em"><b>Bod-IDE: An Augmented Reality Sandbox for eFashion Garments</b></p><p><span>Kevin Ta</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Electronic Fashion</span><span class="ui brown basic label">Creativity Support Tool</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="tei-2016-somanath"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/tei-2016-somanath.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">TEI 2016</span></p><p class="color" style="font-size:1.3em"><b>Engaging &#x27;At-Risk&#x27; Students through Maker Culture Activities</b></p><p><a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <span>Laura Morrison</span> , <span>Janette Hughes</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a> , <span>Mario Costa Sousa</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">DIY</span><span class="ui brown basic label">At Risk Students</span><span class="ui brown basic label">Maker Culture</span><span class="ui brown basic label">Education</span><span class="ui brown basic label">Young Learners</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2018-feick"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2018-feick.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2018</span><span class="ui big basic pink label"><b><i class="fas fa-award"></i> Honorable Mention</b></span></p><p class="color" style="font-size:1.3em"><b>Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration</b></p><p><a href="people/martin-feick"><img src="static/images/people/martin-feick.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Martin Feick</span></a> , <span>Terrance Tin Hoi Mok</span> , <a href="people/anthony-tang"><img src="static/images/people/anthony-tang.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Anthony Tang</span></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Object Focused Collaboration</span><span class="ui brown basic label">Physical Telepresence</span><span class="ui brown basic label">Collaborative Physical Tasks</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2018-mahadevan"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2018-mahadevan.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2018</span></p><p class="color" style="font-size:1.3em"><b>Communicating Awareness and Intent in Autonomous Vehicle-Pedestrian Interaction</b></p><p><a href="people/karthik-mahadevan"><img src="static/images/people/karthik-mahadevan.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Karthik Mahadevan</span></a> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Autonomous Vehicle Pedestrian Interaction</span><span class="ui brown basic label">Perceived Awareness And Intent In Autonomous Vehicles</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="hri-2018-feick"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/hri-2018-feick.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">HRI 2018</span></p><p class="color" style="font-size:1.3em"><b>The Way You Move: The Effect of a Robot Surrogate Movement in Remote Collaboration</b></p><p><a href="people/martin-feick"><img src="static/images/people/martin-feick.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Martin Feick</span></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a> , <a href="people/anthony-tang"><img src="static/images/people/anthony-tang.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Anthony Tang</span></a> , <span>André Miede</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a></p><p><div class="ui large basic labels"><span class="ui brown basic label">Movement Trajectory Velocity</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Robot Surrogate</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="sui-2017-li"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/sui-2017-li.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">SUI 2017</span></p><p class="color" style="font-size:1.3em"><b>Visibility Perception and Dynamic Viewsheds for Topographic Maps and Models</b></p><p><span>Nico Li</span> , <a href="people/wesley-willett"><img src="static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Wesley Willett</span></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a> , <span>Mario Costa Sousa</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Terrain Visualization</span><span class="ui brown basic label">Geospatial Visualization</span><span class="ui brown basic label">Dynamic Viewshed</span><span class="ui brown basic label">Topographic Maps</span><span class="ui brown basic label">Tangible User Interfaces</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2017-somanath"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2017-somanath.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2017</span></p><p class="color" style="font-size:1.3em"><b>&#x27;Maker&#x27; within Constraints: Exploratory Study of Young Learners using Arduino at a High School in India</b></p><p><a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Sowmya Somanath</span></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a> , <span>Janette Hughes</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a> , <span>Mario Costa Sousa</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">India</span><span class="ui brown basic label">HCI 4 D</span><span class="ui brown basic label">Physical Computing</span><span class="ui brown basic label">DIY</span><span class="ui brown basic label">Young Learners</span><span class="ui brown basic label">Maker Culture</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="dis-2016-jones"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/dis-2016-jones.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">DIS 2016</span></p><p class="color" style="font-size:1.3em"><b>Elevating Communication, Collaboration, and Shared Experiences in Mobile Video through Drones</b></p><p><a href="people/brennan-jones"><img src="static/images/people/brennan-jones.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Brennan Jones</span></a> , <span>Kody Dillman</span> , <span>Richard Tang</span> , <a href="people/anthony-tang"><img src="static/images/people/anthony-tang.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Anthony Tang</span></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Ehud Sharlin</span></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Lora Oehlberg</span></a> , <a href="people/carman-neustaedter"><img src="static/images/people/carman-neustaedter.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Carman Neustaedter</span></a> , <span>Scott Bateman</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Telepresence</span><span class="ui brown basic label">Video Communication</span><span class="ui brown basic label">Shared Experiences</span><span class="ui brown basic label">Teleoperation</span><span class="ui brown basic label">Drones</span><span class="ui brown basic label">Collaboration</span><span class="ui brown basic label">Hri</span></div></p></div></div></div><div id="publications-modal"><div id="chi-2025-madill" class="ui large modal"><div class="header"><a href="publications/chi-2025-madill" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2025-madill</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2025</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2025-madill.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/chi-2025-madill" target="_blank">Playing with Robots: Performing Arts Techniques for Designing and Understanding Robot Group Movement</a></h1><p class="meta"><span>Philippa Madill</span> , <span>Matthew Newton</span> , <span>Huanjun Zhao</span> , <span>Yichen Lian</span> , <a href="people/zachary-mckendrick"><img src="static/images/people/zachary-mckendrick.jpg" class="ui circular spaced image mini-profile"/><strong>Zachary McKendrick</strong></a> , <span>Patrick Finn</span> , <a href="people/aditya-shekhar-nittala"><img src="static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><strong>Aditya Shekhar Nittala</strong></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2025-madill.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2025-madill.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>In this work, we introduce a formal design approach derived from the performing arts to design robot group behaviour. In our first experiment, we worked with professional actors, directors, and non-specialists using a participatory design approach to identify common group behaviour patterns. In a follow-up studio work, we identified twelve common group movement patterns, transposed them into a performance script, built a scale model to support the performance process, and evaluated the patterns with a senior actor under studio conditions. We evaluated our refined models with 20 volunteers in a user study in the third experiment. Results from our affective circumplex modelling suggest that the patterns elicit positive emotional responses from the users. Also, participants performed better than chance in identifying the motion patterns without prior training. Based on our results, we propose design guidelines for social robots’ behaviour and movement design to improve their overall comprehensibility in interaction.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Humanities</span><span class="ui brown basic label">Art</span><span class="ui brown basic label">Robots</span><span class="ui brown basic label">Method</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Philippa Madill<!-- -->, <!-- -->Matthew Newton<!-- -->, <!-- -->Huanjun Zhao<!-- -->, <!-- -->Yichen Lian<!-- -->, <!-- -->Zachary McKendrick<!-- -->, <!-- -->Patrick Finn<!-- -->, <!-- -->Aditya Shekhar Nittala<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Playing with Robots: Performing Arts Techniques for Designing and Understanding Robot Group Movement</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;25)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->.  DOI: <a href="https://dl.acm.org/doi/10.1145/3706598.3713996" target="_blank">https://dl.acm.org/doi/10.1145/3706598.3713996</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2021-asha" class="ui large modal"><div class="header"><a href="publications/dis-2021-asha" target="_blank"><i class="fas fa-link fa-fw"></i>dis-2021-asha</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">DIS 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/dis-2021-asha.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/dis-2021-asha" target="_blank">Co-Designing Interactions between Pedestrians in Wheelchairs and Autonomous Vehicles</a></h1><p class="meta"><a href="people/ashratuz-zavin-asha"><img src="static/images/people/ashratuz-zavin-asha.jpg" class="ui circular spaced image mini-profile"/><strong>Ashratuz Zavin Asha</strong></a> , <a href="people/christopher-smith"><img src="static/images/people/christopher-smith.jpg" class="ui circular spaced image mini-profile"/><strong>Christopher Smith</strong></a> , <a href="people/georgina-freeman"><img src="static/images/people/georgina-freeman.jpg" class="ui circular spaced image mini-profile"/><strong>Georgina Freeman</strong></a> , <span>Sean Crump</span> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/dis-2021-asha.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>dis-2021-asha.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>In the near future, mixed traffic consisting of manual and autonomous vehicles (AVs) will be common. Questions surrounding how vulnerable road users such as pedestrians in wheelchairs (PWs) will make crossing decisions in these new situations are underexplored. We conducted a remote co-design study with one of the researchers of this work who has the lived experience as a powered wheelchair user and applied inclusive design practices. This allowed us to identify and reflect on interface design ideas that can help PWs make safe crossing decisions at intersections. Through an iterative five-week study, we implemented interfaces that can be placed on the vehicle, on the wheelchair, and on the street infrastructure and evaluated them during the co-design sessions using a VR simulator testbed. Informed by our findings, we discuss design insights for implementing inclusive interfaces to improve interactions between autonomous vehicles and vulnerable road users.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Pedestrians In Wheelchairs</span><span class="ui brown basic label">Co Design</span><span class="ui brown basic label">Autonomous Vehicles</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Ashratuz Zavin Asha<!-- -->, <!-- -->Christopher Smith<!-- -->, <!-- -->Georgina Freeman<!-- -->, <!-- -->Sean Crump<!-- -->, <!-- -->Sowmya Somanath<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Co-Designing Interactions between Pedestrians in Wheelchairs and Autonomous Vehicles</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;21)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="10.1145/3461778.3462068" target="_blank">10.1145/3461778.3462068</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2021-hammad" class="ui large modal"><div class="header"><a href="publications/chi-2021-hammad" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2021-hammad</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2021</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2021-hammad.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/chi-2021-hammad" target="_blank">Homecoming: Exploring Returns to Long-Term Single Player Games</a></h1><p class="meta"><span>Noor Hammad</span> , <span>Owen Brierley</span> , <a href="people/zachary-mckendrick"><img src="static/images/people/zachary-mckendrick.jpg" class="ui circular spaced image mini-profile"/><strong>Zachary McKendrick</strong></a> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <span>Patrick Finn</span> , <span>Jessica Hammer</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2021-hammad.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2021-hammad.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We present an autobiographical design journey exploring the experience of returning to long-term single player games. Continuing progress from a previously saved game, particularly when substantial time has passed, is an understudied area in games research. To begin our exploration in this domain, we investigated what the return experience is like first-hand. By returning to four long-term single player games played extensively in the past, we revealed a phenomenon we call The Pivot Point, a ‘eureka’ moment in return gameplay. The pivot point anchors our design explorations, where we created prototypes to leverage the pivot point in reconnecting with the experience. These return experiences and subsequent prototyping iterations inform our understanding of how to design better returns to gameplay, which can benefit both producers and consumers of long-term single player games.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Long Term Single Player Game</span><span class="ui brown basic label">Autobiographical Design</span><span class="ui brown basic label">Pivot Point</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Noor Hammad<!-- -->, <!-- -->Owen Brierley<!-- -->, <!-- -->Zachary McKendrick<!-- -->, <!-- -->Sowmya Somanath<!-- -->, <!-- -->Patrick Finn<!-- -->, <!-- -->Jessica Hammer<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Homecoming: Exploring Returns to Long-Term Single Player Games</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;21)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3411764.3445357" target="_blank">https://doi.org/10.1145/3411764.3445357</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="imwut-2020-wang" class="ui large modal"><div class="header"><a href="publications/imwut-2020-wang" target="_blank"><i class="fas fa-link fa-fw"></i>imwut-2020-wang</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">IMWUT 2020</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/imwut-2020-wang.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/imwut-2020-wang" target="_blank">AssessBlocks: Exploring Toy Block Play Features for Assessing Stress in Young Children after Natural Disasters</a></h1><p class="meta"><span>Xiyue Wang</span> , <span>Kazuki Takashima</span> , <span>Tomoaki Adachi</span> , <span>Patrick Finn</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a> , <span>Yoshifumi Kitamura</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/imwut-2020-wang.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>imwut-2020-wang.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/fxxvZBY80ug" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/fxxvZBY80ug?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/fxxvZBY80ug/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Natural disasters cause long-lasting mental health problems such as PTSD in children. Following the 2011 Earthquake and Tsunami in Japan, we witnessed a shift of toy block play behavior in young children who suffered from stress after the disaster. The behavior reflected their emotional responses to the traumatic event. In this paper, we explore the feasibility of using data captured from block-play to assess children&#x27;s stress after a major natural disaster. We prototyped sets of sensor-embedded toy blocks, AssessBlocks, that automate quantitative play data acquisition. During a three-year period, the blocks were dispatched to fifty-two post-disaster children. Within a free play session, we captured block features, a child&#x27;s playing behavior, and stress evaluated by several methods. The result from our analysis reveal correlations between block play features and stress measurements and show initial promise of using the effectiveness of using AssessBlocks to assess children&#x27;s stress after a disaster. We provide detailed insights into the potential as well as the challenges of our approach and unique conditions. From these insights we summarize guidelines for future research in automated play assessment systems that support children&#x27;s mental health.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Well Being</span><span class="ui brown basic label">Toy Blocks</span><span class="ui brown basic label">PTSD</span><span class="ui brown basic label">Tangibles For Health</span><span class="ui brown basic label">Stress Assessment</span><span class="ui brown basic label">Play</span><span class="ui brown basic label">Children</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Xiyue Wang<!-- -->, <!-- -->Kazuki Takashima<!-- -->, <!-- -->Tomoaki Adachi<!-- -->, <!-- -->Patrick Finn<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Yoshifumi Kitamura<!-- -->. <b>AssessBlocks: Exploring Toy Block Play Features for Assessing Stress in Young Children after Natural Disasters</b>. <i>In Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT &#x27;20)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->29<!-- -->.  DOI: <a href="https://doi.org/10.1145/3381016" target="_blank">https://doi.org/10.1145/3381016</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2020-asha" class="ui large modal"><div class="header"><a href="publications/chi-2020-asha" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2020-asha</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2020 LBW</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2020-asha.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/chi-2020-asha" target="_blank">Views from the Wheelchair: Understanding Interaction between Autonomous Vehicle and Pedestrians with Reduced Mobility</a></h1><p class="meta"><a href="people/ashratuz-zavin-asha"><img src="static/images/people/ashratuz-zavin-asha.jpg" class="ui circular spaced image mini-profile"/><strong>Ashratuz Zavin Asha</strong></a> , <a href="people/christopher-smith"><img src="static/images/people/christopher-smith.jpg" class="ui circular spaced image mini-profile"/><strong>Christopher Smith</strong></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2020-asha.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2020-asha.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/JNc49desa44" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/JNc49desa44?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/JNc49desa44/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We are interested in the ways pedestrians will interact with autonomous vehicle (AV) in a future AV transportation ecosystem, when nonverbal cues from the driver such as eye movements, hand gestures, etc. are no longer provided. In this work, we examine a subset of this challenge: interaction between pedestrian with reduced mobility (PRM) and AV. This study explores interface designs between AVs and people in a wheelchair to help them interact with AVs by conducting a preliminary design study. We have assessed the data collected from the study using qualitative analysis and presented different findings on AV-PRM interactions. Our findings reflect on the importance of visual interfaces, changes to the wheelchair and the creative use of the street infrastructure.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Autonomous Vehicle</span><span class="ui brown basic label">Pedestrian With Reduced Mobility</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Ashratuz Zavin Asha<!-- -->, <!-- -->Christopher Smith<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Sowmya Somanath<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Views from the Wheelchair: Understanding Interaction between Autonomous Vehicle and Pedestrians with Reduced Mobility</b>. <i>In undefined (CHI 202 &#x27;BW)</i>. <!-- -->  Page: 1-<!-- -->8<!-- -->.  DOI: <a href="10.1145/3334480.3383041" target="_blank">10.1145/3334480.3383041</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2020-hou" class="ui large modal"><div class="header"><a href="publications/chi-2020-hou" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2020-hou</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2020</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2020-hou.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/chi-2020-hou" target="_blank">Autonomous Vehicle-Cyclist Interaction: Peril and Promise</a></h1><p class="meta"><span>Ming Hou</span> , <a href="people/karthik-mahadevan"><img src="static/images/people/karthik-mahadevan.jpg" class="ui circular spaced image mini-profile"/><strong>Karthik Mahadevan</strong></a> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2020-hou.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2020-hou.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/fsgbUeAaFfI" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/fsgbUeAaFfI?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/fsgbUeAaFfI/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Autonomous vehicles (AVs) will redefine interactions between road users. Presently, cyclists and drivers communicate through implicit cues (vehicle motion) and explicit but imprecise signals (hand gestures, horns). Future AVs could consistently communicate awareness and intent and other feedback to cyclists based on their sensor data. We present an exploration of AV-cyclist interaction, starting with preliminary design studies which informed the implementation of an immersive VR AV-cyclist simulator, and the design and evaluation of a number of AV-cyclist interfaces. Our findings suggest that AV-cyclist interfaces can improve rider confidence in lane merging scenarios. We contribute an AV-cyclist immersive simulator, insights on trade-offs of various aspects of AV-cyclist interaction design including modalities, location, and complexity, and positive results suggesting improved rider confidence due to AV-cyclist interaction. While we are encouraged by the potential positive impact AV-cyclist interfaces can have on cyclist culture, we also emphasize the risks over-reliance can pose to cyclists.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Autonomous Vehicle Cyclist Interaction</span><span class="ui brown basic label">Interfaces For Communicating Intent And Awareness</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Ming Hou<!-- -->, <!-- -->Karthik Mahadevan<!-- -->, <!-- -->Sowmya Somanath<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Lora Oehlberg<!-- -->. <b>Autonomous Vehicle-Cyclist Interaction: Peril and Promise</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;20)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/3313831.3376884" target="_blank">https://doi.org/10.1145/3313831.3376884</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/DtxkWAW9B1s" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/DtxkWAW9B1s?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/DtxkWAW9B1s/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="cnc-2019-hammad" class="ui large modal"><div class="header"><a href="publications/cnc-2019-hammad" target="_blank"><i class="fas fa-link fa-fw"></i>cnc-2019-hammad</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">C&amp;C 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/cnc-2019-hammad.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/cnc-2019-hammad" target="_blank">Mutation: Leveraging Performing Arts Practices in Cyborg Transitioning</a></h1><p class="meta"><a href="people/nour-hammad"><img src="static/images/people/nour-hammad.jpg" class="ui circular spaced image mini-profile"/><strong>Nour Hammad</strong></a> , <span>Elaheh Sanoubari</span> , <span>Patrick Finn</span> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <span>James E. Young</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/cnc-2019-hammad.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>cnc-2019-hammad.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/HFH59__Fkok" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/HFH59__Fkok?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/HFH59__Fkok/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We present Mutation: performing arts based approach that can help decrease the cognitive load associated with cyborg transitioning. Cyborgs are human-machine hybrids with organic and mechatronic body parts that can be implanted or worn. The transition into and out of experiencing additional body parts is not fully understood. Our goal is to draw from performing arts techniques in order to help decrease the cognitive load associated with becoming and unbecoming a cyborg. Actors constantly shift between states, whether from one character to another, or from pre- to post- performance. We contribute a straightforward adaptation of classic performing art practices to cyborg transitioning, and a study where actors used these protocols in order to enter a cyborg state, perform as a cyborg, and then exit the cyborg state. Our work on Mutation suggests that classic performing art practices can be useful in cyborg transitioning, as well as in other technology augmented experiences.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Interaction Design</span><span class="ui brown basic label">Cyborgs</span><span class="ui brown basic label">User Experience</span><span class="ui brown basic label">Performing Art Techniques</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Nour Hammad<!-- -->, <!-- -->Elaheh Sanoubari<!-- -->, <!-- -->Patrick Finn<!-- -->, <!-- -->Sowmya Somanath<!-- -->, <!-- -->James E. Young<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Mutation: Leveraging Performing Arts Practices in Cyborg Transitioning</b>. <i>In Proceedings of the ACM on Creativity and Cognition (C&amp;C &#x27;19)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->.  DOI: <a href="https://doi.org/10.1145/3325480.3325508" target="_blank">https://doi.org/10.1145/3325480.3325508</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2019-mahadevan" class="ui large modal"><div class="header"><a href="publications/dis-2019-mahadevan" target="_blank"><i class="fas fa-link fa-fw"></i>dis-2019-mahadevan</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">DIS 2019</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/dis-2019-mahadevan.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/dis-2019-mahadevan" target="_blank">AV-Pedestrian Interaction Design Using a Pedestrian Mixed Traffic Simulator</a></h1><p class="meta"><a href="people/karthik-mahadevan"><img src="static/images/people/karthik-mahadevan.jpg" class="ui circular spaced image mini-profile"/><strong>Karthik Mahadevan</strong></a> , <span>Elaheh Sanoubari</span> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <span>James E. Young</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/dis-2019-mahadevan.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>dis-2019-mahadevan.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>AV-pedestrian interaction will impact pedestrian safety, etiquette, and overall acceptance of AV technology. Evaluating AV-pedestrian interaction is challenging given limited availability of AVs and safety concerns. These challenges are compounded by &quot;mixed traffic&quot; conditions: studying AV-pedestrian interaction will be difficult in traffic consisting of vehicles varying in autonomy level. We propose immersive pedestrian simulators as design tools to study AV-pedestrian interaction, allowing rapid prototyping and evaluation of future AV-pedestrian interfaces. We present OnFoot: a VR-based simulator that immerses participants in mixed traffic conditions and allows examination of their behavior while controlling vehicles&#x27; autonomy-level, traffic and street characteristics, behavior of other virtual pedestrians, and integration of novel AV-pedestrian interfaces. We validated OnFoot against prior simulators and Wizard-of-Oz studies, and conducted a user study, manipulating vehicles&#x27; autonomy level, interfaces, and pedestrian group behavior. Our findings highlight the potential to use VR simulators as powerful tools for AV-pedestrian interaction design in mixed traffic.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Mixed Traffic</span><span class="ui brown basic label">Pedestrian Simulator</span><span class="ui brown basic label">Autonomous Vehicle Pedestrian Interaction</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Karthik Mahadevan<!-- -->, <!-- -->Elaheh Sanoubari<!-- -->, <!-- -->Sowmya Somanath<!-- -->, <!-- -->James E. Young<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>AV-Pedestrian Interaction Design Using a Pedestrian Mixed Traffic Simulator</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;19)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/3322276.3322328" target="_blank">https://doi.org/10.1145/3322276.3322328</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2018-ta" class="ui large modal"><div class="header"><a href="publications/dis-2018-ta" target="_blank"><i class="fas fa-link fa-fw"></i>dis-2018-ta</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">DIS 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/dis-2018-ta.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/dis-2018-ta" target="_blank">Bod-IDE: An Augmented Reality Sandbox for eFashion Garments</a></h1><p class="meta"><span>Kevin Ta</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/dis-2018-ta.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>dis-2018-ta.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>Electronic fashion (eFashion) garments use technology to augment the human body with wearable interaction. In developing ideas, eFashion designers need to prototype the role and behavior of the interactive garment in context; however, current wearable prototyping toolkits require semi-permanent construction with physical materials that cannot easily be altered. We present Bod-IDE, an augmented reality &#x27;mirror&#x27; that allows eFashion designers to create virtual interactive garment prototypes. Designers can quickly build, refine, and test on-the-body interactions without the need to connect or program electronics. By envisioning interaction with the body in mind, eFashion designers can focus more on reimagining the relationship between bodies, clothing, and technology.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Augmented Reality</span><span class="ui brown basic label">Electronic Fashion</span><span class="ui brown basic label">Creativity Support Tool</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kevin Ta<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Lora Oehlberg<!-- -->. <b>Bod-IDE: An Augmented Reality Sandbox for eFashion Garments</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->5<!-- -->.  DOI: <a href="https://doi.org/10.1145/3197391.3205408" target="_blank">https://doi.org/10.1145/3197391.3205408</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="tei-2016-somanath" class="ui large modal"><div class="header"><a href="publications/tei-2016-somanath" target="_blank"><i class="fas fa-link fa-fw"></i>tei-2016-somanath</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">TEI 2016</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/tei-2016-somanath.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/tei-2016-somanath" target="_blank">Engaging &#x27;At-Risk&#x27; Students through Maker Culture Activities</a></h1><p class="meta"><a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <span>Laura Morrison</span> , <span>Janette Hughes</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a> , <span>Mario Costa Sousa</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/tei-2016-somanath.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>tei-2016-somanath.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>This paper presents a set of lessons learnt from introducing maker culture and DIY paradigms to &#x27;at-risk&#x27; students (age 12-14). Our goal is to engage &#x27;at-risk&#x27; students through maker culture activities. While improved technology literacy is one of the outcomes we also wanted the learners to use technology to realize concepts and ideas, and to gain freedom of thinking similar to creators, artists and designers. We present our study and a set of high level suggestions to enable thinking about how maker culture activities can facilitate engagement and creative use of technology by 1) thinking about creativity in task, 2) facilitating different entry points, 3) the importance of personal relevance, and 4) relevance to education.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">DIY</span><span class="ui brown basic label">At Risk Students</span><span class="ui brown basic label">Maker Culture</span><span class="ui brown basic label">Education</span><span class="ui brown basic label">Young Learners</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Sowmya Somanath<!-- -->, <!-- -->Laura Morrison<!-- -->, <!-- -->Janette Hughes<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Mario Costa Sousa<!-- -->. <b>Engaging &#x27;At-Risk&#x27; Students through Maker Culture Activities</b>. <i>In Proceedings of the International Conference on Tangible, Embedded, and Embodied Interaction (TEI &#x27;16)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->9<!-- -->.  DOI: <a href="https://doi.org/10.1145/2839462.2839482" target="_blank">https://doi.org/10.1145/2839462.2839482</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2018-feick" class="ui large modal"><div class="header"><a href="publications/chi-2018-feick" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2018-feick</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2018-feick.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/chi-2018-feick" target="_blank">Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration</a></h1><p class="meta"><a href="people/martin-feick"><img src="static/images/people/martin-feick.jpg" class="ui circular spaced image mini-profile"/><strong>Martin Feick</strong></a> , <span>Terrance Tin Hoi Mok</span> , <a href="people/anthony-tang"><img src="static/images/people/anthony-tang.jpg" class="ui circular spaced image mini-profile"/><strong>Anthony Tang</strong></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2018-feick.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2018-feick.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/sfxTHsPJWHY" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/sfxTHsPJWHY?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/sfxTHsPJWHY/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Remote collaborators working together on physical objects have difficulty building a shared understanding of what each person is talking about. Conventional video chat systems are insufficient for many situations because they present a single view of the object in a flattened image. To understand how this limited perspective affects collaboration, we designed the Remote Manipulator (ReMa), which can reproduce orientation manipulations on a proxy object at a remote site. We conducted two studies with ReMa, with two main findings. First, a shared perspective is more effective and preferred compared to the opposing perspective offered by conventional video chat systems. Second, the physical proxy and video chat complement one another in a combined system: people used the physical proxy to understand objects, and used video chat to perform gestures and confirm remote actions.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Object Focused Collaboration</span><span class="ui brown basic label">Physical Telepresence</span><span class="ui brown basic label">Collaborative Physical Tasks</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Martin Feick<!-- -->, <!-- -->Terrance Tin Hoi Mok<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173574.3173855" target="_blank">https://doi.org/10.1145/3173574.3173855</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2018-mahadevan" class="ui large modal"><div class="header"><a href="publications/chi-2018-mahadevan" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2018-mahadevan</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2018-mahadevan.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/chi-2018-mahadevan" target="_blank">Communicating Awareness and Intent in Autonomous Vehicle-Pedestrian Interaction</a></h1><p class="meta"><a href="people/karthik-mahadevan"><img src="static/images/people/karthik-mahadevan.jpg" class="ui circular spaced image mini-profile"/><strong>Karthik Mahadevan</strong></a> , <a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2018-mahadevan.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2018-mahadevan.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/D_hhcGVREGA" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/D_hhcGVREGA?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/D_hhcGVREGA/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Drivers use nonverbal cues such as vehicle speed, eye gaze, and hand gestures to communicate awareness and intent to pedestrians. Conversely, in autonomous vehicles, drivers can be distracted or absent, leaving pedestrians to infer awareness and intent from the vehicle alone. In this paper, we investigate the usefulness of interfaces (beyond vehicle movement) that explicitly communicate awareness and intent of autonomous vehicles to pedestrians, focusing on crosswalk scenarios. We conducted a preliminary study to gain insight on designing interfaces that communicate autonomous vehicle awareness and intent to pedestrians. Based on study outcomes, we developed four prototype interfaces and deployed them in studies involving a Segway and a car. We found interfaces communicating vehicle awareness and intent: (1) can help pedestrians attempting to cross; (2) are not limited to the vehicle and can exist in the environment; and (3) should use a combination of modalities such as visual, auditory, and physical.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Autonomous Vehicle Pedestrian Interaction</span><span class="ui brown basic label">Perceived Awareness And Intent In Autonomous Vehicles</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Karthik Mahadevan<!-- -->, <!-- -->Sowmya Somanath<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Communicating Awareness and Intent in Autonomous Vehicle-Pedestrian Interaction</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->12<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173574.3174003" target="_blank">https://doi.org/10.1145/3173574.3174003</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/08OEKuz93dY" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/08OEKuz93dY?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/08OEKuz93dY/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="hri-2018-feick" class="ui large modal"><div class="header"><a href="publications/hri-2018-feick" target="_blank"><i class="fas fa-link fa-fw"></i>hri-2018-feick</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">HRI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/hri-2018-feick.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/hri-2018-feick" target="_blank">The Way You Move: The Effect of a Robot Surrogate Movement in Remote Collaboration</a></h1><p class="meta"><a href="people/martin-feick"><img src="static/images/people/martin-feick.jpg" class="ui circular spaced image mini-profile"/><strong>Martin Feick</strong></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <a href="people/anthony-tang"><img src="static/images/people/anthony-tang.jpg" class="ui circular spaced image mini-profile"/><strong>Anthony Tang</strong></a> , <span>André Miede</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/hri-2018-feick.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>hri-2018-feick.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>In this paper, we discuss the role of the movement trajectory and velocity enabled by our tele-robotic system (ReMa) for remote collaboration on physical tasks. Our system reproduces changes in object orientation and position at a remote location using a humanoid robotic arm. However, even minor kinematics differences between robot and human arm can result in awkward or exaggerated robot movements. As a result, user communication with the robotic system can become less efficient, less fluent and more time intensive.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Movement Trajectory Velocity</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Robot Surrogate</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Martin Feick<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->André Miede<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>The Way You Move: The Effect of a Robot Surrogate Movement in Remote Collaboration</b>. <i>In Adjunct Adjunct Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction (HRI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->2<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173386.3176959" target="_blank">https://doi.org/10.1145/3173386.3176959</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="sui-2017-li" class="ui large modal"><div class="header"><a href="publications/sui-2017-li" target="_blank"><i class="fas fa-link fa-fw"></i>sui-2017-li</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">SUI 2017</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/sui-2017-li.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/sui-2017-li" target="_blank">Visibility Perception and Dynamic Viewsheds for Topographic Maps and Models</a></h1><p class="meta"><span>Nico Li</span> , <a href="people/wesley-willett"><img src="static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a> , <span>Mario Costa Sousa</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/sui-2017-li.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>sui-2017-li.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://player.vimeo.com/video/275404995" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://player.vimeo.com/video/275404995?autoplay=1&gt;&lt;img src=https://i.vimeocdn.com/video/707686230_640.webp&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We compare the effectiveness of 2D maps and 3D terrain models for visibility tasks and demonstrate how interactive dynamic viewsheds can improve performance for both types of terrain representations. In general, the two-dimensional nature of classic topographic maps limits their legibility and can make complex yet typical cartographic tasks like determining the visibility between locations difficult. Both 3D physical models and interactive techniques like dynamic viewsheds have the potential to improve viewers&#x27; understanding of topography, but their impact has not been deeply explored. We evaluate the effectiveness of 2D maps, 3D models, and interactive viewsheds for both simple and complex visibility tasks. Our results demonstrate the benefits of the dynamic viewshed technique and highlight opportunities for additional tactile interactions. Based on these findings we present guidelines for improving the design and usability of future topographic maps and models.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Terrain Visualization</span><span class="ui brown basic label">Geospatial Visualization</span><span class="ui brown basic label">Dynamic Viewshed</span><span class="ui brown basic label">Topographic Maps</span><span class="ui brown basic label">Tangible User Interfaces</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Nico Li<!-- -->, <!-- -->Wesley Willett<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Mario Costa Sousa<!-- -->. <b>Visibility Perception and Dynamic Viewsheds for Topographic Maps and Models</b>. <i>In undefined (SUI &#x27;17)</i>. <!-- -->  Page: 1-<!-- -->9<!-- -->.  DOI: <a href="https://doi.org/10.1145/3131277.3132178" target="_blank">https://doi.org/10.1145/3131277.3132178</a></p></div></div><div class="block"><h1>Talk</h1><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/aVXUojoQF60" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/aVXUojoQF60?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/aVXUojoQF60/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2017-somanath" class="ui large modal"><div class="header"><a href="publications/chi-2017-somanath" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2017-somanath</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2017</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/chi-2017-somanath.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/chi-2017-somanath" target="_blank">&#x27;Maker&#x27; within Constraints: Exploratory Study of Young Learners using Arduino at a High School in India</a></h1><p class="meta"><a href="people/sowmya-somanath"><img src="static/images/people/sowmya-somanath.jpg" class="ui circular spaced image mini-profile"/><strong>Sowmya Somanath</strong></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <span>Janette Hughes</span> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a> , <span>Mario Costa Sousa</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2017-somanath.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2017-somanath.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/NpIME1h1mH8" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/NpIME1h1mH8?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/NpIME1h1mH8/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Do-it-yourself (DIY) inspired activities have gained popularity as a means of creative expression and self-directed learning. However, DIY culture is difficult to implement in places with limited technology infrastructure and traditional learning cultures. Our goal is to understand how learners in such a setting react to DIY activities. We present observations from a physical computing workshop with 12 students (13-15 years old) conducted at a high school in India. We observed unique challenges for these students when tackling DIY activities: a high monetary and psychological cost to exploration, limited independent learning resources, difficulties with finding intellectual courage and assumed technical language proficiency. Our participants, however, overcome some of these challenges by adopting their own local strategies: resilience, nonverbal and verbal learning techniques, and creating documentation and fallback circuit versions. Based on our findings, we discuss a set of lessons learned about makerspaces in a context with socio-technical challenges.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">India</span><span class="ui brown basic label">HCI 4 D</span><span class="ui brown basic label">Physical Computing</span><span class="ui brown basic label">DIY</span><span class="ui brown basic label">Young Learners</span><span class="ui brown basic label">Maker Culture</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Sowmya Somanath<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Janette Hughes<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Mario Costa Sousa<!-- -->. <b>&#x27;Maker&#x27; within Constraints: Exploratory Study of Young Learners using Arduino at a High School in India</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;17)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3025453.3025849" target="_blank">https://doi.org/10.1145/3025453.3025849</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="dis-2016-jones" class="ui large modal"><div class="header"><a href="publications/dis-2016-jones" target="_blank"><i class="fas fa-link fa-fw"></i>dis-2016-jones</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="publications">Publications</a><i class="right angle icon divider"></i><a class="active section">DIS 2016</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="static/images/publications/cover/dis-2016-jones.jpg"/></div><div class="thirteen wide column"><h1><a href="publications/dis-2016-jones" target="_blank">Elevating Communication, Collaboration, and Shared Experiences in Mobile Video through Drones</a></h1><p class="meta"><a href="people/brennan-jones"><img src="static/images/people/brennan-jones.jpg" class="ui circular spaced image mini-profile"/><strong>Brennan Jones</strong></a> , <span>Kody Dillman</span> , <span>Richard Tang</span> , <a href="people/anthony-tang"><img src="static/images/people/anthony-tang.jpg" class="ui circular spaced image mini-profile"/><strong>Anthony Tang</strong></a> , <a href="people/ehud-sharlin"><img src="static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a> , <a href="people/lora-oehlberg"><img src="static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <a href="people/carman-neustaedter"><img src="static/images/people/carman-neustaedter.jpg" class="ui circular spaced image mini-profile"/><strong>Carman Neustaedter</strong></a> , <span>Scott Bateman</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/dis-2016-jones.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>dis-2016-jones.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/10hbJHIQVX8" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/10hbJHIQVX8?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/10hbJHIQVX8/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>People are increasingly using mobile video to communicate, collaborate, and share experiences while on the go. Yet this presents challenges in adequately sharing camera views with remote users. In this paper, we study the use of semi-autonomous drones for video conferencing, where an outdoor user (using a smartphone) is connected to a desktop user who can explore the environment from the drone&#x27;s perspective. We describe findings from a study where pairs collaborated to complete shared navigation and search tasks. We illustrate the benefits of providing the desktop user with a view that is elevated, manipulable, and decoupled from the outdoor user. In addition, we articulate how participants overcame challenges in communicating environmental information and navigational cues, negotiated control of the view, and used the drone as a tool for sharing experiences. This provides a new way of thinking about mobile video conferencing where cameras that are decoupled from both users play an integral role in communication, collaboration, and sharing experiences.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Telepresence</span><span class="ui brown basic label">Video Communication</span><span class="ui brown basic label">Shared Experiences</span><span class="ui brown basic label">Teleoperation</span><span class="ui brown basic label">Drones</span><span class="ui brown basic label">Collaboration</span><span class="ui brown basic label">Hri</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Brennan Jones<!-- -->, <!-- -->Kody Dillman<!-- -->, <!-- -->Richard Tang<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Ehud Sharlin<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Carman Neustaedter<!-- -->, <!-- -->Scott Bateman<!-- -->. <b>Elevating Communication, Collaboration, and Shared Experiences in Mobile Video through Drones</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;16)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/2901790.2901847" target="_blank">https://doi.org/10.1145/2901790.2901847</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img style="max-width:180px;margin:30px auto" src="static/images/logo-6.png"/><div class="content"><img style="max-width:200px;margin:0px auto" src="static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{"id":"ehud-sharlin"}},"page":"person","query":{"id":"ehud-sharlin"},"buildId":"hmNAYcqzNONa-Ruzzzu6c","dynamicBuildId":false,"nextExport":true}</script><script async="" id="__NEXT_PAGE__/person" src="_next/static/hmNAYcqzNONa-Ruzzzu6c/pages/person.js"></script><script async="" id="__NEXT_PAGE__/_app" src="_next/static/hmNAYcqzNONa-Ruzzzu6c/pages/_app.js"></script><script src="_next/static/runtime/webpack-8ed9452df514b4d17d80.js" async=""></script><script src="_next/static/chunks/commons.0c93cb8d3516282dd2c4.js" async=""></script><script src="_next/static/runtime/main-563fdde58a64bdca21c4.js" async=""></script></body></html>
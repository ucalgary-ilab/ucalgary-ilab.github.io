<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><title data-next-head="">Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="anthropographics, demographic data, diversity, marginalized populations" data-next-head=""/><meta name="description" content="We explore the potential of generative AI text-to-image models to help designers efficiently craft unique, representative, and demographically diverse anthropographics that visualize data about people. Currently, creating data-driven iconic images to represent individuals in a dataset often requires considerable design effort. Generative text-to-image models can streamline the process of creating these images, but risk perpetuating designer biases in addition to stereotypes latent in the models. In response, we outline a conceptual workflow for crafting anthropographic assets for visualizations, highlighting possible sources of risk and bias as well as opportunities for reflection and refinement by a human designer. Using an implementation of this workflow with Stable Diffusion and Google Colab, we illustrate a variety of new anthropographic designs that showcase the visual expressiveness and scalability of these generative approaches. Based on our experiments, we also identify challenges and research opportunities for new AI-enabled anthropographic visualization tools." data-next-head=""/><meta property="og:title" content="Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta property="og:description" content="We explore the potential of generative AI text-to-image models to help designers efficiently craft unique, representative, and demographically diverse anthropographics that visualize data about people. Currently, creating data-driven iconic images to represent individuals in a dataset often requires considerable design effort. Generative text-to-image models can streamline the process of creating these images, but risk perpetuating designer biases in addition to stereotypes latent in the models. In response, we outline a conceptual workflow for crafting anthropographic assets for visualizations, highlighting possible sources of risk and bias as well as opportunities for reflection and refinement by a human designer. Using an implementation of this workflow with Stable Diffusion and Google Colab, we illustrate a variety of new anthropographic designs that showcase the visual expressiveness and scalability of these generative approaches. Based on our experiments, we also identify challenges and research opportunities for new AI-enabled anthropographic visualization tools." data-next-head=""/><meta property="og:site_name" content="University of Calgary Interactions Lab" data-next-head=""/><meta property="og:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/chi-2024-dhawka.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:title" content="Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta name="twitter:description" content="We explore the potential of generative AI text-to-image models to help designers efficiently craft unique, representative, and demographically diverse anthropographics that visualize data about people. Currently, creating data-driven iconic images to represent individuals in a dataset often requires considerable design effort. Generative text-to-image models can streamline the process of creating these images, but risk perpetuating designer biases in addition to stereotypes latent in the models. In response, we outline a conceptual workflow for crafting anthropographic assets for visualizations, highlighting possible sources of risk and bias as well as opportunities for reflection and refinement by a human designer. Using an implementation of this workflow with Stable Diffusion and Google Colab, we illustrate a variety of new anthropographic designs that showcase the visual expressiveness and scalability of these generative approaches. Based on our experiments, we also identify challenges and research opportunities for new AI-enabled anthropographic visualization tools." data-next-head=""/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/chi-2024-dhawka.jpg" data-next-head=""/><meta name="twitter:card" content="summary" data-next-head=""/><meta name="twitter:site" content="@ucalgary" data-next-head=""/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link rel="preload" href="/pr-preview/pr-119/_next/static/media/dc84b505c4b06e35-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/pr-preview/pr-119/_next/static/css/166b884a4fa23da5.css" as="style"/><link rel="preload" href="/pr-preview/pr-119/_next/static/css/fddaaa684739fd85.css" as="style"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              // $('.ui.sidebar')
              //   .sidebar('attach events', '.sidebar.icon')

              $('.sidebar.icon').on('click', function(event) {
                $('.ui.sidebar')
                  .sidebar('toggle')
              })

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><link rel="stylesheet" href="/pr-preview/pr-119/_next/static/css/166b884a4fa23da5.css" data-n-g=""/><link rel="stylesheet" href="/pr-preview/pr-119/_next/static/css/fddaaa684739fd85.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" noModule="" src="/pr-preview/pr-119/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/pr-preview/pr-119/_next/static/chunks/webpack-80f4257a9d9b51ec.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/340-0811f861fdc48158.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/main-237fefe93cf728ed.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/vendor-styles-645b1da9d3c23d5f.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/505-08c629510f2693f2.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/pages/_app-07645c635360276a.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/851-9ae2497a89059d76.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/649-9eade54d2ab75249.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/696-a5335f570829c66d.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/969-858ff5a9cc0fd621.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/chunks/pages/publications/%5Bid%5D-443e4bc73a80c2d3.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/QbIa86gIlcDZ778_GQ44B/_buildManifest.js" defer=""></script><script src="/pr-preview/pr-119/_next/static/QbIa86gIlcDZ778_GQ44B/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="__className_2318e8"><div class="ui center aligned container"><div class="ui secondary huge compact menu"><a class="item" href="/pr-preview/pr-119/"><img class="ui tiny image" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" style="color:transparent" srcSet="/pr-preview/pr-119/static/images/ilab-logo-3d.gif 1x" src="/pr-preview/pr-119/static/images/ilab-logo-3d.gif"/></a><a class="item" href="/pr-preview/pr-119/people/">People</a><a class="item" href="/pr-preview/pr-119/publications/">Research</a></div></div><div class="ui center aligned container"><div class="ui secondary huge compact menu"><a class="item" href="/pr-preview/pr-119/"><img class="ui tiny image" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" style="color:transparent" srcSet="/pr-preview/pr-119/static/images/ilab-logo-3d.gif 1x" src="/pr-preview/pr-119/static/images/ilab-logo-3d.gif"/></a><a class="item" href="/pr-preview/pr-119/people/">People</a><a class="item" href="/pr-preview/pr-119/publications/">Research</a></div></div><div class="pusher"><div class="ui stackable grid"><div class="one wide column"></div><div class="ten wide column centered" style="margin-top:30px"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/pr-preview/pr-119/publications/">Publications</a><svg data-prefix="fas" data-icon="angle-right" class="svg-inline--fa fa-angle-right" role="img" viewBox="0 0 256 512" aria-hidden="true"><path fill="currentColor" d="M247.1 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L179.2 256 41.9 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"></path></svg><a class="active section">CHI 2024</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img alt="chi-2024-dhawka cover" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="cover" style="color:transparent" srcSet="/pr-preview/pr-119/static/images/publications/cover/chi-2024-dhawka.jpg 1x" src="/pr-preview/pr-119/static/images/publications/cover/chi-2024-dhawka.jpg"/></div><div class="thirteen wide column"><h1>Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics</h1><p class="meta"><a href="/people/priya-dhawka"><img alt="priya-dhawka photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-119/static/images/people/priya-dhawka.jpg 1x" src="/pr-preview/pr-119/static/images/people/priya-dhawka.jpg"/><strong>Priya Dhawka</strong></a> , <span>Lauren Perera</span> , <a href="/people/wesley-willett"><img alt="wesley-willett photo" loading="lazy" width="0" height="0" decoding="async" data-nimg="1" class="ui circular spaced image mini-profile" style="color:transparent" srcSet="/pr-preview/pr-119/static/images/people/wesley-willett.jpg 1x" src="/pr-preview/pr-119/static/images/people/wesley-willett.jpg"/><strong>Wesley Willett</strong></a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/dCEFvx4AqIo" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/dCEFvx4AqIo?autoplay=1&gt;&lt;Image width={0} height={0} alt=https://img.youtube.com/vi/dCEFvx4AqIo/maxresdefault.jpg src=https://img.youtube.com/vi/dCEFvx4AqIo/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>We explore the potential of generative AI text-to-image models to help designers efficiently craft unique, representative, and demographically diverse anthropographics that visualize data about people. Currently, creating data-driven iconic images to represent individuals in a dataset often requires considerable design effort. Generative text-to-image models can streamline the process of creating these images, but risk perpetuating designer biases in addition to stereotypes latent in the models. In response, we outline a conceptual workflow for crafting anthropographic assets for visualizations, highlighting possible sources of risk and bias as well as opportunities for reflection and refinement by a human designer. Using an implementation of this workflow with Stable Diffusion and Google Colab, we illustrate a variety of new anthropographic designs that showcase the visual expressiveness and scalability of these generative approaches. Based on our experiments, we also identify challenges and research opportunities for new AI-enabled anthropographic visualization tools.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Anthropographics</span><span class="ui brown basic label">Demographic Data</span><span class="ui brown basic label">Diversity</span><span class="ui brown basic label">Marginalized Populations</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Priya Dhawka<!-- -->, <!-- -->Lauren Perera<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Better Little People Pictures: Generative Creation of Demographically Diverse Anthropographics</b>. <i>In <!-- -->Proceedings of the CHI Conference on Human Factors in Computing Systems<!-- -->(<!-- -->CHI 2024<!-- -->)</i>. <!-- -->ACM, New York, NY, USA<!-- --> <!-- -->DOI: <a href="https://doi.org/10.1145/3613904.3641957" target="_blank">https://doi.org/10.1145/3613904.3641957</a></p></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><div class="content"><a href="https://ucalgary.ca"><img alt="University of Calgary logo" loading="lazy" width="200" height="0" decoding="async" data-nimg="1" style="color:transparent;max-width:200px;margin:0px auto;height:auto" srcSet="/pr-preview/pr-119/static/images/logo-4.png 1x, /pr-preview/pr-119/static/images/logo-4.png 2x" src="/pr-preview/pr-119/static/images/logo-4.png"/></a><div class="sub header"><a class="item" href="https://cpsc.ucalgary.ca">Department of Computer Science</a></div></div></div></footer></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><div class="content"><a href="https://ucalgary.ca"><img alt="University of Calgary logo" loading="lazy" width="200" height="0" decoding="async" data-nimg="1" style="color:transparent;max-width:200px;margin:0px auto;height:auto" srcSet="/pr-preview/pr-119/static/images/logo-4.png 1x, /pr-preview/pr-119/static/images/logo-4.png 2x" src="/pr-preview/pr-119/static/images/logo-4.png"/></a><div class="sub header"><a class="item" href="https://cpsc.ucalgary.ca">Department of Computer Science</a></div></div></div></footer></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"ids":[{"id":"assets-2017-suzuki"},{"id":"assets-2023-mok"},{"id":"capstone-2025-haptic-floor-proxy"},{"id":"cga-2019-ivanov"},{"id":"cgi-2019-danyluk"},{"id":"chi-2015-aseniero"},{"id":"chi-2015-jones"},{"id":"chi-2015-oehlberg"},{"id":"chi-2015-willett"},{"id":"chi-2017-aoki"},{"id":"chi-2017-hull"},{"id":"chi-2017-ledo"},{"id":"chi-2017-somanath"},{"id":"chi-2018-dillman"},{"id":"chi-2018-feick"},{"id":"chi-2018-heshmat"},{"id":"chi-2018-ledo"},{"id":"chi-2018-mahadevan"},{"id":"chi-2018-neustaedter"},{"id":"chi-2018-oh"},{"id":"chi-2018-suzuki"},{"id":"chi-2018-wuertz"},{"id":"chi-2019-danyluk"},{"id":"chi-2019-george"},{"id":"chi-2020-anjani"},{"id":"chi-2020-asha"},{"id":"chi-2020-goffin"},{"id":"chi-2020-hou"},{"id":"chi-2020-suzuki"},{"id":"chi-2021-danyluk"},{"id":"chi-2021-ens"},{"id":"chi-2021-hammad"},{"id":"chi-2022-bressa"},{"id":"chi-2022-ivanov"},{"id":"chi-2022-nittala"},{"id":"chi-2022-suzuki"},{"id":"chi-2023-dhawka"},{"id":"chi-2023-faridan"},{"id":"chi-2023-monteiro"},{"id":"chi-2024-bressa"},{"id":"chi-2024-dhawka"},{"id":"chi-2024-panigrahy"},{"id":"chi-2025-ghaneezabadi"},{"id":"chi-2025-madill"},{"id":"chi-2025-shiokawa"},{"id":"chi-ea-2022-blair"},{"id":"chi-ea-2023-chulpongsatorn"},{"id":"chi-ea-2023-fang"},{"id":"cmj-2020-ko"},{"id":"cnc-2019-hammad"},{"id":"cupum-2021-rout"},{"id":"dis-2016-jones"},{"id":"dis-2017-mok"},{"id":"dis-2018-mikalauskas"},{"id":"dis-2018-pham"},{"id":"dis-2018-ta"},{"id":"dis-2019-blair"},{"id":"dis-2019-bressa"},{"id":"dis-2019-ledo"},{"id":"dis-2019-mahadevan"},{"id":"dis-2019-nakayama"},{"id":"dis-2019-seyed"},{"id":"dis-2021-asha"},{"id":"dis-2021-blair"},{"id":"dis-2021-wannamaker"},{"id":"dis-2023-li"},{"id":"dis-2024-danyluk"},{"id":"frobt-2022-suzuki"},{"id":"gecco-2022-ivanov"},{"id":"gi-2020-rajabiyazdi"},{"id":"gi-2021-mactavish"},{"id":"gi-2022-hull"},{"id":"haid-2020-frisson"},{"id":"hri-2018-feick"},{"id":"httf-2024-blair"},{"id":"ieee-2021-willett"},{"id":"ijac-2021-hosseini"},{"id":"imwut-2020-wang"},{"id":"imx-2020-mok"},{"id":"iros-2020-hedayati"},{"id":"iros-2022-suzuki"},{"id":"mdpi-actuators-2024-piao"},{"id":"mdpi-arts-2023-frisson"},{"id":"mobilehci-2015-ledo"},{"id":"mobilehci-2019-hung"},{"id":"nime-2020-kirkegaard"},{"id":"nime-2020-ko"},{"id":"nime-2022-frisson"},{"id":"siggraph-labs-2023-seta"},{"id":"sui-2017-li"},{"id":"tei-2016-somanath"},{"id":"tei-2019-mikalauskas"},{"id":"tei-2019-tolley"},{"id":"tei-2019-wun"},{"id":"tei-2020-suzuki"},{"id":"tei-2021-pratte"},{"id":"tochi-2022-nittala"},{"id":"tvcg-2016-lopez"},{"id":"tvcg-2017-goffin"},{"id":"tvcg-2017-willett"},{"id":"tvcg-2019-blascheck"},{"id":"tvcg-2019-walny"},{"id":"tvcg-2020-danyluk"},{"id":"uist-2018-suzuki"},{"id":"uist-2019-suzuki"},{"id":"uist-2020-suzuki"},{"id":"uist-2020-yixian"},{"id":"uist-2021-suzuki"},{"id":"uist-2022-kaimoto"},{"id":"uist-2022-liao"},{"id":"uist-2022-nisser"},{"id":"uist-2022-nittala"},{"id":"uist-2023-chulpongsatorn"},{"id":"uist-2023-ihara"},{"id":"uist-2023-mukashev"},{"id":"uist-2023-xia"},{"id":"uist-2023-xia2"},{"id":"uist-2024-gunturu"},{"id":"uist-2024-roy"},{"id":"uist-sic-2022-faridan"},{"id":"vr-2019-satriadi"},{"id":"vrst-2022-frisson"}]},"__N_SSG":true},"page":"/publications/[id]","query":{"id":"chi-2024-dhawka"},"buildId":"QbIa86gIlcDZ778_GQ44B","assetPrefix":"/pr-preview/pr-119","runtimeConfig":{"basePath":"/pr-preview/pr-119"},"isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>
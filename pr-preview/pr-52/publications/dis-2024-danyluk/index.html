<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><title data-next-head="">Understanding Gesture and Microgesture Inputs for Augmented Reality Maps | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="gestural input, microgestures, AR, maps" data-next-head=""/><meta name="description" content="We explore the potential for subtle on-hand gesture and microgesture interactions for map navigation with augmented reality (AR) devices. We describe a design exercise and follow-up elicitation study in which we identified on-hand gestures for cartographic interaction primitives. Microgestures and on-hand interactions are a promising space for AR map navigation as they offers always-available, tactile, and memorable spaces for interaction. Our findings show a clear set of microgesture interaction patterns that are well suited for supporting map navigation and manipulation. In particular, we highlight how the properties of various microgestures align with particular cartographic interaction tasks. We also describe our experience creating an exploratory proof-of-concept AR map prototype which helped us identify new opportunities and practical challenges for microgesture control. Finally, we discuss how future AR map systems could benefit from on-hand and microgesture input schemes." data-next-head=""/><meta property="og:title" content="Understanding Gesture and Microgesture Inputs for Augmented Reality Maps | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta property="og:description" content="We explore the potential for subtle on-hand gesture and microgesture interactions for map navigation with augmented reality (AR) devices. We describe a design exercise and follow-up elicitation study in which we identified on-hand gestures for cartographic interaction primitives. Microgestures and on-hand interactions are a promising space for AR map navigation as they offers always-available, tactile, and memorable spaces for interaction. Our findings show a clear set of microgesture interaction patterns that are well suited for supporting map navigation and manipulation. In particular, we highlight how the properties of various microgestures align with particular cartographic interaction tasks. We also describe our experience creating an exploratory proof-of-concept AR map prototype which helped us identify new opportunities and practical challenges for microgesture control. Finally, we discuss how future AR map systems could benefit from on-hand and microgesture input schemes." data-next-head=""/><meta property="og:site_name" content="University of Calgary Interactions Lab" data-next-head=""/><meta property="og:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/dis-2024-danyluk.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:title" content="Understanding Gesture and Microgesture Inputs for Augmented Reality Maps | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta name="twitter:description" content="We explore the potential for subtle on-hand gesture and microgesture interactions for map navigation with augmented reality (AR) devices. We describe a design exercise and follow-up elicitation study in which we identified on-hand gestures for cartographic interaction primitives. Microgestures and on-hand interactions are a promising space for AR map navigation as they offers always-available, tactile, and memorable spaces for interaction. Our findings show a clear set of microgesture interaction patterns that are well suited for supporting map navigation and manipulation. In particular, we highlight how the properties of various microgestures align with particular cartographic interaction tasks. We also describe our experience creating an exploratory proof-of-concept AR map prototype which helped us identify new opportunities and practical challenges for microgesture control. Finally, we discuss how future AR map systems could benefit from on-hand and microgesture input schemes." data-next-head=""/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/dis-2024-danyluk.jpg" data-next-head=""/><meta name="twitter:card" content="summary" data-next-head=""/><meta name="twitter:site" content="@ucalgary" data-next-head=""/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="format-detection" content="telephone=no"/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.css" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/css/lightbox.css" rel="stylesheet"/><link href="/static/css/style.css" rel="stylesheet"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox-plus-jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              $('.ui.sidebar')
                .sidebar('attach events', '.sidebar.icon')

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-a339f4a57035852b.js" defer=""></script><script src="/_next/static/chunks/framework-b1e5f14688f9ffe6.js" defer=""></script><script src="/_next/static/chunks/main-619a4c7e824c8b27.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9ccadb934b519984.js" defer=""></script><script src="/_next/static/chunks/7e42aecb-c9d29bee94cdcb2d.js" defer=""></script><script src="/_next/static/chunks/244-3cfd9bb0254716ab.js" defer=""></script><script src="/_next/static/chunks/79-1f13dfb9cd5d4218.js" defer=""></script><script src="/_next/static/chunks/143-862545ebf876f01e.js" defer=""></script><script src="/_next/static/chunks/pages/publication-e7d5970df319abca.js" defer=""></script><script src="/_next/static/ZVDgPlO3kfsgNkAKiskli/_buildManifest.js" defer=""></script><script src="/_next/static/ZVDgPlO3kfsgNkAKiskli/_ssgManifest.js" defer=""></script></head><body><link rel="preload" as="image" href="/static/images/publications/cover/dis-2024-danyluk.jpg"/><link rel="preload" as="image" href="/static/images/people/kurtis-danyluk.jpg"/><link rel="preload" as="image" href="/static/images/people/aditya-shekhar-nittala.jpg"/><link rel="preload" as="image" href="/static/images/people/wesley-willett.jpg"/><link rel="preload" as="image" href="/static/images/logo-6.png"/><link rel="preload" as="image" href="/static/images/logo-4.png"/><div id="__next"><div><div><div class="ui right vertical sidebar menu"><a class="item" href="/">Home</a><a class="item active" href="/publications">Publications</a><a class="item" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item active" href="/publications">Publications</a><a class="item" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a><div class="toc item"><a href="/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div></div><div class="ui stackable grid"><div class="one wide column"></div><div class="ten wide column centered" style="margin-top:30px"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">DIS 2024</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/dis-2024-danyluk.jpg"/></div><div class="thirteen wide column"><h1>Understanding Gesture and Microgesture Inputs for Augmented Reality Maps</h1><p class="meta"><a href="/people/kurtis-danyluk"><img src="/static/images/people/kurtis-danyluk.jpg" class="ui circular spaced image mini-profile"/><strong>Kurtis Danyluk</strong></a> , <span>Simon Klueber</span> , <a href="/people/aditya-shekhar-nittala"><img src="/static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><strong>Aditya Shekhar Nittala</strong></a> , <a href="/people/wesley-willett"><img src="/static/images/people/wesley-willett.jpg" class="ui circular spaced image mini-profile"/><strong>Wesley Willett</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/dis-2024-danyluk.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>dis-2024-danyluk.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>We explore the potential for subtle on-hand gesture and microgesture interactions for map navigation with augmented reality (AR) devices. We describe a design exercise and follow-up elicitation study in which we identified on-hand gestures for cartographic interaction primitives. Microgestures and on-hand interactions are a promising space for AR map navigation as they offers always-available, tactile, and memorable spaces for interaction. Our findings show a clear set of microgesture interaction patterns that are well suited for supporting map navigation and manipulation. In particular, we highlight how the properties of various microgestures align with particular cartographic interaction tasks. We also describe our experience creating an exploratory proof-of-concept AR map prototype which helped us identify new opportunities and practical challenges for microgesture control. Finally, we discuss how future AR map systems could benefit from on-hand and microgesture input schemes.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Gestural Input</span><span class="ui brown basic label">Microgestures</span><span class="ui brown basic label">AR</span><span class="ui brown basic label">Maps</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Kurtis Danyluk<!-- -->, <!-- -->Simon Klueber<!-- -->, <!-- -->Aditya Shekhar Nittala<!-- -->, <!-- -->Wesley Willett<!-- -->. <b>Understanding Gesture and Microgesture Inputs for Augmented Reality Maps</b>. <i>In Proceedings of the ACM on Designing Interactive Systems Conference (DIS &#x27;24)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->.  DOI: <a href="https://doi.org/10.1145/3643834.3661630" target="_blank">https://doi.org/10.1145/3643834.3661630</a></p></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img style="max-width:180px;margin:30px auto" src="/static/images/logo-6.png"/><div class="content"><img style="max-width:200px;margin:0px auto" src="/static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"id":"dis-2024-danyluk"}},"page":"/publication","query":{"id":"dis-2024-danyluk"},"buildId":"ZVDgPlO3kfsgNkAKiskli","nextExport":true,"isFallback":false,"gip":true}</script></body></html>
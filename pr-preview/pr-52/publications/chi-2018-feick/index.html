<!DOCTYPE html><html><head><meta charSet="utf-8" data-next-head=""/><meta name="viewport" content="width=device-width" data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><title data-next-head="">Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="cscw, remote collaboration, object-focused collaboration, physical telepresence, collaborative physical tasks" data-next-head=""/><meta name="description" content="Remote collaborators working together on physical objects have difficulty building a shared understanding of what each person is talking about. Conventional video chat systems are insufficient for many situations because they present a single view of the object in a flattened image. To understand how this limited perspective affects collaboration, we designed the Remote Manipulator (ReMa), which can reproduce orientation manipulations on a proxy object at a remote site. We conducted two studies with ReMa, with two main findings. First, a shared perspective is more effective and preferred compared to the opposing perspective offered by conventional video chat systems. Second, the physical proxy and video chat complement one another in a combined system: people used the physical proxy to understand objects, and used video chat to perform gestures and confirm remote actions." data-next-head=""/><meta property="og:title" content="Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta property="og:description" content="Remote collaborators working together on physical objects have difficulty building a shared understanding of what each person is talking about. Conventional video chat systems are insufficient for many situations because they present a single view of the object in a flattened image. To understand how this limited perspective affects collaboration, we designed the Remote Manipulator (ReMa), which can reproduce orientation manipulations on a proxy object at a remote site. We conducted two studies with ReMa, with two main findings. First, a shared perspective is more effective and preferred compared to the opposing perspective offered by conventional video chat systems. Second, the physical proxy and video chat complement one another in a combined system: people used the physical proxy to understand objects, and used video chat to perform gestures and confirm remote actions." data-next-head=""/><meta property="og:site_name" content="University of Calgary Interactions Lab" data-next-head=""/><meta property="og:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/chi-2018-feick.jpg" data-next-head=""/><meta property="og:type" content="website" data-next-head=""/><meta name="twitter:title" content="Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration | Interactions Lab - University of Calgary HCI Group" data-next-head=""/><meta name="twitter:description" content="Remote collaborators working together on physical objects have difficulty building a shared understanding of what each person is talking about. Conventional video chat systems are insufficient for many situations because they present a single view of the object in a flattened image. To understand how this limited perspective affects collaboration, we designed the Remote Manipulator (ReMa), which can reproduce orientation manipulations on a proxy object at a remote site. We conducted two studies with ReMa, with two main findings. First, a shared perspective is more effective and preferred compared to the opposing perspective offered by conventional video chat systems. Second, the physical proxy and video chat complement one another in a combined system: people used the physical proxy to understand objects, and used video chat to perform gestures and confirm remote actions." data-next-head=""/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/chi-2018-feick.jpg" data-next-head=""/><meta name="twitter:card" content="summary" data-next-head=""/><meta name="twitter:site" content="@ucalgary" data-next-head=""/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" data-next-head=""/><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="format-detection" content="telephone=no"/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.css" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/css/lightbox.css" rel="stylesheet"/><link href="/static/css/style.css" rel="stylesheet"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox-plus-jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              $('.ui.sidebar')
                .sidebar('attach events', '.sidebar.icon')

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><noscript data-n-css=""></noscript><script defer="" noModule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-a339f4a57035852b.js" defer=""></script><script src="/_next/static/chunks/framework-b1e5f14688f9ffe6.js" defer=""></script><script src="/_next/static/chunks/main-619a4c7e824c8b27.js" defer=""></script><script src="/_next/static/chunks/pages/_app-9ccadb934b519984.js" defer=""></script><script src="/_next/static/chunks/7e42aecb-c9d29bee94cdcb2d.js" defer=""></script><script src="/_next/static/chunks/244-3cfd9bb0254716ab.js" defer=""></script><script src="/_next/static/chunks/79-1f13dfb9cd5d4218.js" defer=""></script><script src="/_next/static/chunks/143-862545ebf876f01e.js" defer=""></script><script src="/_next/static/chunks/pages/publication-e7d5970df319abca.js" defer=""></script><script src="/_next/static/fH_DUTG3kbK13W1Tpnm8C/_buildManifest.js" defer=""></script><script src="/_next/static/fH_DUTG3kbK13W1Tpnm8C/_ssgManifest.js" defer=""></script></head><body><link rel="preload" as="image" href="/static/images/publications/cover/chi-2018-feick.jpg"/><link rel="preload" as="image" href="/static/images/people/martin-feick.jpg"/><link rel="preload" as="image" href="/static/images/people/anthony-tang.jpg"/><link rel="preload" as="image" href="/static/images/people/lora-oehlberg.jpg"/><link rel="preload" as="image" href="/static/images/people/ehud-sharlin.jpg"/><link rel="preload" as="image" href="/static/images/logo-6.png"/><link rel="preload" as="image" href="/static/images/logo-4.png"/><div id="__next"><div><div><div class="ui right vertical sidebar menu"><a class="item" href="/">Home</a><a class="item active" href="/publications">Publications</a><a class="item" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item active" href="/publications">Publications</a><a class="item" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a><div class="toc item"><a href="/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div></div><div class="ui stackable grid"><div class="one wide column"></div><div class="ten wide column centered" style="margin-top:30px"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2018</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2018-feick.jpg"/></div><div class="thirteen wide column"><h1>Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration</h1><p class="meta"><a href="/people/martin-feick"><img src="/static/images/people/martin-feick.jpg" class="ui circular spaced image mini-profile"/><strong>Martin Feick</strong></a> , <span>Terrance Tin Hoi Mok</span> , <a href="/people/anthony-tang"><img src="/static/images/people/anthony-tang.jpg" class="ui circular spaced image mini-profile"/><strong>Anthony Tang</strong></a> , <a href="/people/lora-oehlberg"><img src="/static/images/people/lora-oehlberg.jpg" class="ui circular spaced image mini-profile"/><strong>Lora Oehlberg</strong></a> , <a href="/people/ehud-sharlin"><img src="/static/images/people/ehud-sharlin.jpg" class="ui circular spaced image mini-profile"/><strong>Ehud Sharlin</strong></a></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/chi-2018-feick.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2018-feick.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/sfxTHsPJWHY" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/sfxTHsPJWHY?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/sfxTHsPJWHY/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowFullScreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Remote collaborators working together on physical objects have difficulty building a shared understanding of what each person is talking about. Conventional video chat systems are insufficient for many situations because they present a single view of the object in a flattened image. To understand how this limited perspective affects collaboration, we designed the Remote Manipulator (ReMa), which can reproduce orientation manipulations on a proxy object at a remote site. We conducted two studies with ReMa, with two main findings. First, a shared perspective is more effective and preferred compared to the opposing perspective offered by conventional video chat systems. Second, the physical proxy and video chat complement one another in a combined system: people used the physical proxy to understand objects, and used video chat to perform gestures and confirm remote actions.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Cscw</span><span class="ui brown basic label">Remote Collaboration</span><span class="ui brown basic label">Object Focused Collaboration</span><span class="ui brown basic label">Physical Telepresence</span><span class="ui brown basic label">Collaborative Physical Tasks</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Martin Feick<!-- -->, <!-- -->Terrance Tin Hoi Mok<!-- -->, <!-- -->Anthony Tang<!-- -->, <!-- -->Lora Oehlberg<!-- -->, <!-- -->Ehud Sharlin<!-- -->. <b>Perspective on and Re-orientation of Physical Proxies in Object-Focused Remote Collaboration</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;18)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->13<!-- -->.  DOI: <a href="https://doi.org/10.1145/3173574.3173855" target="_blank">https://doi.org/10.1145/3173574.3173855</a></p></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img style="max-width:180px;margin:30px auto" src="/static/images/logo-6.png"/><div class="content"><img style="max-width:200px;margin:0px auto" src="/static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"id":"chi-2018-feick"}},"page":"/publication","query":{"id":"chi-2018-feick"},"buildId":"fH_DUTG3kbK13W1Tpnm8C","nextExport":true,"isFallback":false,"gip":true}</script></body></html>
<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="format-detection" content="telephone=no"/><link href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.css" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/css/lightbox.css" rel="stylesheet"/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link href="/static/css/style.css" rel="stylesheet"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox-plus-jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              $('.ui.sidebar')
                .sidebar('attach events', '.sidebar.icon')

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><title class="next-head">CrossTalk: Intelligent Substrates for Language-Oriented Interaction in Video-Based Communication and Collaboration | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="Videoconferencing, Natural Language Interface, Language-oriented Interaction, Context-aware Computing" class="next-head"/><meta name="description" content="Despite the advances and ubiquity of digital communication media such as videoconferencing and virtual reality, they remain oblivious to the rich intentions expressed by users. Beyond transmitting audio, videos, and messages, we envision digital communication media as proactive facilitators that can provide unobtrusive assistance to enhance communication and collaboration. Informed by the results of a formative study, we propose three key design concepts to explore the systematic integration of intelligence into communication and collaboration, including the panel substrate, language-based intent recognition, and lightweight interaction techniques. We developed CrossTalk, a videoconferencing system that instantiates these concepts, which was found to enable a more fluid and flexible communication and collaboration experience." class="next-head"/><meta property="og:title" content="CrossTalk: Intelligent Substrates for Language-Oriented Interaction in Video-Based Communication and Collaboration | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta property="og:description" content="Despite the advances and ubiquity of digital communication media such as videoconferencing and virtual reality, they remain oblivious to the rich intentions expressed by users. Beyond transmitting audio, videos, and messages, we envision digital communication media as proactive facilitators that can provide unobtrusive assistance to enhance communication and collaboration. Informed by the results of a formative study, we propose three key design concepts to explore the systematic integration of intelligence into communication and collaboration, including the panel substrate, language-based intent recognition, and lightweight interaction techniques. We developed CrossTalk, a videoconferencing system that instantiates these concepts, which was found to enable a more fluid and flexible communication and collaboration experience." class="next-head"/><meta property="og:site_name" content="University of Calgary Interactions Lab" class="next-head"/><meta property="og:url" content="https://ilab.ucalgary.ca/" class="next-head"/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/uist-2023-xia2.jpg" class="next-head"/><meta property="og:type" content="website" class="next-head"/><meta name="twitter:title" content="CrossTalk: Intelligent Substrates for Language-Oriented Interaction in Video-Based Communication and Collaboration | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta name="twitter:description" content="Despite the advances and ubiquity of digital communication media such as videoconferencing and virtual reality, they remain oblivious to the rich intentions expressed by users. Beyond transmitting audio, videos, and messages, we envision digital communication media as proactive facilitators that can provide unobtrusive assistance to enhance communication and collaboration. Informed by the results of a formative study, we propose three key design concepts to explore the systematic integration of intelligence into communication and collaboration, including the panel substrate, language-based intent recognition, and lightweight interaction techniques. We developed CrossTalk, a videoconferencing system that instantiates these concepts, which was found to enable a more fluid and flexible communication and collaboration experience." class="next-head"/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/publications/cover/uist-2023-xia2.jpg" class="next-head"/><meta name="twitter:card" content="summary" class="next-head"/><meta name="twitter:site" content="@ucalgary" class="next-head"/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" class="next-head"/><link rel="preload" href="/_next/static/abOftCVXQ7bohEfVyBLWa/pages/publication.js" as="script"/><link rel="preload" href="/_next/static/abOftCVXQ7bohEfVyBLWa/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.0c93cb8d3516282dd2c4.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-563fdde58a64bdca21c4.js" as="script"/></head><body><div id="__next"><div><div><div class="ui right vertical sidebar menu"><a class="item" href="/">Home</a><a class="item active" href="/publications">Publications</a><a class="item" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item active" href="/publications">Publications</a><a class="item" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a><div class="toc item"><a href="/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div></div><div class="ui stackable grid"><div class="one wide column"></div><div class="ten wide column centered" style="margin-top:30px"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">UIST 2023</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/uist-2023-xia2.jpg"/></div><div class="thirteen wide column"><h1>CrossTalk: Intelligent Substrates for Language-Oriented Interaction in Video-Based Communication and Collaboration</h1><p class="meta"><span>Haijun Xia</span> , <span>Tony Wang</span> , <a href="/people/aditya-gunturu"><img src="/static/images/people/aditya-gunturu.jpg" class="ui circular spaced image mini-profile"/><strong>Aditya Gunturu</strong></a> , <span>Peiling Jiang</span> , <span>William Duan</span> , <span>Xiaoshuo Yao</span></p><p><a href="https://raw.githubusercontent.com/ucalgary-ilab/ucalgary-ilab.github.io/master/static/publications/uist-2023-xia2.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>uist-2023-xia2.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/8I1yXNRcm54" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/8I1yXNRcm54?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/8I1yXNRcm54/maxresdefault.jpg&gt;&lt;span&gt;â–¶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Despite the advances and ubiquity of digital communication media such as videoconferencing and virtual reality, they remain oblivious to the rich intentions expressed by users. Beyond transmitting audio, videos, and messages, we envision digital communication media as proactive facilitators that can provide unobtrusive assistance to enhance communication and collaboration. Informed by the results of a formative study, we propose three key design concepts to explore the systematic integration of intelligence into communication and collaboration, including the panel substrate, language-based intent recognition, and lightweight interaction techniques. We developed CrossTalk, a videoconferencing system that instantiates these concepts, which was found to enable a more fluid and flexible communication and collaboration experience.</p><div class="ui large basic labels">Keywords: Â <span class="ui brown basic label">Videoconferencing</span><span class="ui brown basic label">Natural Language Interface</span><span class="ui brown basic label">Language Oriented Interaction</span><span class="ui brown basic label">Context Aware Computing</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Haijun Xia<!-- -->, <!-- -->Tony Wang<!-- -->, <!-- -->Aditya Gunturu<!-- -->, <!-- -->Peiling Jiang<!-- -->, <!-- -->William Duan<!-- -->, <!-- -->Xiaoshuo Yao<!-- -->.Â <b>CrossTalk: Intelligent Substrates for Language-Oriented Interaction in Video-Based Communication and Collaboration</b>.Â <i>In Proceedings of the Annual ACM Symposium on User Interface Software and Technology (UIST &#x27;23)</i>.Â <!-- -->ACM, New York, NY, USA<!-- -->Â  Page: 1-<!-- -->16<!-- -->.Â  DOI: <a href="https://doi.org/10.1145/3586183.3606773" target="_blank">https://doi.org/10.1145/3586183.3606773</a></p></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img style="max-width:180px;margin:30px auto" src="/static/images/logo-6.png"/><div class="content"><img style="max-width:200px;margin:0px auto" src="/static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{"id":"uist-2023-xia2"}},"page":"/publication","query":{"id":"uist-2023-xia2"},"buildId":"abOftCVXQ7bohEfVyBLWa","dynamicBuildId":false,"nextExport":true}</script><script async="" id="__NEXT_PAGE__/publication" src="/_next/static/abOftCVXQ7bohEfVyBLWa/pages/publication.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/abOftCVXQ7bohEfVyBLWa/pages/_app.js"></script><script src="/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" async=""></script><script src="/_next/static/chunks/commons.0c93cb8d3516282dd2c4.js" async=""></script><script src="/_next/static/runtime/main-563fdde58a64bdca21c4.js" async=""></script></body></html>